{
    "docs": [
        {
            "location": "/", 
            "text": "UncertainData.jl\n\n\n\n\nMotivation\n\n\nUncertainData.jl was born to systematically deal with uncertain data, and to  \nsample\n from  \nuncertain datasets\n more rigorously.  It makes workflows involving uncertain data of  \ndifferent types\n  and from different sources significantly easier.\n\n\n\n\nPackage philosophy\n\n\nWay too often in data analysis the uncertainties in observational data are ignored or not  dealt with in a systematic manner. The core concept of the package is that uncertain data  should live in the probability domain, not as single value representations of the data  (e.g. the mean).\n\n\nIn this package, uncertain data values are thus  \nstored as probability distributions\n.  Only when performing a computation or plotting, the uncertain values are realized by  resampling the probability distributions furnishing them.\n\n\n\n\nOrganising uncertain data\n\n\nIndividual uncertain observations of different types are seamlessly mixed and can be organised in \ncollections of uncertain values\n.\n\n\n\n\nMathematical operations\n\n\nSeveral \nelementary mathematical operations\n and  \ntrigonometric functions\n are supported  for uncertain values. Computations are done using a  \nresampling approach\n.\n\n\n\n\nStatistics on uncertain datasets\n\n\nStatistics on uncertain datasets are computed using a resampling approach:\n\n\n\n\nCore statistics\n\n\nHypothesis tests\n\n\n\n\n\n\nResampling\n\n\nResampling\n is done by drawing random numbers from the furnishing distributions/populations of the uncertain value(s), using one of the \nresample\n methods.\n\n\nIndividual uncertain values\n may be sampled as they are, or after first applying \nsampling constraints\n on the underlying distributions/populations.\n\n\nCollections of uncertain values\n. Resampling collections can be done assuming no sequential dependence for your data, or by applying sequential sampling models. During this process \nsampling constraints\n can be applied element-wise or on entire collections.\n\n\n\n\nBasic workflow\n\n\n\n\nDefine uncertain values\n by probability distributions.\n\n\nDefine uncertain datasets\n by gathering uncertain values.\n\n\nUse sampling constraints\n to \nconstraint the support of the distributions furnishing the uncertain values\n (i.e. apply subjective criteria to decide what is acceptable data and what is not).\n\n\nResample the uncertain values\n or \nuncertain datasets\n.\n\n\nExtend existing algorithm\n to accept uncertain values/datasets.\n\n\nQuantify the uncertainty\n in your dataset or on whatever measure your algorithm computes.\n\n\n\n\n\n\nRelated software\n\n\nA related package is \nMeasurements.jl\n, which propagates errors exactly and handles correlated uncertainties. However,  Measurements.jl accepts only normally distributed values. This package serves a slightly  different purpose: it was born to provide an easy way of handling uncertainties of  \nmany different types\n,  using a \nresampling\n approach to obtain  \nstatistics\n when needed, and providing a rich set of  \nsampling constraints\n that makes it easy  for the user to reason about and plot their uncertain data under different assumptions.\n\n\nDepending on your needs, \nMeasurements.jl\n  may be a better (and faster) choice if your data satisfies the requirements for the package  (normally distributed) and if your uncertainties are correlated.\n\n\n\n\nContributing\n\n\nIf you have questions, or a good idea for new functionality that could be useful to have in  the package, please submit an issue, or even better - a pull request.", 
            "title": "Package overview"
        }, 
        {
            "location": "/#uncertaindatajl", 
            "text": "", 
            "title": "UncertainData.jl"
        }, 
        {
            "location": "/#motivation", 
            "text": "UncertainData.jl was born to systematically deal with uncertain data, and to   sample  from   uncertain datasets  more rigorously.  It makes workflows involving uncertain data of   different types   and from different sources significantly easier.", 
            "title": "Motivation"
        }, 
        {
            "location": "/#package_philosophy", 
            "text": "Way too often in data analysis the uncertainties in observational data are ignored or not  dealt with in a systematic manner. The core concept of the package is that uncertain data  should live in the probability domain, not as single value representations of the data  (e.g. the mean).  In this package, uncertain data values are thus   stored as probability distributions .  Only when performing a computation or plotting, the uncertain values are realized by  resampling the probability distributions furnishing them.", 
            "title": "Package philosophy"
        }, 
        {
            "location": "/#organising_uncertain_data", 
            "text": "Individual uncertain observations of different types are seamlessly mixed and can be organised in  collections of uncertain values .", 
            "title": "Organising uncertain data"
        }, 
        {
            "location": "/#mathematical_operations", 
            "text": "Several  elementary mathematical operations  and   trigonometric functions  are supported  for uncertain values. Computations are done using a   resampling approach .", 
            "title": "Mathematical operations"
        }, 
        {
            "location": "/#statistics_on_uncertain_datasets", 
            "text": "Statistics on uncertain datasets are computed using a resampling approach:   Core statistics  Hypothesis tests", 
            "title": "Statistics on uncertain datasets"
        }, 
        {
            "location": "/#resampling", 
            "text": "Resampling  is done by drawing random numbers from the furnishing distributions/populations of the uncertain value(s), using one of the  resample  methods.  Individual uncertain values  may be sampled as they are, or after first applying  sampling constraints  on the underlying distributions/populations.  Collections of uncertain values . Resampling collections can be done assuming no sequential dependence for your data, or by applying sequential sampling models. During this process  sampling constraints  can be applied element-wise or on entire collections.", 
            "title": "Resampling"
        }, 
        {
            "location": "/#basic_workflow", 
            "text": "Define uncertain values  by probability distributions.  Define uncertain datasets  by gathering uncertain values.  Use sampling constraints  to  constraint the support of the distributions furnishing the uncertain values  (i.e. apply subjective criteria to decide what is acceptable data and what is not).  Resample the uncertain values  or  uncertain datasets .  Extend existing algorithm  to accept uncertain values/datasets.  Quantify the uncertainty  in your dataset or on whatever measure your algorithm computes.", 
            "title": "Basic workflow"
        }, 
        {
            "location": "/#related_software", 
            "text": "A related package is  Measurements.jl , which propagates errors exactly and handles correlated uncertainties. However,  Measurements.jl accepts only normally distributed values. This package serves a slightly  different purpose: it was born to provide an easy way of handling uncertainties of   many different types ,  using a  resampling  approach to obtain   statistics  when needed, and providing a rich set of   sampling constraints  that makes it easy  for the user to reason about and plot their uncertain data under different assumptions.  Depending on your needs,  Measurements.jl   may be a better (and faster) choice if your data satisfies the requirements for the package  (normally distributed) and if your uncertainties are correlated.", 
            "title": "Related software"
        }, 
        {
            "location": "/#contributing", 
            "text": "If you have questions, or a good idea for new functionality that could be useful to have in  the package, please submit an issue, or even better - a pull request.", 
            "title": "Contributing"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_overview/", 
            "text": "Uncertain value types\n\n\nThe core concept of \nUncertainData\n is to replace an uncertain data value with a  probability distribution describing the point's uncertainty.\n\n\nThe following types of uncertain values are currently implemented:\n\n\n\n\nTheoretical distributions with known parameters\n.\n\n\nTheoretical distributions with parameters fitted to empirical data\n.\n\n\nKernel density estimated distributions estimated from empirical data\n.\n\n\nWeighted (nested) populations\n where the probability of    drawing values are already known, so you can skip kernel density estimation. Populations can be    nested, and may contain numerical values, uncertain values or both.\n\n\nValues without uncertainty\n have their own dedicated    \nCertainValue\n type, so that you can uncertain values with certain values.\n\n\nMeasurement\n instances\n from \nMeasurements.jl\n are treated as normal distributions with known mean and standard devation.\n\n\n\n\n\n\nSome quick examples\n\n\nSee also the \nextended examples\n!\n\n\n\n\nKernel density estimation (KDE)\n\n\nIf the data doesn't follow an obvious theoretical distribution, the recommended course of action is to represent the uncertain value with a kernel density estimate of the distribution.\n\n\n\n\n\n\nImplicit KDE estimate\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Generate some random data from a normal distribution, so that we get a\n\n\n# histogram resembling a normal distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nNormal\n(),\n \n1000\n)\n\n\n\n# Uncertain value represented by a kernel density estimate (it is inferred\n\n\n# that KDE is wanted when no distribution is provided to the constructor).\n\n\nuv\n \n=\n \nUncertainValue\n(\nsome_sample\n)\n\n\n\n\n\n\n\n\nExplicit KDE estimate\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some random data from a normal distribution, so that we get a\n\n\n# histogram resembling a normal distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nNormal\n(),\n \n1000\n)\n\n\n\n\n# Specify that we want a kernel density estimate representation\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\n\n\nPopulations\n\n\nIf you have a population of values where each value has a probability assigned to it,  you can construct an uncertain value by providing the values and uncertainties as  two equal-length vectors to the constructor. Weights are normalized by default.\n\n\n1\n2\n3\nvals\n \n=\n \nrand\n(\n100\n)\n\n\nweights\n \n=\n \nrand\n(\n100\n)\n\n\np\n \n=\n \nUncertainValue\n(\nvals\n,\n \nweights\n)\n\n\n\n\n\n\n\n\n\nFitting a theoretical distribution\n\n\nIf your data has a histogram closely resembling some theoretical distribution, the uncertain value may be represented by fitting such a distribution to the data.\n\n\n\n\n\n\nExample 1: fitting a normal distribution\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some random data from a normal distribution, so that we get a\n\n\n# histogram resembling a normal distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nNormal\n(),\n \n1000\n)\n\n\n\n# Uncertain value represented by a theoretical normal distribution with\n\n\n# parameters fitted to the data.\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nExample 2: fitting a gamma distribution\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some random data from a gamma distribution, so that we get a\n\n\n# histogram resembling a gamma distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(),\n \n1000\n)\n\n\n\n# Uncertain value represented by a theoretical gamma distribution with\n\n\n# parameters fitted to the data.\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\n\n\nTheoretical distribution with known parameters\n\n\nIt is common when working with uncertain data found in the scientific literature that data value are stated to follow a distribution with given parameters. For example, a data value may be given as normal distribution with a given mean \n\u03bc\n \n=\n \n2\n.\n2\n and standard deviation \n\u03c3\n \n=\n \n0\n.\n3\n.\n\n\n\n\n\n\nExample 1: theoretical normal distribution\n\n\n1\n2\n3\n# Uncertain value represented by a theoretical normal distribution with\n\n\n# known parameters \u03bc = 2.2 and \u03c3 = 0.3\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2.2\n,\n \n0.3\n)\n\n\n\n\n\n\n\n\nExample 2: theoretical gamma distribution\n\n\n1\n2\n3\n# Uncertain value represented by a theoretical gamma distribution with\n\n\n# known parameters \u03b1 = 2.1 and \u03b8 = 3.1\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2.1\n,\n \n3.1\n)\n\n\n\n\n\n\n\n\nExample 3: theoretical binomial distribution\n\n\n1\n2\n3\n# Uncertain value represented by a theoretical binomial distribution with\n\n\n# known parameters p = 32 and p = 0.13\n\n\nuv\n \n=\n \nUncertainValue\n(\nBinomial\n,\n \n32\n,\n \n0.13\n)\n\n\n\n\n\n\n\n\n\n\nValues with no uncertainty\n\n\nScalars with no uncertainty can also be represented. \n\n\n1\nc1\n,\n \nc2\n \n=\n \nUncertainValue\n(\n2\n),\n \nUncertainValue\n(\n2.2\n)", 
            "title": "Types of uncertain values"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_overview/#uncertain_value_types", 
            "text": "The core concept of  UncertainData  is to replace an uncertain data value with a  probability distribution describing the point's uncertainty.  The following types of uncertain values are currently implemented:   Theoretical distributions with known parameters .  Theoretical distributions with parameters fitted to empirical data .  Kernel density estimated distributions estimated from empirical data .  Weighted (nested) populations  where the probability of    drawing values are already known, so you can skip kernel density estimation. Populations can be    nested, and may contain numerical values, uncertain values or both.  Values without uncertainty  have their own dedicated     CertainValue  type, so that you can uncertain values with certain values.  Measurement  instances  from  Measurements.jl  are treated as normal distributions with known mean and standard devation.", 
            "title": "Uncertain value types"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_overview/#some_quick_examples", 
            "text": "See also the  extended examples !", 
            "title": "Some quick examples"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_overview/#kernel_density_estimation_kde", 
            "text": "If the data doesn't follow an obvious theoretical distribution, the recommended course of action is to represent the uncertain value with a kernel density estimate of the distribution.    Implicit KDE estimate  1\n2\n3\n4\n5\n6\n7\n8\n9 using   Distributions ,   UncertainData ,   KernelDensity  # Generate some random data from a normal distribution, so that we get a  # histogram resembling a normal distribution.  some_sample   =   rand ( Normal (),   1000 )  # Uncertain value represented by a kernel density estimate (it is inferred  # that KDE is wanted when no distribution is provided to the constructor).  uv   =   UncertainValue ( some_sample )     Explicit KDE estimate  1\n2\n3\n4\n5\n6\n7\n8\n9 using   Distributions ,   UncertainData  # Generate some random data from a normal distribution, so that we get a  # histogram resembling a normal distribution.  some_sample   =   rand ( Normal (),   1000 )  # Specify that we want a kernel density estimate representation  uv   =   UncertainValue ( UnivariateKDE ,   some_sample )", 
            "title": "Kernel density estimation (KDE)"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_overview/#populations", 
            "text": "If you have a population of values where each value has a probability assigned to it,  you can construct an uncertain value by providing the values and uncertainties as  two equal-length vectors to the constructor. Weights are normalized by default.  1\n2\n3 vals   =   rand ( 100 )  weights   =   rand ( 100 )  p   =   UncertainValue ( vals ,   weights )", 
            "title": "Populations"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_overview/#fitting_a_theoretical_distribution", 
            "text": "If your data has a histogram closely resembling some theoretical distribution, the uncertain value may be represented by fitting such a distribution to the data.    Example 1: fitting a normal distribution  1\n2\n3\n4\n5\n6\n7\n8\n9 using   Distributions ,   UncertainData  # Generate some random data from a normal distribution, so that we get a  # histogram resembling a normal distribution.  some_sample   =   rand ( Normal (),   1000 )  # Uncertain value represented by a theoretical normal distribution with  # parameters fitted to the data.  uv   =   UncertainValue ( Normal ,   some_sample )     Example 2: fitting a gamma distribution  1\n2\n3\n4\n5\n6\n7\n8\n9 using   Distributions ,   UncertainData  # Generate some random data from a gamma distribution, so that we get a  # histogram resembling a gamma distribution.  some_sample   =   rand ( Gamma (),   1000 )  # Uncertain value represented by a theoretical gamma distribution with  # parameters fitted to the data.  uv   =   UncertainValue ( Gamma ,   some_sample )", 
            "title": "Fitting a theoretical distribution"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_overview/#theoretical_distribution_with_known_parameters", 
            "text": "It is common when working with uncertain data found in the scientific literature that data value are stated to follow a distribution with given parameters. For example, a data value may be given as normal distribution with a given mean  \u03bc   =   2 . 2  and standard deviation  \u03c3   =   0 . 3 .    Example 1: theoretical normal distribution  1\n2\n3 # Uncertain value represented by a theoretical normal distribution with  # known parameters \u03bc = 2.2 and \u03c3 = 0.3  uv   =   UncertainValue ( Normal ,   2.2 ,   0.3 )     Example 2: theoretical gamma distribution  1\n2\n3 # Uncertain value represented by a theoretical gamma distribution with  # known parameters \u03b1 = 2.1 and \u03b8 = 3.1  uv   =   UncertainValue ( Gamma ,   2.1 ,   3.1 )     Example 3: theoretical binomial distribution  1\n2\n3 # Uncertain value represented by a theoretical binomial distribution with  # known parameters p = 32 and p = 0.13  uv   =   UncertainValue ( Binomial ,   32 ,   0.13 )", 
            "title": "Theoretical distribution with known parameters"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_overview/#values_with_no_uncertainty", 
            "text": "Scalars with no uncertainty can also be represented.   1 c1 ,   c2   =   UncertainValue ( 2 ),   UncertainValue ( 2.2 )", 
            "title": "Values with no uncertainty"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_kde/", 
            "text": "When your data have an empirical distribution that doesn't follow any obvious theoretical distribution, the data may be represented by a kernel density estimate.\n\n\n\n\nGeneric constructor\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainValue\n \n \nMethod\n.\n\n\n1\nUncertainValue\n(\nvalues\n::\nVector\n,\n \nprobs\n::\nUnion\n{\nVector\n,\n \nAbstractWeights\n})\n\n\n\n\n\n\n\nConstruct a population whose members are given by \nvalues\n and whose sampling  probabilities are given by \nprobs\n. The elements of \nvalues\n can be either  numeric or uncertain values of any type.\n\n\nsource\n\n\n1\n2\n3\nUncertainValue\n(\ndata\n::\nVector\n{\nT\n};\n\n    \nkernel\n::\nType\n{\nD\n}\n \n=\n \nNormal\n,\n\n    \nnpoints\n::\nInt\n=\n2048\n)\n \nwhere\n \n{\nD\n \n:\n \nDistributions\n.\nDistribution\n,\n \nT\n}\n\n\n\n\n\n\n\nConstruct an uncertain value by a kernel density estimate to \ndata\n.\n\n\nFast Fourier transforms are used in the kernel density estimation, so the number of points should be a power of 2 (default = 2048).\n\n\nsource\n\n\n1\n2\n3\nUncertainValue\n(\nkerneldensity\n::\nType\n{\nK\n}\n,\n \ndata\n::\nVector\n{\nT\n}\n;\n\n    \nkernel\n::\nType\n{\nD\n}\n \n=\n \nNormal\n,\n\n    \nnpoints\n::\nInt\n=\n2048\n)\n \nwhere\n \n{\nK\n \n:\n \nUnivariateKDE,\n \nD\n \n:\n \nDistribution,\n \nT\n}\n\n\n\n\n\n\n\nConstruct an uncertain value by a kernel density estimate to \ndata\n.\n\n\nFast Fourier transforms are used in the kernel density estimation, so the number of points should be a power of 2 (default = 2048).\n\n\nsource\n\n\n1\n2\nUncertainValue\n(\nempiricaldata\n::\nAbstractVector\n{\nT\n},\n\n    \nd\n::\nType\n{\nD\n})\n \nwhere\n \n{\nD\n \n:\n \nDistribution\n}\n\n\n\n\n\n\n\nConstructor for empirical distributions.\n\n\nFit a distribution of type \nd\n to the data and use that as the representation of the empirical distribution. Calls \nDistributions\n.\nfit\n behind the scenes.\n\n\nArguments\n\n\n\n\nempiricaldata\n: The data for which to fit the \ndistribution\n.\n\n\ndistribution\n: A valid univariate distribution from \nDistributions\n.\njl\n.\n\n\n\n\nsource\n\n\n\n\nType documentation\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarKDE\n \n \nType\n.\n\n\n1\nUncertainScalarKDE\n\n\n\n\n\n\n\nAn empirical value represented by a distribution estimated from actual data.\n\n\nFields\n\n\n\n\ndistribution\n: The \nUnvariateKDE\n estimate for the distribution of \nvalues\n.\n\n\nvalues\n: The values from which \ndistribution\n is estimated.\n\n\nrange\n: The values for which the pdf is estimated.\n\n\npdf\n: The values of the pdf at each point in \nrange\n.\n\n\n\n\nsource\n\n\n\n\nExamples\n\n\n\n\n\n\nImplicit KDE constructor\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the implicit KDE constructor to create the uncertain value\n\n\nuv\n \n=\n \nUncertainValue\n(\nv\n::\nVector\n)\n\n\n\n\n\n\n\n\nExplicit KDE constructor\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the explicit KDE constructor to create the uncertain value.\n\n\n# This constructor follows the same convention as when fitting distributions\n\n\n# to empirical data, so this is the recommended way to construct KDE estimates.\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nv\n::\nVector\n)\n\n\n\n\n\n\n\n\nChanging the kernel\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the explicit KDE constructor to create the uncertain value, specifying\n\n\n# that we want to use normal distributions as the kernel. The kernel can be\n\n\n# any valid kernel from Distributions.jl, and the default is to use normal\n\n\n# distributions.\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nv\n::\nVector\n;\n \nkernel\n \n=\n \nNormal\n)\n\n\n\n\n\n\n\n\nAdjusting number of points\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the explicit KDE constructor to create the uncertain value, specifying\n\n\n# the number of points we want to use for the kernel density estimate. Fast\n\n\n# Fourier transforms are used behind the scenes, so the number of points\n\n\n# should be a power of 2 (the default is 2048 points).\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nv\n::\nVector\n;\n \nnpoints\n \n=\n \n1024\n)\n\n\n\n\n\n\n\n\n\n\nExtended example\n\n\nLet's create a bimodal distribution, then sample 10000 values from it.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\nusing\n \nDistributions\n\n\n\nn1\n \n=\n \nNormal\n(\n-\n3.0\n,\n \n1.2\n)\n\n\nn2\n \n=\n \nNormal\n(\n8.0\n,\n \n1.2\n)\n\n\nn3\n \n=\n \nNormal\n(\n0.0\n,\n \n2.5\n)\n\n\n\n# Use a mixture model to create a bimodal distribution\n\n\nM\n \n=\n \nMixtureModel\n([\nn1\n,\n \nn2\n,\n \nn3\n])\n\n\n\n# Sample the mixture model.\n\n\nsamples_empirical\n \n=\n \nrand\n(\nM\n,\n \nInt\n(\n1e4\n));\n\n\n\n\n\n\n\n\n\nIt is not obvious which distribution to fit to such data.\n\n\nA kernel density estimate, however, will always be a decent representation of the data, because it doesn't follow a specific distribution and adapts to the data values.\n\n\nTo create a kernel density estimate, simply call the \nUncertainValue\n(\nv\n::\nVector\n{\nNumber\n}\n)\n constructor with a vector containing the sample:\n\n\n1\nuv\n \n=\n \nUncertainValue\n(\nsamples_empirical\n)\n\n\n\n\n\n\n\nThe plot below compares the empirical histogram (here represented as a density plot) with our kernel density estimate.\n\n\n1\n2\n3\n4\n5\n6\n7\nusing\n \nPlots\n,\n \nStatPlots\n,\n \nUncertainData\n\n\nuv\n \n=\n \nUncertainValue\n(\nsamples_empirical\n)\n\n\ndensity\n(\nmvals\n,\n \nlabel\n \n=\n \n10000 mixture model (M) samples\n)\n\n\ndensity!\n(\nrand\n(\nuv\n,\n \nInt\n(\n1e4\n)),\n\n    \nlabel\n \n=\n \n10000 samples from KDE estimate to M\n)\n\n\nxlabel!\n(\ndata value\n)\n\n\nylabel!\n(\nprobability density\n)\n\n\n\n\n\n\n\n\n\n\n\nConstructor\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainValue\n \n \nMethod\n.\n\n\n1\n2\n3\nUncertainValue\n(\ndata\n::\nVector\n{\nT\n};\n\n    \nkernel\n::\nType\n{\nD\n}\n \n=\n \nNormal\n,\n\n    \nnpoints\n::\nInt\n=\n2048\n)\n \nwhere\n \n{\nD\n \n:\n \nDistributions\n.\nDistribution\n,\n \nT\n}\n\n\n\n\n\n\n\nConstruct an uncertain value by a kernel density estimate to \ndata\n.\n\n\nFast Fourier transforms are used in the kernel density estimation, so the number of points should be a power of 2 (default = 2048).\n\n\nsource\n\n\n\n\nAdditional keyword arguments and examples\n\n\nIf the only argument to the \nUncertainValue\n constructor is a vector of values, the default behaviour is to represent the distribution by a kernel density estimate (KDE), i.e. \nUncertainValue\n(\ndata\n)\n. Gaussian kernels are used by default. The syntax \nUncertainValue\n(\nUnivariateKDE\n,\n \ndata\n)\n will also work if \nKernelDensity\n.\njl\n is loaded.", 
            "title": "Kernel density estimates (KDE)"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_kde/#generic_constructor", 
            "text": "#  UncertainData . UncertainValues . UncertainValue     Method .  1 UncertainValue ( values :: Vector ,   probs :: Union { Vector ,   AbstractWeights })    Construct a population whose members are given by  values  and whose sampling  probabilities are given by  probs . The elements of  values  can be either  numeric or uncertain values of any type.  source  1\n2\n3 UncertainValue ( data :: Vector { T }; \n     kernel :: Type { D }   =   Normal , \n     npoints :: Int = 2048 )   where   { D   :   Distributions . Distribution ,   T }    Construct an uncertain value by a kernel density estimate to  data .  Fast Fourier transforms are used in the kernel density estimation, so the number of points should be a power of 2 (default = 2048).  source  1\n2\n3 UncertainValue ( kerneldensity :: Type { K } ,   data :: Vector { T } ; \n     kernel :: Type { D }   =   Normal , \n     npoints :: Int = 2048 )   where   { K   :   UnivariateKDE,   D   :   Distribution,   T }    Construct an uncertain value by a kernel density estimate to  data .  Fast Fourier transforms are used in the kernel density estimation, so the number of points should be a power of 2 (default = 2048).  source  1\n2 UncertainValue ( empiricaldata :: AbstractVector { T }, \n     d :: Type { D })   where   { D   :   Distribution }    Constructor for empirical distributions.  Fit a distribution of type  d  to the data and use that as the representation of the empirical distribution. Calls  Distributions . fit  behind the scenes.  Arguments   empiricaldata : The data for which to fit the  distribution .  distribution : A valid univariate distribution from  Distributions . jl .   source", 
            "title": "Generic constructor"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_kde/#type_documentation", 
            "text": "#  UncertainData . UncertainValues . UncertainScalarKDE     Type .  1 UncertainScalarKDE    An empirical value represented by a distribution estimated from actual data.  Fields   distribution : The  UnvariateKDE  estimate for the distribution of  values .  values : The values from which  distribution  is estimated.  range : The values for which the pdf is estimated.  pdf : The values of the pdf at each point in  range .   source", 
            "title": "Type documentation"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_kde/#examples", 
            "text": "Implicit KDE constructor   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the implicit KDE constructor to create the uncertain value  uv   =   UncertainValue ( v :: Vector )     Explicit KDE constructor   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 using   Distributions ,   UncertainData ,   KernelDensity  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the explicit KDE constructor to create the uncertain value.  # This constructor follows the same convention as when fitting distributions  # to empirical data, so this is the recommended way to construct KDE estimates.  uv   =   UncertainValue ( UnivariateKDE ,   v :: Vector )     Changing the kernel   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 using   Distributions ,   UncertainData ,   KernelDensity  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the explicit KDE constructor to create the uncertain value, specifying  # that we want to use normal distributions as the kernel. The kernel can be  # any valid kernel from Distributions.jl, and the default is to use normal  # distributions.  uv   =   UncertainValue ( UnivariateKDE ,   v :: Vector ;   kernel   =   Normal )     Adjusting number of points   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 using   Distributions ,   UncertainData ,   KernelDensity  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the explicit KDE constructor to create the uncertain value, specifying  # the number of points we want to use for the kernel density estimate. Fast  # Fourier transforms are used behind the scenes, so the number of points  # should be a power of 2 (the default is 2048 points).  uv   =   UncertainValue ( UnivariateKDE ,   v :: Vector ;   npoints   =   1024 )", 
            "title": "Examples"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_kde/#extended_example", 
            "text": "Let's create a bimodal distribution, then sample 10000 values from it.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 using   Distributions  n1   =   Normal ( - 3.0 ,   1.2 )  n2   =   Normal ( 8.0 ,   1.2 )  n3   =   Normal ( 0.0 ,   2.5 )  # Use a mixture model to create a bimodal distribution  M   =   MixtureModel ([ n1 ,   n2 ,   n3 ])  # Sample the mixture model.  samples_empirical   =   rand ( M ,   Int ( 1e4 ));     It is not obvious which distribution to fit to such data.  A kernel density estimate, however, will always be a decent representation of the data, because it doesn't follow a specific distribution and adapts to the data values.  To create a kernel density estimate, simply call the  UncertainValue ( v :: Vector { Number } )  constructor with a vector containing the sample:  1 uv   =   UncertainValue ( samples_empirical )    The plot below compares the empirical histogram (here represented as a density plot) with our kernel density estimate.  1\n2\n3\n4\n5\n6\n7 using   Plots ,   StatPlots ,   UncertainData  uv   =   UncertainValue ( samples_empirical )  density ( mvals ,   label   =   10000 mixture model (M) samples )  density! ( rand ( uv ,   Int ( 1e4 )), \n     label   =   10000 samples from KDE estimate to M )  xlabel! ( data value )  ylabel! ( probability density )", 
            "title": "Extended example"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_kde/#constructor", 
            "text": "#  UncertainData . UncertainValues . UncertainValue     Method .  1\n2\n3 UncertainValue ( data :: Vector { T }; \n     kernel :: Type { D }   =   Normal , \n     npoints :: Int = 2048 )   where   { D   :   Distributions . Distribution ,   T }    Construct an uncertain value by a kernel density estimate to  data .  Fast Fourier transforms are used in the kernel density estimation, so the number of points should be a power of 2 (default = 2048).  source", 
            "title": "Constructor"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_kde/#additional_keyword_arguments_and_examples", 
            "text": "If the only argument to the  UncertainValue  constructor is a vector of values, the default behaviour is to represent the distribution by a kernel density estimate (KDE), i.e.  UncertainValue ( data ) . Gaussian kernels are used by default. The syntax  UncertainValue ( UnivariateKDE ,   data )  will also work if  KernelDensity . jl  is loaded.", 
            "title": "Additional keyword arguments and examples"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/", 
            "text": "It is common in the scientific literature to encounter uncertain data values which are reported as following a specific distribution. For example, an author report the mean and standard deviation of a value stated to follow a normal distribution. \nUncertainData\n makes it easy to represent such values!\n\n\n\n\nGeneric constructors\n\n\n\n\nFrom instances of distributions\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainValue\n \n \nMethod\n.\n\n\n1\nUncertainValue\n(\nd\n::\nDistributions\n.\nDistribution\n)\n\n\n\n\n\n\n\nConstruct an uncertain value from an instance of a distribution. If a specific uncertain value type has not been implemented, the number of parameters is  determined from the distribution and an instance of one of the following types is returned: \n\n\n\n\nUncertainScalarTheoreticalOneParameter\n\n\nUncertainScalarTheoreticalTwoParameter\n\n\nUncertainScalarTheoreticalThreeParameter\n\n\n\n\nExamples\n\n\n1\n2\n3\nUncertainValue\n(\nNormal\n(\n0\n,\n \n1\n))\n\n\nUncertainValue\n(\nGamma\n(\n4\n,\n \n5.1\n))\n\n\nUncertainValue\n(\nBinomial\n,\n \n8\n,\n \n0.2\n)\n\n\n\n\n\n\n\nsource\n\n\n\n\nDefined from scratch\n\n\nUncertain values represented by theoretical distributions may be constructed using the two-parameter or three-parameter constructors \nUncertainValue\n(\nd\n::\nType\n{\nD\n}\n,\n \na\n:\nNumber\n,\n \nb\n:\nNumber\n)\n or \nUncertainValue\n(\nd\n::\nType\n{\nD\n}\n,\n \na\n:\nNumber\n,\n \nb\n:\nNumber\n,\n \nc\n:\nNumber\n)\n (see below). Parameters are provided to the constructor in the same order as for constructing  the equivalent distributions in \nDistributions\n.\njl\n.\n\n\n\n\nTwo-parameter distributions\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainValue\n \n \nMethod\n.\n\n\n1\n2\nUncertainValue\n(\ndistribution\n::\nType\n{\nD\n},\n \na\n::\nT1\n,\n \nb\n::\nT2\n;\n\n    \nkwargs\n...\n)\n \nwhere\n \n{\nT1\n:\nNumber\n,\n \nT2\n \n:\n \nNumber\n,\n \nD\n:\nDistribution\n}\n\n\n\n\n\n\n\nConstructor for two-parameter distributions\n\n\nUncertainValue\ns are currently implemented for the following two-parameter distributions: \nUniform\n, \nNormal\n, \nBinomial\n, \nBeta\n, \nBetaPrime\n, \nGamma\n, and \nFrechet\n.\n\n\nArguments\n\n\n\n\na\n, \nb\n: Generic parameters whose meaning varies depending   on what \ndistribution\n is provided. See the list below.\n\n\ndistribution\n: A valid univariate distribution from \nDistributions\n.\njl\n.\n\n\n\n\nPrecisely what  \na\n and \nb\n are depends on which distribution is provided.\n\n\n\n\nUncertainValue\n(\nNormal\n,\n \n\u03bc\n,\n \n\u03c3\n)\n returns an \nUncertainScalarNormallyDistributed\n instance.\n\n\nUncertainValue\n(\nUniform\n,\n \nlower\n,\n \nupper\n)\n returns an \nUncertainScalarUniformlyDistributed\n instance.\n\n\nUncertainValue\n(\nBeta\n,\n \n\u03b1\n,\n \n\u03b2\n)\n returns an \nUncertainScalarBetaDistributed\n instance.\n\n\nUncertainValue\n(\nBetaPrime\n,\n \n\u03b1\n,\n \n\u03b2\n)\n returns an \nUncertainScalarBetaPrimeDistributed\n instance.\n\n\nUncertainValue\n(\nGamma\n,\n \n\u03b1\n,\n \n\u03b8\n)\n returns an \nUncertainScalarGammaDistributed\n instance.\n\n\nUncertainValue\n(\nFrechet\n,\n \n\u03b1\n,\n \n\u03b8\n)\n returns an \nUncertainScalarFrechetDistributed\n instance.\n\n\nUncertainValue\n(\nBinomial\n,\n \nn\n,\n \np\n)\n returns an \nUncertainScalarBinomialDistributed\n instance.\n\n\n\n\nKeyword arguments\n\n\n\n\nn\n\u03c3\n: If \ndistribution\n \n:\n \nDistributions\n.\nNormal\n, then how many standard   deviations away from \n\u03bc\n does \nlower\n and \nupper\n (i.e. both, because   they are the same distance away from \n\u03bc\n) represent?\n\n\ntolerance\n: A threshold determining how symmetric the uncertainties   must be in order to allow the construction of  Normal distribution   (\nupper\n \n-\n \nlower\n \n \nthreshold\n is required).\n\n\ntrunc_lower\n: Lower truncation bound for distributions with infinite   support. Defaults to \n-\nInf\n.\n\n\ntrunc_upper\n: Upper truncation bound for distributions with infinite   support. Defaults to \nInf\n.\n\n\n\n\nExamples\n\n\nNormal distribution\n\n\nNormal distributions are formed by using the constructor \nUncertainValue\n(\n\u03bc\n,\n \n\u03c3\n,\n \nNormal\n;\n \nkwargs\n...)\n. This gives a normal distribution with mean \u03bc and standard deviation \u03c3/n\u03c3 (n\u03c3 must be given as a keyword argument).\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n# A normal distribution with mean = 2.3 and standard deviation 0.3.\n\n\nUncertainValue\n(\n2.3\n,\n \n0.3\n,\n \nNormal\n)\n\n\n\n# A normal distribution with mean 2.3 and standard deviation 0.3/2.\n\n\nUncertainValue\n(\n2.3\n,\n \n0.3\n,\n \nNormal\n,\n \nn\u03c3\n \n=\n \n2\n)\n\n\n\n# A normal distribution with mean 2.3 and standard deviation = 0.3,\n\n\ntruncated\n \nto\n \nthe\n \ninterval\n \n`[1, 3]`\n.\n\n\nUncertainValue\n(\n2.3\n,\n \n0.3\n,\n \nNormal\n,\n \ntrunc_lower\n \n=\n \n1.0\n,\n \ntrunc_upper\n \n=\n \n3.0\n)\n\n\n\n\n\n\n\nUniform distribution\n\n\nUniform distributions are formed using the \nUncertainValue\n(\nlower\n,\n \nupper\n,\n \nUniform\n)\n constructor.\n\n\n1\n2\n#  A uniform distribution on `[2, 3]`\n\n\nUncertainValue\n(\n-\n2\n,\n \n3\n,\n \nUniform\n)\n\n\n\n\n\n\n\nsource\n\n\n\n\nThree-parameter distributions\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainValue\n \n \nMethod\n.\n\n\n1\n2\nUncertainValue\n(\ndistribution\n::\nType\n{\nD\n},\n \na\n::\nT1\n,\n \nb\n::\nT2\n,\n \nc\n::\nT3\n;\n\n    \nkwargs\n...\n)\n \nwhere\n \n{\nT1\n:\nNumber\n,\n \nT2\n:\nNumber\n,\n \nT3\n:\nNumber\n,\n \nD\n:\nDistribution\n}\n\n\n\n\n\n\n\nConstructor for three-parameter distributions\n\n\nCurrently implemented distributions are \nBetaBinomial\n.\n\n\nArguments\n\n\n\n\na\n, \nb\n, \nc\n: Generic parameters whose meaning varies depending   on what \ndistribution\n is provided. See the list below.\n\n\ndistribution\n: A valid univariate distribution from \nDistributions\n.\njl\n.\n\n\n\n\nPrecisely what \na\n, \nb\n and \nc\n are depends on which distribution is provided.\n\n\n\n\nUncertainValue\n(\nBetaBinomial\n,\n \nn\n,\n \n\u03b1\n,\n \n\u03b2\n)\n returns an \nUncertainScalarBetaBinomialDistributed\n instance.\n\n\n\n\nKeyword arguments\n\n\n\n\nn\n\u03c3\n: If \ndistribution\n \n:\n \nDistributions\n.\nNormal\n, then how many standard   deviations away from \n\u03bc\n does \nlower\n and \nupper\n (i.e. both, because   they are the same distance away from \n\u03bc\n) represent?\n\n\ntolerance\n: A threshold determining how symmetric the uncertainties   must be in order to allow the construction of  Normal distribution   (\nupper\n \n-\n \nlower\n \n \nthreshold\n is required).\n\n\ntrunc_lower\n: Lower truncation bound for distributions with infinite   support. Defaults to \n-\nInf\n.\n\n\ntrunc_upper\n: Upper truncation bound for distributions with infinite   support. Defaults to \nInf\n.\n\n\n\n\nExamples\n\n\nBetaBinomial distribution\n\n\nNormal distributions are formed by using the constructor \nUncertainValue\n(\n\u03bc\n,\n \n\u03c3\n,\n \nNormal\n;\n \nkwargs\n...)\n. This gives a normal distribution with mean \u03bc and standard deviation \u03c3/n\u03c3 (n\u03c3 must be given as a keyword argument).\n\n\n1\n2\n3\n# A beta binomial distribution with n = 100 trials and parameters \u03b1 = 2.3 and\n\n\n# \u03b2 = 5\n\n\nUncertainValue\n(\n100\n,\n \n2.3\n,\n \n5\n,\n \nBetaBinomial\n)\n\n\n\n\n\n\n\nsource\n\n\n\n\nType documentation\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarBetaBinomialDistributed\n \n \nType\n.\n\n\nUncertain value represented by a beta binomial distribution.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarBetaDistributed\n \n \nType\n.\n\n\nUncertain value represented by a beta distribution.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarBetaPrimeDistributed\n \n \nType\n.\n\n\nUncertain value represented by a beta prime distribution.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarBinomialDistributed\n \n \nType\n.\n\n\nUncertain value represented by a binomial distribution.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarFrechetDistributed\n \n \nType\n.\n\n\nUncertain value represented by a Fr\u00e9chet distribution.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarGammaDistributed\n \n \nType\n.\n\n\nUncertain value represented by a gamma distribution.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarNormallyDistributed\n \n \nType\n.\n\n\nUncertain value represented by a normal distribution.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarUniformlyDistributed\n \n \nType\n.\n\n\nUncertain value represented by a uniform distribution.\n\n\nsource\n\n\n\n\nList of supported distributions\n\n\nSupported distributions are:\n\n\n\n\nUniform\n\n\nNormal\n\n\nGamma\n\n\nBeta\n\n\nBetaPrime\n\n\nFrechet\n\n\nBinomial\n\n\nBetaBinomial\n\n\n\n\nMore distributions will be added in the future!.\n\n\n\n\nExamples\n\n\n\n\n\n\nUniform\n\n\n1\n2\n# Uncertain value generated by a uniform distribution on [-5.0, 5.1].\n\n\nuv\n \n=\n \nUncertainValue\n(\nUniform\n,\n \n-\n5.0\n,\n \n5.1\n)\n\n\n\n\n\n\n\n\nNormal\n\n\n1\n2\n3\n# Uncertain value generated by a normal distribution with parameters \u03bc = -2 and\n\n\n# \u03c3 = 0.5.\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n-\n2\n,\n \n0.5\n)\n\n\n\n\n\n\n\n\nGamma\n\n\n1\n2\n3\n# Uncertain value generated by a gamma distribution with parameters \u03b1 = 2.2\n\n\n# and \u03b8 = 3.\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2.2\n,\n \n3\n)\n\n\n\n\n\n\n\n\nBeta\n\n\n1\n2\n3\n# Uncertain value generated by a beta distribution with parameters \u03b1 = 1.5\n\n\n# and \u03b2 = 3.5\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n1.5\n,\n \n3.5\n)\n\n\n\n\n\n\n\n\nBetaPrime\n\n\n1\n2\n3\n# Uncertain value generated by a beta prime distribution with parameters \u03b1 = 1.7\n\n\n# and \u03b2 = 3.2\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n1.7\n,\n \n3.2\n)\n\n\n\n\n\n\n\n\nFr\u00e9chet\n\n\n1\n2\n3\n# Uncertain value generated by a Fr\u00e9chet distribution with parameters \u03b1 = 2.1\n\n\n# and \u03b8 = 4\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n2.1\n,\n \n4\n)\n\n\n\n\n\n\n\n\nBinomial\n\n\n1\n2\n3\n# Uncertain value generated by binomial distribution with n = 28 trials and\n\n\n# probability p = 0.2 of success in individual trials.\n\n\nuv\n \n=\n \nUncertainValue\n(\nBinomial\n,\n \n28\n,\n \n0.2\n)\n\n\n\n\n\n\n\n\nBetaBinomial\n\n\n1\n2\n3\n# Creates an uncertain value generated by a beta-binomial distribution with\n\n\n# n = 28 trials, and parameters \u03b1 = 1.5 and \u03b2 = 3.5.\n\n\nuv\n \n=\n \nUncertainValue\n(\nBetaBinomial\n,\n \n28\n,\n \n3.3\n,\n \n4.4\n)", 
            "title": "Theoretical distributions with known parameters"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#generic_constructors", 
            "text": "", 
            "title": "Generic constructors"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#from_instances_of_distributions", 
            "text": "#  UncertainData . UncertainValues . UncertainValue     Method .  1 UncertainValue ( d :: Distributions . Distribution )    Construct an uncertain value from an instance of a distribution. If a specific uncertain value type has not been implemented, the number of parameters is  determined from the distribution and an instance of one of the following types is returned:    UncertainScalarTheoreticalOneParameter  UncertainScalarTheoreticalTwoParameter  UncertainScalarTheoreticalThreeParameter   Examples  1\n2\n3 UncertainValue ( Normal ( 0 ,   1 ))  UncertainValue ( Gamma ( 4 ,   5.1 ))  UncertainValue ( Binomial ,   8 ,   0.2 )    source", 
            "title": "From instances of distributions"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#defined_from_scratch", 
            "text": "Uncertain values represented by theoretical distributions may be constructed using the two-parameter or three-parameter constructors  UncertainValue ( d :: Type { D } ,   a : Number ,   b : Number )  or  UncertainValue ( d :: Type { D } ,   a : Number ,   b : Number ,   c : Number )  (see below). Parameters are provided to the constructor in the same order as for constructing  the equivalent distributions in  Distributions . jl .", 
            "title": "Defined from scratch"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#two-parameter_distributions", 
            "text": "#  UncertainData . UncertainValues . UncertainValue     Method .  1\n2 UncertainValue ( distribution :: Type { D },   a :: T1 ,   b :: T2 ; \n     kwargs ... )   where   { T1 : Number ,   T2   :   Number ,   D : Distribution }    Constructor for two-parameter distributions  UncertainValue s are currently implemented for the following two-parameter distributions:  Uniform ,  Normal ,  Binomial ,  Beta ,  BetaPrime ,  Gamma , and  Frechet .  Arguments   a ,  b : Generic parameters whose meaning varies depending   on what  distribution  is provided. See the list below.  distribution : A valid univariate distribution from  Distributions . jl .   Precisely what   a  and  b  are depends on which distribution is provided.   UncertainValue ( Normal ,   \u03bc ,   \u03c3 )  returns an  UncertainScalarNormallyDistributed  instance.  UncertainValue ( Uniform ,   lower ,   upper )  returns an  UncertainScalarUniformlyDistributed  instance.  UncertainValue ( Beta ,   \u03b1 ,   \u03b2 )  returns an  UncertainScalarBetaDistributed  instance.  UncertainValue ( BetaPrime ,   \u03b1 ,   \u03b2 )  returns an  UncertainScalarBetaPrimeDistributed  instance.  UncertainValue ( Gamma ,   \u03b1 ,   \u03b8 )  returns an  UncertainScalarGammaDistributed  instance.  UncertainValue ( Frechet ,   \u03b1 ,   \u03b8 )  returns an  UncertainScalarFrechetDistributed  instance.  UncertainValue ( Binomial ,   n ,   p )  returns an  UncertainScalarBinomialDistributed  instance.   Keyword arguments   n \u03c3 : If  distribution   :   Distributions . Normal , then how many standard   deviations away from  \u03bc  does  lower  and  upper  (i.e. both, because   they are the same distance away from  \u03bc ) represent?  tolerance : A threshold determining how symmetric the uncertainties   must be in order to allow the construction of  Normal distribution   ( upper   -   lower     threshold  is required).  trunc_lower : Lower truncation bound for distributions with infinite   support. Defaults to  - Inf .  trunc_upper : Upper truncation bound for distributions with infinite   support. Defaults to  Inf .   Examples  Normal distribution  Normal distributions are formed by using the constructor  UncertainValue ( \u03bc ,   \u03c3 ,   Normal ;   kwargs ...) . This gives a normal distribution with mean \u03bc and standard deviation \u03c3/n\u03c3 (n\u03c3 must be given as a keyword argument).  1\n2\n3\n4\n5\n6\n7\n8\n9 # A normal distribution with mean = 2.3 and standard deviation 0.3.  UncertainValue ( 2.3 ,   0.3 ,   Normal )  # A normal distribution with mean 2.3 and standard deviation 0.3/2.  UncertainValue ( 2.3 ,   0.3 ,   Normal ,   n\u03c3   =   2 )  # A normal distribution with mean 2.3 and standard deviation = 0.3,  truncated   to   the   interval   `[1, 3]` .  UncertainValue ( 2.3 ,   0.3 ,   Normal ,   trunc_lower   =   1.0 ,   trunc_upper   =   3.0 )    Uniform distribution  Uniform distributions are formed using the  UncertainValue ( lower ,   upper ,   Uniform )  constructor.  1\n2 #  A uniform distribution on `[2, 3]`  UncertainValue ( - 2 ,   3 ,   Uniform )    source", 
            "title": "Two-parameter distributions"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#three-parameter_distributions", 
            "text": "#  UncertainData . UncertainValues . UncertainValue     Method .  1\n2 UncertainValue ( distribution :: Type { D },   a :: T1 ,   b :: T2 ,   c :: T3 ; \n     kwargs ... )   where   { T1 : Number ,   T2 : Number ,   T3 : Number ,   D : Distribution }    Constructor for three-parameter distributions  Currently implemented distributions are  BetaBinomial .  Arguments   a ,  b ,  c : Generic parameters whose meaning varies depending   on what  distribution  is provided. See the list below.  distribution : A valid univariate distribution from  Distributions . jl .   Precisely what  a ,  b  and  c  are depends on which distribution is provided.   UncertainValue ( BetaBinomial ,   n ,   \u03b1 ,   \u03b2 )  returns an  UncertainScalarBetaBinomialDistributed  instance.   Keyword arguments   n \u03c3 : If  distribution   :   Distributions . Normal , then how many standard   deviations away from  \u03bc  does  lower  and  upper  (i.e. both, because   they are the same distance away from  \u03bc ) represent?  tolerance : A threshold determining how symmetric the uncertainties   must be in order to allow the construction of  Normal distribution   ( upper   -   lower     threshold  is required).  trunc_lower : Lower truncation bound for distributions with infinite   support. Defaults to  - Inf .  trunc_upper : Upper truncation bound for distributions with infinite   support. Defaults to  Inf .   Examples  BetaBinomial distribution  Normal distributions are formed by using the constructor  UncertainValue ( \u03bc ,   \u03c3 ,   Normal ;   kwargs ...) . This gives a normal distribution with mean \u03bc and standard deviation \u03c3/n\u03c3 (n\u03c3 must be given as a keyword argument).  1\n2\n3 # A beta binomial distribution with n = 100 trials and parameters \u03b1 = 2.3 and  # \u03b2 = 5  UncertainValue ( 100 ,   2.3 ,   5 ,   BetaBinomial )    source", 
            "title": "Three-parameter distributions"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#type_documentation", 
            "text": "#  UncertainData . UncertainValues . UncertainScalarBetaBinomialDistributed     Type .  Uncertain value represented by a beta binomial distribution.  source  #  UncertainData . UncertainValues . UncertainScalarBetaDistributed     Type .  Uncertain value represented by a beta distribution.  source  #  UncertainData . UncertainValues . UncertainScalarBetaPrimeDistributed     Type .  Uncertain value represented by a beta prime distribution.  source  #  UncertainData . UncertainValues . UncertainScalarBinomialDistributed     Type .  Uncertain value represented by a binomial distribution.  source  #  UncertainData . UncertainValues . UncertainScalarFrechetDistributed     Type .  Uncertain value represented by a Fr\u00e9chet distribution.  source  #  UncertainData . UncertainValues . UncertainScalarGammaDistributed     Type .  Uncertain value represented by a gamma distribution.  source  #  UncertainData . UncertainValues . UncertainScalarNormallyDistributed     Type .  Uncertain value represented by a normal distribution.  source  #  UncertainData . UncertainValues . UncertainScalarUniformlyDistributed     Type .  Uncertain value represented by a uniform distribution.  source", 
            "title": "Type documentation"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#list_of_supported_distributions", 
            "text": "Supported distributions are:   Uniform  Normal  Gamma  Beta  BetaPrime  Frechet  Binomial  BetaBinomial   More distributions will be added in the future!.", 
            "title": "List of supported distributions"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#examples", 
            "text": "Uniform  1\n2 # Uncertain value generated by a uniform distribution on [-5.0, 5.1].  uv   =   UncertainValue ( Uniform ,   - 5.0 ,   5.1 )     Normal  1\n2\n3 # Uncertain value generated by a normal distribution with parameters \u03bc = -2 and  # \u03c3 = 0.5.  uv   =   UncertainValue ( Normal ,   - 2 ,   0.5 )     Gamma  1\n2\n3 # Uncertain value generated by a gamma distribution with parameters \u03b1 = 2.2  # and \u03b8 = 3.  uv   =   UncertainValue ( Gamma ,   2.2 ,   3 )     Beta  1\n2\n3 # Uncertain value generated by a beta distribution with parameters \u03b1 = 1.5  # and \u03b2 = 3.5  uv   =   UncertainValue ( Beta ,   1.5 ,   3.5 )     BetaPrime  1\n2\n3 # Uncertain value generated by a beta prime distribution with parameters \u03b1 = 1.7  # and \u03b2 = 3.2  uv   =   UncertainValue ( Beta ,   1.7 ,   3.2 )     Fr\u00e9chet  1\n2\n3 # Uncertain value generated by a Fr\u00e9chet distribution with parameters \u03b1 = 2.1  # and \u03b8 = 4  uv   =   UncertainValue ( Beta ,   2.1 ,   4 )     Binomial  1\n2\n3 # Uncertain value generated by binomial distribution with n = 28 trials and  # probability p = 0.2 of success in individual trials.  uv   =   UncertainValue ( Binomial ,   28 ,   0.2 )     BetaBinomial  1\n2\n3 # Creates an uncertain value generated by a beta-binomial distribution with  # n = 28 trials, and parameters \u03b1 = 1.5 and \u03b2 = 3.5.  uv   =   UncertainValue ( BetaBinomial ,   28 ,   3.3 ,   4.4 )", 
            "title": "Examples"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_fitted/", 
            "text": "For data values with histograms close to some known distribution, the user may choose to represent the data by fitting a theoretical distribution to the values. This will only work well if the histogram closely resembles a theoretical distribution.\n\n\n\n\nGeneric constructor\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainValue\n \n \nMethod\n.\n\n\n1\n2\nUncertainValue\n(\nempiricaldata\n::\nAbstractVector\n{\nT\n},\n\n    \nd\n::\nType\n{\nD\n})\n \nwhere\n \n{\nD\n \n:\n \nDistribution\n}\n\n\n\n\n\n\n\nConstructor for empirical distributions.\n\n\nFit a distribution of type \nd\n to the data and use that as the representation of the empirical distribution. Calls \nDistributions\n.\nfit\n behind the scenes.\n\n\nArguments\n\n\n\n\nempiricaldata\n: The data for which to fit the \ndistribution\n.\n\n\ndistribution\n: A valid univariate distribution from \nDistributions\n.\njl\n.\n\n\n\n\nsource\n\n\n\n\nType documentation\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarTheoreticalFit\n \n \nType\n.\n\n\nUncertainScalarTheoreticalFit\n\n\nAn empirical value represented by a distribution estimated from actual data.\n\n\nFields\n\n\n\n\ndistribution\n The distribution describing the value.\n\n\nvalues\n: The values from which \ndistribution\n is estimated.\n\n\n\n\nsource\n\n\n\n\nExamples\n\n\n\n\n\n\nUniform\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nUniform\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Define an uncertain value by fitting a uniform distribution to the sample.\n\n\nuv\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nNormal\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Represent the uncertain value by a fitted normal distribution.\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nGamma\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,\n\n\n# \u03b8 = 5.2.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(\n2.1\n,\n \n5.2\n),\n \n1000\n)\n\n\n\n# Represent the uncertain value by a fitted gamma distribution.\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nIn these examples we're trying to fit the same distribution to our sample as the distribution from which we draw the sample. Thus, we will get good fits. In real applications, make sure to always visually investigate the histogram of your data!\n\n\n\n\nBeware: fitting distributions may lead to nonsensical results!\n\n\nIn a less contrived example, we may try to fit a beta distribution to a sample generated from a gamma distribution.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,\n\n\n# \u03b8 = 5.2.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(\n2.1\n,\n \n5.2\n),\n \n1000\n)\n\n\n\n# Represent the uncertain value by a fitted beta distribution.\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\nThis is obviously not a good idea. Always visualise your distribution before deciding on which distribution to fit! You won't get any error messages if you try to fit a distribution that does not match your data.\n\n\nIf the data do not follow an obvious theoretical distribution, it is better to use kernel density estimation to define the uncertain value.", 
            "title": "Theoretical distributions with fitted parameters"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_fitted/#generic_constructor", 
            "text": "#  UncertainData . UncertainValues . UncertainValue     Method .  1\n2 UncertainValue ( empiricaldata :: AbstractVector { T }, \n     d :: Type { D })   where   { D   :   Distribution }    Constructor for empirical distributions.  Fit a distribution of type  d  to the data and use that as the representation of the empirical distribution. Calls  Distributions . fit  behind the scenes.  Arguments   empiricaldata : The data for which to fit the  distribution .  distribution : A valid univariate distribution from  Distributions . jl .   source", 
            "title": "Generic constructor"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_fitted/#type_documentation", 
            "text": "#  UncertainData . UncertainValues . UncertainScalarTheoreticalFit     Type .  UncertainScalarTheoreticalFit  An empirical value represented by a distribution estimated from actual data.  Fields   distribution  The distribution describing the value.  values : The values from which  distribution  is estimated.   source", 
            "title": "Type documentation"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_fitted/#examples", 
            "text": "Uniform   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Create a normal distribution  d   =   Uniform ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Define an uncertain value by fitting a uniform distribution to the sample.  uv   =   UncertainValue ( Uniform ,   some_sample )     Normal   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Represent the uncertain value by a fitted normal distribution.  uv   =   UncertainValue ( Normal ,   some_sample )     Gamma  1\n2\n3\n4\n5\n6\n7\n8 using   Distributions ,   UncertainData  # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,  # \u03b8 = 5.2.  some_sample   =   rand ( Gamma ( 2.1 ,   5.2 ),   1000 )  # Represent the uncertain value by a fitted gamma distribution.  uv   =   UncertainValue ( Gamma ,   some_sample )     In these examples we're trying to fit the same distribution to our sample as the distribution from which we draw the sample. Thus, we will get good fits. In real applications, make sure to always visually investigate the histogram of your data!", 
            "title": "Examples"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_fitted/#beware_fitting_distributions_may_lead_to_nonsensical_results", 
            "text": "In a less contrived example, we may try to fit a beta distribution to a sample generated from a gamma distribution.  1\n2\n3\n4\n5\n6\n7\n8 using   Distributions ,   UncertainData  # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,  # \u03b8 = 5.2.  some_sample   =   rand ( Gamma ( 2.1 ,   5.2 ),   1000 )  # Represent the uncertain value by a fitted beta distribution.  uv   =   UncertainValue ( Beta ,   some_sample )    This is obviously not a good idea. Always visualise your distribution before deciding on which distribution to fit! You won't get any error messages if you try to fit a distribution that does not match your data.  If the data do not follow an obvious theoretical distribution, it is better to use kernel density estimation to define the uncertain value.", 
            "title": "Beware: fitting distributions may lead to nonsensical results!"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_populations/", 
            "text": "The \nUncertainScalarPopulation\n type allows representation of an uncertain scalar  represented by a population of values who will be sampled according to a vector of  explicitly provided probabilities. Think of it as an explicit kernel density estimate. \n\n\n\n\nGeneric constructor\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainValue\n \n \nMethod\n.\n\n\n1\nUncertainValue\n(\nvalues\n::\nVector\n,\n \nprobs\n::\nUnion\n{\nVector\n,\n \nAbstractWeights\n})\n\n\n\n\n\n\n\nConstruct a population whose members are given by \nvalues\n and whose sampling  probabilities are given by \nprobs\n. The elements of \nvalues\n can be either  numeric or uncertain values of any type.\n\n\nsource\n\n\n\n\nType documentation\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainScalarPopulation\n \n \nType\n.\n\n\n1\n2\n3\nUncertainScalarPopulation\n(\nvalues\n,\n \nprobs\n)\n\n\nUncertainScalarPopulation\n(\nvalues\n,\n \nprobs\n::\nVector\n{\nNumber\n})\n\n\nUncertainScalarPopulation\n(\nvalues\n,\n \nprobs\n::\nStatsbase\n.\nAbstractWeights\n)\n\n\n\n\n\n\n\nAn \nUncertainScalarPopulation\n, which consists of some population members (\nvalues\n) and some weights (\nprobs\n) that indicate the relative importance of the  population members (for example during resampling). \n\n\nFields\n\n\n\n\nvalues\n: The members of the population. Can be either numerical values, any   type of uncertain value defined in this package (including populations), and   \nMeasurement\n instances from Measurements.jl.\n\n\nprobs\n: The probabilities of sampling each member of the population.\n\n\n\n\nConstructors\n\n\n\n\nIf \nvalues\n contains only scalar numeric values, then the \nvalues\n field    will be of type \nVector\n{\nNumber\n}\n.\n\n\nIf \nvalues\n contains one or more uncertain values, then the \nvalues\n field    will be of type \nVector\n{\nAbstractUncertainValue\n}\n\n\n\n\nExample\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n# Uncertain population consisting of CertainValues (scalars get promoted to \n\n\n# CertainValue), theoretical distributions and KDE distributions\n\n\npop1\n \n=\n \nUncertainScalarPopulation\n(\n\n    \n[\n3.0\n,\n \nUncertainValue\n(\nNormal\n,\n \n0\n,\n \n1\n),\n \nUncertainValue\n(\nGamma\n,\n \n2\n,\n \n3\n),\n \n    \nUncertainValue\n(\nUniform\n,\n \nrand\n(\n1000\n))],\n \n[\n0.5\n,\n \n0.5\n,\n \n0.5\n,\n \n0.5\n])\n\n\n\n# Uncertain population consisting of scalar values\n\n\npop2\n \n=\n \nUncertainScalarPopulation\n([\n1\n,\n \n2\n,\n \n3\n],\n \nrand\n(\n3\n))\n\n\npop3\n \n=\n \nUncertainScalarPopulation\n([\n1\n,\n \n2\n,\n \n3\n],\n \nWeights\n(\nrand\n(\n3\n)))\n\n\n\n# Uncertain population consisting of uncertain populations\n\n\npop4\n \n=\n \nUncertainScalarPopulation\n([\npop1\n,\n \npop2\n],\n \n[\n0.1\n,\n \n0.5\n])\n\n\n\n# Uncertain population consisting of uncertain populations, a scalar and \n\n\n# a normal distribution. Assign random weights.\n\n\nvals\n \n=\n \n[\npop1\n,\n \npop2\n,\n \n2\n,\n \nUncertainValue\n(\nNormal\n,\n \n0.3\n,\n \n0.014\n)]\n\n\npop5\n \n=\n \nUncertainScalarPopulation\n(\nvals\n,\n \nWeights\n(\nrand\n(\n4\n)))\n\n\n\n\n\n\n\nsource", 
            "title": "Weighted (nested) populations"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_populations/#generic_constructor", 
            "text": "#  UncertainData . UncertainValues . UncertainValue     Method .  1 UncertainValue ( values :: Vector ,   probs :: Union { Vector ,   AbstractWeights })    Construct a population whose members are given by  values  and whose sampling  probabilities are given by  probs . The elements of  values  can be either  numeric or uncertain values of any type.  source", 
            "title": "Generic constructor"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_populations/#type_documentation", 
            "text": "#  UncertainData . UncertainValues . UncertainScalarPopulation     Type .  1\n2\n3 UncertainScalarPopulation ( values ,   probs )  UncertainScalarPopulation ( values ,   probs :: Vector { Number })  UncertainScalarPopulation ( values ,   probs :: Statsbase . AbstractWeights )    An  UncertainScalarPopulation , which consists of some population members ( values ) and some weights ( probs ) that indicate the relative importance of the  population members (for example during resampling).   Fields   values : The members of the population. Can be either numerical values, any   type of uncertain value defined in this package (including populations), and    Measurement  instances from Measurements.jl.  probs : The probabilities of sampling each member of the population.   Constructors   If  values  contains only scalar numeric values, then the  values  field    will be of type  Vector { Number } .  If  values  contains one or more uncertain values, then the  values  field    will be of type  Vector { AbstractUncertainValue }   Example   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 # Uncertain population consisting of CertainValues (scalars get promoted to   # CertainValue), theoretical distributions and KDE distributions  pop1   =   UncertainScalarPopulation ( \n     [ 3.0 ,   UncertainValue ( Normal ,   0 ,   1 ),   UncertainValue ( Gamma ,   2 ,   3 ),  \n     UncertainValue ( Uniform ,   rand ( 1000 ))],   [ 0.5 ,   0.5 ,   0.5 ,   0.5 ])  # Uncertain population consisting of scalar values  pop2   =   UncertainScalarPopulation ([ 1 ,   2 ,   3 ],   rand ( 3 ))  pop3   =   UncertainScalarPopulation ([ 1 ,   2 ,   3 ],   Weights ( rand ( 3 )))  # Uncertain population consisting of uncertain populations  pop4   =   UncertainScalarPopulation ([ pop1 ,   pop2 ],   [ 0.1 ,   0.5 ])  # Uncertain population consisting of uncertain populations, a scalar and   # a normal distribution. Assign random weights.  vals   =   [ pop1 ,   pop2 ,   2 ,   UncertainValue ( Normal ,   0.3 ,   0.014 )]  pop5   =   UncertainScalarPopulation ( vals ,   Weights ( rand ( 4 )))    source", 
            "title": "Type documentation"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_certainvalue/", 
            "text": "The \nCertainValue\n allows representation of values with no uncertainty. It behaves  just as a scalar, but can be mixed with uncertain values when performing  \nmathematical operations\n and  \nresampling\n. \n\n\n\n\nGeneric constructor\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nUncertainValue\n \n \nMethod\n.\n\n\n1\nUncertainValue\n(\nx\n::\nT\n)\n \nwhere\n \nT\n \n:\n \nReal\n\n\n\n\n\n\n\nCreate a \nCertainValue\n instance from a scalar with no uncertainty.\n\n\nsource\n\n\n\n\nType documentation\n\n\n#\n\n\nUncertainData\n.\nUncertainValues\n.\nCertainValue\n \n \nType\n.\n\n\n1\nCertainValue\n\n\n\n\n\n\n\nA simple wrapper type for values with no uncertainty (i.e. represented by a scalar).\n\n\nExamples\n\n\nThe two following ways of constructing values without uncertainty are equivalent. \n\n\n1\n2\nu1\n,\n \nu2\n \n=\n \nCertainValue\n(\n2.2\n),\n \nCertainValue\n(\n6\n)\n\n\nw1\n,\n \nw2\n \n=\n \nUncertainValue\n(\n2.2\n),\n \nUncertainValue\n(\n6\n)\n\n\n\n\n\n\n\nsource", 
            "title": "Values without uncertainty"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_certainvalue/#generic_constructor", 
            "text": "#  UncertainData . UncertainValues . UncertainValue     Method .  1 UncertainValue ( x :: T )   where   T   :   Real    Create a  CertainValue  instance from a scalar with no uncertainty.  source", 
            "title": "Generic constructor"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_certainvalue/#type_documentation", 
            "text": "#  UncertainData . UncertainValues . CertainValue     Type .  1 CertainValue    A simple wrapper type for values with no uncertainty (i.e. represented by a scalar).  Examples  The two following ways of constructing values without uncertainty are equivalent.   1\n2 u1 ,   u2   =   CertainValue ( 2.2 ),   CertainValue ( 6 )  w1 ,   w2   =   UncertainValue ( 2.2 ),   UncertainValue ( 6 )    source", 
            "title": "Type documentation"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_Measurements/", 
            "text": "Measurement\n instances from \nMeasurements.jl\n1\n are  treated as normal distributions with known means. \nNote: once you convert a measurement, you lose the  functionality provided by Measurements.jl, such as exact error propagation\n.\n\n\n\n\nGeneric constructor\n\n\nIf \nx\n \n=\n \nmeasurement\n(\n2\n.\n2\n,\n \n0\n.\n21\n)\n is a measurement, then \nUncertainValue\n(\nx\n)\n will return an \nUncertainScalarNormallyDistributed\n instance.\n\n\n\n\nReferences\n\n\n\n\n\n\n\n\n\n\nM. Giordano, 2016, \"Uncertainty propagation with functionally correlated quantities\", arXiv:1610.08716 (Bibcode: 2016arXiv161008716G).", 
            "title": "Measurements"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_Measurements/#generic_constructor", 
            "text": "If  x   =   measurement ( 2 . 2 ,   0 . 21 )  is a measurement, then  UncertainValue ( x )  will return an  UncertainScalarNormallyDistributed  instance.", 
            "title": "Generic constructor"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_Measurements/#references", 
            "text": "M. Giordano, 2016, \"Uncertainty propagation with functionally correlated quantities\", arXiv:1610.08716 (Bibcode: 2016arXiv161008716G).", 
            "title": "References"
        }, 
        {
            "location": "/uncertain_values/merging/", 
            "text": "Because all uncertainties are handled using a resampling approach, it is trivial to  \ncombine\n or merge uncertain values of different types into a single uncertain value.\n\n\n\n\nNomenclature\n\n\nDepending on your data, you may want to choose of one the following ways of  representing multiple uncertain values as one:\n\n\n\n\nCombining\n. An ensemble of uncertain    values is represented as a weighted population. This approach is nice if you want    to impose expert-opinion on the relative sampling probabilities of uncertain    values in the ensemble, but still sample from the entire supports of each of the   furnishing values. This introduces no additional approximations besides what    is already present at the moment you define your uncertain values.\n\n\nMerging\n. Multiple uncertain values are merged using    a kernel density estimate to the overall distribution. This approach introduces    approximations \nbeyond\n what is present in the uncertain values when you define them.\n\n\n\n\n\n\nCombining uncertain values: the population approach\n\n\nCombining\n uncertain values is done by representing them as a weighted population of uncertain values, which is illustrated in the following example:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n# Assume we have done some analysis and have three points whose uncertainties \n\n\n# significantly overlap.\n\n\nv1\n \n=\n \nUncertainValue\n(\nNormal\n(\n0.13\n,\n \n0.52\n))\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n(\n0.27\n,\n \n0.42\n))\n\n\nv3\n \n=\n \nUncertainValue\n(\nNormal\n(\n0.21\n,\n \n0.61\n))\n\n\n\n# Give each value equal sampling probabilities and represent as a population\n\n\npop\n \n=\n \nUncertainValue\n([\nv1\n,\n \nv2\n,\n \nv3\n],\n \n[\n1\n,\n \n1\n,\n \n1\n])\n\n\n\n# Let the values v1, v2 and v3 be sampled with probability ratios 1-2-3\n\n\npop\n \n=\n \nUncertainValue\n([\nv1\n,\n \nv2\n,\n \nv3\n],\n \n[\n1\n,\n \n2\n,\n \n3\n])\n\n\n\n\n\n\n\n\n\nThis is not restricted to normal distributions! We can combine any type of  value in our population, even populations!\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n# Consider a population of normal distributions, and a gamma distribution\n\n\nv1\n \n=\n \nUncertainValue\n(\nNormal\n(\n0.265\n,\n \n0.52\n))\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n(\n0.311\n,\n \n0.15\n))\n\n\nv3\n \n=\n \nUncertainValue\n([\nv1\n,\n \nv2\n],\n \n[\n2\n,\n \n1\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nGamma\n(\n0.5\n,\n \n-\n1\n))\n\n\npts\n \n=\n \n[\nv1\n,\n \nv4\n]\n\n\nwts\n \n=\n \n[\n2\n,\n \n1\n]\n\n\n\n# New population is a nested population with unequal weights\n\n\npop\n \n=\n \nUncertainValue\n(\npts\n,\n \nwts\n)\n\n\n\nd1\n \n=\n \ndensity\n(\nresample\n(\npop\n,\n \n20000\n),\n \nlabel\n \n=\n \npopulation\n)\n\n\n\nd2\n \n=\n \nplot\n()\n\n\ndensity!\n(\nd2\n,\n \nresample\n(\npop\n[\n1\n],\n \n20000\n),\n \nlabel\n \n=\n \nv1\n)\n\n\ndensity!\n(\nd2\n,\n \nresample\n(\npop\n[\n2\n],\n \n20000\n),\n \nlabel\n \n=\n \nv2\n)\n\n\n\nplot\n(\nd1\n,\n \nd2\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nxlabel\n \n=\n \nValue\n,\n \nylabel\n \n=\n \nDensity\n,\n \nlink\n \n=\n \n:\nx\n,\n \nxlims\n \n=\n \n(\n-\n2.5\n,\n \n2.5\n))\n\n\n\n\n\n\n\n\n\nThis makes it possible treat an ensemble of uncertain values as a single uncertain value.\n\n\nWith equal weights, this introduces no bias beyond what is present in the data,  because resampling is done from the full supports of each of the furnishing values.  Additional information on relative sampling probabilities, however, be it informed by expert opinion or quantative estimates, is easily incorporated by adjusting  the sampling weights.\n\n\n\n\nMerging uncertain values: the kernel density estimation (KDE) approach\n\n\nMerging\n multiple uncertain values could be done by fitting a model distribution to  the values. Using any specific theoretical distribution as a model for the combined  uncertainty, however, is in general not possible, because the values may have  different types of uncertainties.\n\n\nThus, in this package, kernel kernel density estimation is used to merge multiple uncertain values.  This has the advantage that you only have to deal with a single estimate to the combined  distribution, but introduces bias because the distribution is \nestimated\n and the  shape of the distribution depends on the parameters of the KDE procedure.\n\n\n\n\nWithout weights\n\n\nWhen no weights are provided, the combined value is computed  by resampling each of the \nN\n uncertain values \nn\n/\nN\n times, then combining using kernel density estimation. \n\n\n#\n\n\nUncertainData\n.\ncombine\n \n \nMethod\n.\n\n\n1\n2\ncombine\n(\nuvals\n::\nVector\n{\nAbstractUncertainValue\n};\n \nn\n \n=\n \n10000\n*\nlength\n(\nuvals\n),\n \n    \nbw\n::\nUnion\n{\nNothing\n,\n \nReal\n}\n \n=\n \nnothing\n)\n\n\n\n\n\n\n\nCombine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in \nuvals\n, \nn\n times  each,  then pooling these draws together. Finally, a kernel density estimate to the final distribution is computed over those draws. \n\n\nThe KDE bandwidth is controlled by \nbw\n. By default, \nbw\n \n=\n \nnothing\n; in this case,  the bandwidth is determined using the \nKernelDensity\n.\ndefault_bandwidth\n function.\n\n\n\n\nTip\n\n\nFor very wide, close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.\n\n\n\n\nExample\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nv1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1\n,\n \n0.3\n)\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n3.7\n,\n \n0.8\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n];\n\n\n\ncombine\n(\nuvals\n)\n\n\ncombine\n(\nuvals\n,\n \nn\n \n=\n \n20000\n)\n \n# adjust number of total draws\n\n\n\n\n\n\n\nsource\n\n\nWeights dictating the relative contribution of each  uncertain value into the combined value can also be provided. \ncombine\n works  with \nProbabilityWeights\n, \nAnalyticWeights\n,  \nFrequencyWeights\n and the generic \nWeights\n. \n\n\nBelow shows an example of combining \n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nv1\n \n=\n \nUncertainValue\n(\nrand\n(\n1000\n))\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n3.7\n,\n \n0.8\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n]\n\n\n\np\n \n=\n \nplot\n(\ntitle\n \n=\n \nL\ndistributions \\,\\, with \\,\\, overlapping \\,\\, supports\n)\n\n\nplot!\n(\nv1\n,\n \nlabel\n \n=\n \nL\nv_1\n,\n \nls\n \n=\n \n:\ndash\n)\n\n\nplot!\n(\nv2\n,\n \nlabel\n \n=\n \nL\nv_2\n,\n \nls\n \n=\n \n:\ndot\n)\n\n\nvline!\n(\nv3\n.\nvalues\n,\n \nlabel\n \n=\n \nL\nv_3\n)\n \n# plot each possible state as vline\n\n\nplot!\n(\nv4\n,\n \nlabel\n \n=\n \nL\nv_4\n)\n\n\n\npcombined\n \n=\n \nplot\n(\ncombine\n(\nuvals\n),\n \ntitle\n \n=\n \nL\nmerge(v_1, v_2, v_3, v_4)\n,\n \nlc\n \n=\n \n:\nblack\n,\n \nlw\n \n=\n \n2\n)\n\n\n\nplot\n(\np\n,\n \npcombined\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nx\n,\n \nylabel\n \n=\n \nDensity\n)\n\n\n\n\n\n\n\n\n\n\n\nWith weights\n\n\nWeights\n, \nProbabilityWeights\n and  \nAnalyticWeights\n are functionally the same. Either  may be used depending on whether the weights are assigned subjectively or quantitatively.  With \nFrequencyWeights\n, it is possible to control the exact number of draws from each  uncertain value that goes into the draw pool before performing KDE.\n\n\n\n\nProbabilityWeights\n\n\n#\n\n\nUncertainData\n.\ncombine\n \n \nMethod\n.\n\n\n1\n2\n3\ncombine\n(\nuvals\n::\nVector\n{\nAbstractUncertainValue\n},\n \nweights\n::\nProbabilityWeights\n;\n \n    \nn\n \n=\n \n10000\n*\nlength\n(\nuvals\n),\n \n    \nbw\n::\nUnion\n{\nNothing\n,\n \nReal\n}\n \n=\n \nnothing\n)\n\n\n\n\n\n\n\nCombine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in \nuvals\n proportionally to the provided  relative analytic \nweights\n indicating their relative importance (these are normalised by  default, so don't need to sum to 1), then pooling these draws together. Finally, a kernel  density estimate to the final distribution is computed over the \nn\n total draws.\n\n\nProviding \nProbabilityWeights\n leads to the exact same behaviour as for \nAnalyticWeights\n,  but may be more appropriote when, for example, weights have been determined  quantitatively. \n\n\nThe KDE bandwidth is controlled by \nbw\n. By default, \nbw\n \n=\n \nnothing\n; in this case,  the bandwidth is determined using the \nKernelDensity\n.\ndefault_bandwidth\n function.\n\n\n\n\nTip\n\n\nFor very wide, close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.\n\n\n\n\nExample\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nv1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1\n,\n \n0.3\n)\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n3.7\n,\n \n0.8\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n];\n\n\n\n# Two difference syntax options\n\n\ncombine\n(\nuvals\n,\n \nProbabilityWeights\n([\n0.2\n,\n \n0.1\n,\n \n0.3\n,\n \n0.2\n]))\n\n\ncombine\n(\nuvals\n,\n \npweights\n([\n0.2\n,\n \n0.1\n,\n \n0.3\n,\n \n0.2\n]),\n \nn\n \n=\n \n20000\n)\n \n# adjust number of total draws\n\n\n\n\n\n\n\nsource\n\n\nFor example:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\nv1\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nrand\n(\n4\n:\n0.25\n:\n6\n,\n \n1000\n),\n \nbandwidth\n \n=\n \n0.02\n)\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n8\n,\n \n0.4\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n];\n\n\n\np\n \n=\n \nplot\n(\ntitle\n \n=\n \nL\ndistributions \\,\\, with \\,\\, overlapping \\,\\, supports\n)\n\n\nplot!\n(\nv1\n,\n \nlabel\n \n=\n \nL\nv_1: KDE \\, over \\, empirical \\, distribution\n,\n \nls\n \n=\n \n:\ndash\n)\n\n\nplot!\n(\nv2\n,\n \nlabel\n \n=\n \nL\nv_2: Normal(0.8, 0.4)\n,\n \nls\n \n=\n \n:\ndot\n)\n\n\n# plot each possible state as vline\n\n\nvline!\n(\nv3\n.\nvalues\n,\n \n    \nlabel\n \n=\n \nL\nv_3: \\, Discrete \\, population\\, [1,2,3], w/ \\, weights \\, [0.3, 0.4, 0.4]\n)\n \n\nplot!\n(\nv4\n,\n \nlabel\n \n=\n \nL\nv_4: \\, Gamma(8, 0.4)\n)\n\n\n\npcombined\n \n=\n \nplot\n(\n\n    \ncombine\n(\nuvals\n,\n \nProbabilityWeights\n([\n0.1\n,\n \n0.3\n,\n \n0.02\n,\n \n0.5\n]),\n \nn\n \n=\n \n100000\n,\n \nbw\n \n=\n \n0.05\n),\n \n    \ntitle\n \n=\n \nL\ncombine([v_1, v_2, v_3, v_4], ProbabilityWeights([0.1, 0.3, 0.02, 0.5])\n,\n \n    \nlc\n \n=\n \n:\nblack\n,\n \nlw\n \n=\n \n2\n)\n\n\n\nplot\n(\np\n,\n \npcombined\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nsize\n \n=\n \n(\n800\n,\n \n600\n),\n \n    \nlink\n \n=\n \n:\nx\n,\n \n    \nylabel\n \n=\n \nDensity\n,\n\n    \ntickfont\n \n=\n \nfont\n(\n12\n),\n\n    \nlegendfont\n \n=\n \nfont\n(\n8\n),\n \nfg_legend\n \n=\n \n:\ntransparent\n,\n \nbg_legend\n \n=\n \n:\ntransparent\n)\n\n\n\n\n\n\n\n\n\n\n\nAnalyticWeights\n\n\n#\n\n\nUncertainData\n.\ncombine\n \n \nMethod\n.\n\n\n1\n2\n3\ncombine\n(\nuvals\n::\nVector\n{\nAbstractUncertainValue\n},\n \nweights\n::\nAnalyticWeights\n;\n \n    \nn\n \n=\n \n10000\n*\nlength\n(\nuvals\n),\n \n    \nbw\n::\nUnion\n{\nNothing\n,\n \nReal\n}\n \n=\n \nnothing\n)\n\n\n\n\n\n\n\nCombine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in \nuvals\n proportionally to the provided  relative probability \nweights\n (these are normalised by default, so don't need  to sum to 1), then pooling these draws together. Finally, a kernel density  estimate to the final distribution is computed over the \nn\n total draws.\n\n\nProviding \nAnalyticWeights\n leads to the exact same behaviour as for \nProbabilityWeights\n, but may be more appropriote when relative importance weights are assigned subjectively,  and not based on quantitative evidence.\n\n\nThe KDE bandwidth is controlled by \nbw\n. By default, \nbw\n \n=\n \nnothing\n; in this case,  the bandwidth is determined using the \nKernelDensity\n.\ndefault_bandwidth\n function.\n\n\n\n\nTip\n\n\nFor very wide, close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.\n\n\n\n\nExample\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nv1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1\n,\n \n0.3\n)\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n3.7\n,\n \n0.8\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n];\n\n\n\n# Two difference syntax options\n\n\ncombine\n(\nuvals\n,\n \nAnalyticWeights\n([\n0.2\n,\n \n0.1\n,\n \n0.3\n,\n \n0.2\n]))\n\n\ncombine\n(\nuvals\n,\n \naweights\n([\n0.2\n,\n \n0.1\n,\n \n0.3\n,\n \n0.2\n]),\n \nn\n \n=\n \n20000\n)\n \n# adjust number of total draws\n\n\n\n\n\n\n\nsource\n\n\nFor example:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nv1\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nrand\n(\n4\n:\n0.25\n:\n6\n,\n \n1000\n),\n \nbandwidth\n \n=\n \n0.02\n)\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n8\n,\n \n0.4\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n];\n\n\n\np\n \n=\n \nplot\n(\ntitle\n \n=\n \nL\ndistributions \\,\\, with \\,\\, overlapping \\,\\, supports\n)\n\n\nplot!\n(\nv1\n,\n \nlabel\n \n=\n \nL\nv_1: KDE \\, over \\, empirical \\, distribution\n,\n \nls\n \n=\n \n:\ndash\n)\n\n\nplot!\n(\nv2\n,\n \nlabel\n \n=\n \nL\nv_2: Normal(0.8, 0.4)\n,\n \nls\n \n=\n \n:\ndot\n)\n\n\nvline!\n(\nv3\n.\nvalues\n,\n \nlabel\n \n=\n \nL\nv_3: \\, Discrete \\, population\\, [1,2,3], w/ \\, weights \\, [0.3, 0.4, 0.4]\n)\n \n# plot each possible state as vline\n\n\nplot!\n(\nv4\n,\n \nlabel\n \n=\n \nL\nv_4: \\, Gamma(8, 0.4)\n)\n\n\n\npcombined\n \n=\n \nplot\n(\ncombine\n(\nuvals\n,\n \nAnalyticWeights\n([\n0.1\n,\n \n0.3\n,\n \n0.02\n,\n \n0.5\n]),\n \nn\n \n=\n \n100000\n,\n \nbw\n \n=\n \n0.05\n),\n \n    \ntitle\n \n=\n \nL\ncombine([v_1, v_2, v_3, v_4], AnalyticWeights([0.1, 0.3, 0.02, 0.5])\n,\n \nlc\n \n=\n \n:\nblack\n,\n \nlw\n \n=\n \n2\n)\n\n\n\nplot\n(\np\n,\n \npcombined\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nsize\n \n=\n \n(\n800\n,\n \n600\n),\n \n    \nlink\n \n=\n \n:\nx\n,\n \n    \nylabel\n \n=\n \nDensity\n,\n\n    \ntickfont\n \n=\n \nfont\n(\n12\n),\n\n    \nlegendfont\n \n=\n \nfont\n(\n8\n),\n \nfg_legend\n \n=\n \n:\ntransparent\n,\n \nbg_legend\n \n=\n \n:\ntransparent\n)\n\n\n\n\n\n\n\n\n\n\n\nGeneric Weights\n\n\n#\n\n\nUncertainData\n.\ncombine\n \n \nMethod\n.\n\n\n1\n2\n3\ncombine\n(\nuvals\n::\nVector\n{\nAbstractUncertainValue\n},\n \nweights\n::\nWeights\n;\n \n    \nn\n \n=\n \n10000\n*\nlength\n(\nuvals\n),\n \n    \nbw\n::\nUnion\n{\nNothing\n,\n \nReal\n}\n \n=\n \nnothing\n)\n\n\n\n\n\n\n\nCombine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in \nuvals\n proportionally to the provided \nweights\n  (these are normalised by default, so don't need to sum to 1), then pooling these draws  together. Finally, a kernel density estimate to the final distribution is computed over  the \nn\n total draws.\n\n\nProviding \nWeights\n leads to the exact same behaviour as for \nProbabilityWeights\n and  \nAnalyticalWeights\n.\n\n\nThe KDE bandwidth is controlled by \nbw\n. By default, \nbw\n \n=\n \nnothing\n; in this case,  the bandwidth is determined using the \nKernelDensity\n.\ndefault_bandwidth\n function.\n\n\n\n\nTip\n\n\nFor very wide, close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.\n\n\n\n\nExample\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nv1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1\n,\n \n0.3\n)\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n3.7\n,\n \n0.8\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n];\n\n\n\n# Two difference syntax options\n\n\ncombine\n(\nuvals\n,\n \nWeights\n([\n0.2\n,\n \n0.1\n,\n \n0.3\n,\n \n0.2\n]))\n\n\ncombine\n(\nuvals\n,\n \nweights\n([\n0.2\n,\n \n0.1\n,\n \n0.3\n,\n \n0.2\n]),\n \nn\n \n=\n \n20000\n)\n \n# adjust number of total draws\n\n\n\n\n\n\n\nsource\n\n\nFor example:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\nv1\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nrand\n(\n4\n:\n0.25\n:\n6\n,\n \n1000\n),\n \nbandwidth\n \n=\n \n0.01\n)\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n8\n,\n \n0.4\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n];\n\n\n\np\n \n=\n \nplot\n(\ntitle\n \n=\n \nL\ndistributions \\,\\, with \\,\\, overlapping \\,\\, supports\n)\n\n\nplot!\n(\nv1\n,\n \nlabel\n \n=\n \nL\nv_1: KDE \\, over \\, empirical \\, distribution\n,\n \nls\n \n=\n \n:\ndash\n)\n\n\nplot!\n(\nv2\n,\n \nlabel\n \n=\n \nL\nv_2: Normal(0.8, 0.4)\n,\n \nls\n \n=\n \n:\ndot\n)\n\n\n# plot each possible state as vline\n\n\nvline!\n(\nv3\n.\nvalues\n,\n \n    \nlabel\n \n=\n \nL\nv_3: \\, Discrete \\, population\\, [1,2,3], w/ \\, weights \\, [0.3, 0.4, 0.4]\n)\n \n\nplot!\n(\nv4\n,\n \nlabel\n \n=\n \nL\nv_4: \\, Gamma(8, 0.4)\n)\n\n\n\npcombined\n \n=\n \nplot\n(\ncombine\n(\nuvals\n,\n \nWeights\n([\n0.1\n,\n \n0.15\n,\n \n0.1\n,\n \n0.1\n]),\n \nn\n \n=\n \n100000\n,\n \nbw\n \n=\n \n0.02\n),\n \n    \ntitle\n \n=\n \nL\ncombine([v_1, v_2, v_3, v_4],  Weights([0.1, 0.15, 0.1, 0.1]))\n,\n \n    \nlc\n \n=\n \n:\nblack\n,\n \nlw\n \n=\n \n2\n)\n\n\n\nplot\n(\np\n,\n \npcombined\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nsize\n \n=\n \n(\n800\n,\n \n600\n),\n \n    \nlink\n \n=\n \n:\nx\n,\n \n    \nylabel\n \n=\n \nDensity\n,\n\n    \ntickfont\n \n=\n \nfont\n(\n12\n),\n\n    \nlegendfont\n \n=\n \nfont\n(\n8\n),\n \nfg_legend\n \n=\n \n:\ntransparent\n,\n \nbg_legend\n \n=\n \n:\ntransparent\n)\n\n\n\n\n\n\n\n\n\n\n\nFrequencyWeights\n\n\nUsing \nFrequencyWeights\n, one may specify the number of times each of the uncertain values  should be sampled to form the pooled resampled draws on which the final kernel density  estimate is performed.\n\n\n#\n\n\nUncertainData\n.\ncombine\n \n \nMethod\n.\n\n\n1\n2\ncombine\n(\nuvals\n::\nVector\n{\nAbstractUncertainValue\n},\n \nweights\n::\nFrequencyWeights\n;\n\n    \nbw\n::\nUnion\n{\nNothing\n,\n \nReal\n}\n \n=\n \nnothing\n)\n\n\n\n\n\n\n\nCombine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in \nuvals\n according to their relative frequencies (the absolute number of draws provided by \nweights\n). Finally, a kernel density  estimate to the final distribution is computed over the \nsum\n(\nweights\n)\n total draws.\n\n\nThe KDE bandwidth is controlled by \nbw\n. By default, \nbw\n \n=\n \nnothing\n; in this case,  the bandwidth is determined using the \nKernelDensity\n.\ndefault_bandwidth\n function.\n\n\n\n\nTip\n\n\nFor very wide and close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.\n\n\n\n\nExample\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nv1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1\n,\n \n0.3\n)\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n3.7\n,\n \n0.8\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n];\n\n\n\n# Two difference syntax options\n\n\ncombine\n(\nuvals\n,\n \nFrequencyWeights\n([\n100\n,\n \n500\n,\n \n343\n,\n \n7000\n]))\n\n\ncombine\n(\nuvals\n,\n \npweights\n([\n1410\n,\n \n550\n,\n \n223\n,\n \n801\n]))\n\n\n\n\n\n\n\nsource\n\n\nFor example:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\nv1\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nrand\n(\n4\n:\n0.25\n:\n6\n,\n \n1000\n),\n \nbandwidth\n \n=\n \n0.01\n)\n\n\nv2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0.8\n,\n \n0.4\n)\n\n\nv3\n \n=\n \nUncertainValue\n([\nrand\n()\n \nfor\n \ni\n \n=\n \n1\n:\n3\n],\n \n[\n0.3\n,\n \n0.3\n,\n \n0.4\n])\n\n\nv4\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n8\n,\n \n0.4\n)\n\n\nuvals\n \n=\n \n[\nv1\n,\n \nv2\n,\n \nv3\n,\n \nv4\n];\n\n\n\np\n \n=\n \nplot\n(\ntitle\n \n=\n \nL\ndistributions \\,\\, with \\,\\, overlapping \\,\\, supports\n)\n\n\nplot!\n(\nv1\n,\n \nlabel\n \n=\n \nL\nv_1: KDE \\, over \\, empirical \\, distribution\n,\n \nls\n \n=\n \n:\ndash\n)\n\n\nplot!\n(\nv2\n,\n \nlabel\n \n=\n \nL\nv_2: Normal(0.8, 0.4)\n,\n \nls\n \n=\n \n:\ndot\n)\n\n\n# plot each possible state as vline\n\n\nvline!\n(\nv3\n.\nvalues\n,\n \n    \nlabel\n \n=\n \nL\nv_3: \\, Discrete \\, population\\, [1,2,3], w/ \\, weights \\, [0.3, 0.4, 0.4]\n)\n \n\nplot!\n(\nv4\n,\n \nlabel\n \n=\n \nL\nv_4: \\, Gamma(8, 0.4)\n)\n\n\n\npcombined\n \n=\n \nplot\n(\ncombine\n(\nuvals\n,\n \nFrequencyWeights\n([\n10000\n,\n \n20000\n,\n \n3000\n,\n \n5000\n]),\n \nbw\n \n=\n \n0.05\n),\n \n    \ntitle\n \n=\n \nL\ncombine([v_1, v_2, v_3, v_4], FrequencyWeights([10000, 20000, 3000, 5000])\n,\n \n    \nlc\n \n=\n \n:\nblack\n,\n \nlw\n \n=\n \n2\n)\n\n\n\nplot\n(\np\n,\n \npcombined\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nsize\n \n=\n \n(\n800\n,\n \n600\n),\n \n    \nlink\n \n=\n \n:\nx\n,\n \n    \nylabel\n \n=\n \nDensity\n,\n\n    \ntickfont\n \n=\n \nfont\n(\n12\n),\n\n    \nlegendfont\n \n=\n \nfont\n(\n8\n),\n \nfg_legend\n \n=\n \n:\ntransparent\n,\n \nbg_legend\n \n=\n \n:\ntransparent\n)", 
            "title": "Combining/merging"
        }, 
        {
            "location": "/uncertain_values/merging/#nomenclature", 
            "text": "Depending on your data, you may want to choose of one the following ways of  representing multiple uncertain values as one:   Combining . An ensemble of uncertain    values is represented as a weighted population. This approach is nice if you want    to impose expert-opinion on the relative sampling probabilities of uncertain    values in the ensemble, but still sample from the entire supports of each of the   furnishing values. This introduces no additional approximations besides what    is already present at the moment you define your uncertain values.  Merging . Multiple uncertain values are merged using    a kernel density estimate to the overall distribution. This approach introduces    approximations  beyond  what is present in the uncertain values when you define them.", 
            "title": "Nomenclature"
        }, 
        {
            "location": "/uncertain_values/merging/#combining_uncertain_values_the_population_approach", 
            "text": "Combining  uncertain values is done by representing them as a weighted population of uncertain values, which is illustrated in the following example:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 # Assume we have done some analysis and have three points whose uncertainties   # significantly overlap.  v1   =   UncertainValue ( Normal ( 0.13 ,   0.52 ))  v2   =   UncertainValue ( Normal ( 0.27 ,   0.42 ))  v3   =   UncertainValue ( Normal ( 0.21 ,   0.61 ))  # Give each value equal sampling probabilities and represent as a population  pop   =   UncertainValue ([ v1 ,   v2 ,   v3 ],   [ 1 ,   1 ,   1 ])  # Let the values v1, v2 and v3 be sampled with probability ratios 1-2-3  pop   =   UncertainValue ([ v1 ,   v2 ,   v3 ],   [ 1 ,   2 ,   3 ])     This is not restricted to normal distributions! We can combine any type of  value in our population, even populations!   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 # Consider a population of normal distributions, and a gamma distribution  v1   =   UncertainValue ( Normal ( 0.265 ,   0.52 ))  v2   =   UncertainValue ( Normal ( 0.311 ,   0.15 ))  v3   =   UncertainValue ([ v1 ,   v2 ],   [ 2 ,   1 ])  v4   =   UncertainValue ( Gamma ( 0.5 ,   - 1 ))  pts   =   [ v1 ,   v4 ]  wts   =   [ 2 ,   1 ]  # New population is a nested population with unequal weights  pop   =   UncertainValue ( pts ,   wts )  d1   =   density ( resample ( pop ,   20000 ),   label   =   population )  d2   =   plot ()  density! ( d2 ,   resample ( pop [ 1 ],   20000 ),   label   =   v1 )  density! ( d2 ,   resample ( pop [ 2 ],   20000 ),   label   =   v2 )  plot ( d1 ,   d2 ,   layout   =   ( 2 ,   1 ),   xlabel   =   Value ,   ylabel   =   Density ,   link   =   : x ,   xlims   =   ( - 2.5 ,   2.5 ))     This makes it possible treat an ensemble of uncertain values as a single uncertain value.  With equal weights, this introduces no bias beyond what is present in the data,  because resampling is done from the full supports of each of the furnishing values.  Additional information on relative sampling probabilities, however, be it informed by expert opinion or quantative estimates, is easily incorporated by adjusting  the sampling weights.", 
            "title": "Combining uncertain values: the population approach"
        }, 
        {
            "location": "/uncertain_values/merging/#merging_uncertain_values_the_kernel_density_estimation_kde_approach", 
            "text": "Merging  multiple uncertain values could be done by fitting a model distribution to  the values. Using any specific theoretical distribution as a model for the combined  uncertainty, however, is in general not possible, because the values may have  different types of uncertainties.  Thus, in this package, kernel kernel density estimation is used to merge multiple uncertain values.  This has the advantage that you only have to deal with a single estimate to the combined  distribution, but introduces bias because the distribution is  estimated  and the  shape of the distribution depends on the parameters of the KDE procedure.", 
            "title": "Merging uncertain values: the kernel density estimation (KDE) approach"
        }, 
        {
            "location": "/uncertain_values/merging/#without_weights", 
            "text": "When no weights are provided, the combined value is computed  by resampling each of the  N  uncertain values  n / N  times, then combining using kernel density estimation.   #  UncertainData . combine     Method .  1\n2 combine ( uvals :: Vector { AbstractUncertainValue };   n   =   10000 * length ( uvals ),  \n     bw :: Union { Nothing ,   Real }   =   nothing )    Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in  uvals ,  n  times  each,  then pooling these draws together. Finally, a kernel density estimate to the final distribution is computed over those draws.   The KDE bandwidth is controlled by  bw . By default,  bw   =   nothing ; in this case,  the bandwidth is determined using the  KernelDensity . default_bandwidth  function.   Tip  For very wide, close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.   Example  1\n2\n3\n4\n5\n6\n7\n8 v1   =   UncertainValue ( Normal ,   1 ,   0.3 )  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Normal ,   3.7 ,   0.8 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ];  combine ( uvals )  combine ( uvals ,   n   =   20000 )   # adjust number of total draws    source  Weights dictating the relative contribution of each  uncertain value into the combined value can also be provided.  combine  works  with  ProbabilityWeights ,  AnalyticWeights ,   FrequencyWeights  and the generic  Weights .   Below shows an example of combining    1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 v1   =   UncertainValue ( rand ( 1000 ))  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Normal ,   3.7 ,   0.8 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ]  p   =   plot ( title   =   L distributions \\,\\, with \\,\\, overlapping \\,\\, supports )  plot! ( v1 ,   label   =   L v_1 ,   ls   =   : dash )  plot! ( v2 ,   label   =   L v_2 ,   ls   =   : dot )  vline! ( v3 . values ,   label   =   L v_3 )   # plot each possible state as vline  plot! ( v4 ,   label   =   L v_4 )  pcombined   =   plot ( combine ( uvals ),   title   =   L merge(v_1, v_2, v_3, v_4) ,   lc   =   : black ,   lw   =   2 )  plot ( p ,   pcombined ,   layout   =   ( 2 ,   1 ),   link   =   : x ,   ylabel   =   Density )", 
            "title": "Without weights"
        }, 
        {
            "location": "/uncertain_values/merging/#with_weights", 
            "text": "Weights ,  ProbabilityWeights  and   AnalyticWeights  are functionally the same. Either  may be used depending on whether the weights are assigned subjectively or quantitatively.  With  FrequencyWeights , it is possible to control the exact number of draws from each  uncertain value that goes into the draw pool before performing KDE.", 
            "title": "With weights"
        }, 
        {
            "location": "/uncertain_values/merging/#probabilityweights", 
            "text": "#  UncertainData . combine     Method .  1\n2\n3 combine ( uvals :: Vector { AbstractUncertainValue },   weights :: ProbabilityWeights ;  \n     n   =   10000 * length ( uvals ),  \n     bw :: Union { Nothing ,   Real }   =   nothing )    Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in  uvals  proportionally to the provided  relative analytic  weights  indicating their relative importance (these are normalised by  default, so don't need to sum to 1), then pooling these draws together. Finally, a kernel  density estimate to the final distribution is computed over the  n  total draws.  Providing  ProbabilityWeights  leads to the exact same behaviour as for  AnalyticWeights ,  but may be more appropriote when, for example, weights have been determined  quantitatively.   The KDE bandwidth is controlled by  bw . By default,  bw   =   nothing ; in this case,  the bandwidth is determined using the  KernelDensity . default_bandwidth  function.   Tip  For very wide, close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.   Example  1\n2\n3\n4\n5\n6\n7\n8\n9 v1   =   UncertainValue ( Normal ,   1 ,   0.3 )  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Normal ,   3.7 ,   0.8 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ];  # Two difference syntax options  combine ( uvals ,   ProbabilityWeights ([ 0.2 ,   0.1 ,   0.3 ,   0.2 ]))  combine ( uvals ,   pweights ([ 0.2 ,   0.1 ,   0.3 ,   0.2 ]),   n   =   20000 )   # adjust number of total draws    source  For example:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24 v1   =   UncertainValue ( UnivariateKDE ,   rand ( 4 : 0.25 : 6 ,   1000 ),   bandwidth   =   0.02 )  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Gamma ,   8 ,   0.4 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ];  p   =   plot ( title   =   L distributions \\,\\, with \\,\\, overlapping \\,\\, supports )  plot! ( v1 ,   label   =   L v_1: KDE \\, over \\, empirical \\, distribution ,   ls   =   : dash )  plot! ( v2 ,   label   =   L v_2: Normal(0.8, 0.4) ,   ls   =   : dot )  # plot each possible state as vline  vline! ( v3 . values ,  \n     label   =   L v_3: \\, Discrete \\, population\\, [1,2,3], w/ \\, weights \\, [0.3, 0.4, 0.4] )   plot! ( v4 ,   label   =   L v_4: \\, Gamma(8, 0.4) )  pcombined   =   plot ( \n     combine ( uvals ,   ProbabilityWeights ([ 0.1 ,   0.3 ,   0.02 ,   0.5 ]),   n   =   100000 ,   bw   =   0.05 ),  \n     title   =   L combine([v_1, v_2, v_3, v_4], ProbabilityWeights([0.1, 0.3, 0.02, 0.5]) ,  \n     lc   =   : black ,   lw   =   2 )  plot ( p ,   pcombined ,   layout   =   ( 2 ,   1 ),   size   =   ( 800 ,   600 ),  \n     link   =   : x ,  \n     ylabel   =   Density , \n     tickfont   =   font ( 12 ), \n     legendfont   =   font ( 8 ),   fg_legend   =   : transparent ,   bg_legend   =   : transparent )", 
            "title": "ProbabilityWeights"
        }, 
        {
            "location": "/uncertain_values/merging/#analyticweights", 
            "text": "#  UncertainData . combine     Method .  1\n2\n3 combine ( uvals :: Vector { AbstractUncertainValue },   weights :: AnalyticWeights ;  \n     n   =   10000 * length ( uvals ),  \n     bw :: Union { Nothing ,   Real }   =   nothing )    Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in  uvals  proportionally to the provided  relative probability  weights  (these are normalised by default, so don't need  to sum to 1), then pooling these draws together. Finally, a kernel density  estimate to the final distribution is computed over the  n  total draws.  Providing  AnalyticWeights  leads to the exact same behaviour as for  ProbabilityWeights , but may be more appropriote when relative importance weights are assigned subjectively,  and not based on quantitative evidence.  The KDE bandwidth is controlled by  bw . By default,  bw   =   nothing ; in this case,  the bandwidth is determined using the  KernelDensity . default_bandwidth  function.   Tip  For very wide, close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.   Example  1\n2\n3\n4\n5\n6\n7\n8\n9 v1   =   UncertainValue ( Normal ,   1 ,   0.3 )  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Normal ,   3.7 ,   0.8 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ];  # Two difference syntax options  combine ( uvals ,   AnalyticWeights ([ 0.2 ,   0.1 ,   0.3 ,   0.2 ]))  combine ( uvals ,   aweights ([ 0.2 ,   0.1 ,   0.3 ,   0.2 ]),   n   =   20000 )   # adjust number of total draws    source  For example:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20 v1   =   UncertainValue ( UnivariateKDE ,   rand ( 4 : 0.25 : 6 ,   1000 ),   bandwidth   =   0.02 )  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Gamma ,   8 ,   0.4 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ];  p   =   plot ( title   =   L distributions \\,\\, with \\,\\, overlapping \\,\\, supports )  plot! ( v1 ,   label   =   L v_1: KDE \\, over \\, empirical \\, distribution ,   ls   =   : dash )  plot! ( v2 ,   label   =   L v_2: Normal(0.8, 0.4) ,   ls   =   : dot )  vline! ( v3 . values ,   label   =   L v_3: \\, Discrete \\, population\\, [1,2,3], w/ \\, weights \\, [0.3, 0.4, 0.4] )   # plot each possible state as vline  plot! ( v4 ,   label   =   L v_4: \\, Gamma(8, 0.4) )  pcombined   =   plot ( combine ( uvals ,   AnalyticWeights ([ 0.1 ,   0.3 ,   0.02 ,   0.5 ]),   n   =   100000 ,   bw   =   0.05 ),  \n     title   =   L combine([v_1, v_2, v_3, v_4], AnalyticWeights([0.1, 0.3, 0.02, 0.5]) ,   lc   =   : black ,   lw   =   2 )  plot ( p ,   pcombined ,   layout   =   ( 2 ,   1 ),   size   =   ( 800 ,   600 ),  \n     link   =   : x ,  \n     ylabel   =   Density , \n     tickfont   =   font ( 12 ), \n     legendfont   =   font ( 8 ),   fg_legend   =   : transparent ,   bg_legend   =   : transparent )", 
            "title": "AnalyticWeights"
        }, 
        {
            "location": "/uncertain_values/merging/#generic_weights", 
            "text": "#  UncertainData . combine     Method .  1\n2\n3 combine ( uvals :: Vector { AbstractUncertainValue },   weights :: Weights ;  \n     n   =   10000 * length ( uvals ),  \n     bw :: Union { Nothing ,   Real }   =   nothing )    Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in  uvals  proportionally to the provided  weights   (these are normalised by default, so don't need to sum to 1), then pooling these draws  together. Finally, a kernel density estimate to the final distribution is computed over  the  n  total draws.  Providing  Weights  leads to the exact same behaviour as for  ProbabilityWeights  and   AnalyticalWeights .  The KDE bandwidth is controlled by  bw . By default,  bw   =   nothing ; in this case,  the bandwidth is determined using the  KernelDensity . default_bandwidth  function.   Tip  For very wide, close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.   Example  1\n2\n3\n4\n5\n6\n7\n8\n9 v1   =   UncertainValue ( Normal ,   1 ,   0.3 )  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Normal ,   3.7 ,   0.8 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ];  # Two difference syntax options  combine ( uvals ,   Weights ([ 0.2 ,   0.1 ,   0.3 ,   0.2 ]))  combine ( uvals ,   weights ([ 0.2 ,   0.1 ,   0.3 ,   0.2 ]),   n   =   20000 )   # adjust number of total draws    source  For example:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23 v1   =   UncertainValue ( UnivariateKDE ,   rand ( 4 : 0.25 : 6 ,   1000 ),   bandwidth   =   0.01 )  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Gamma ,   8 ,   0.4 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ];  p   =   plot ( title   =   L distributions \\,\\, with \\,\\, overlapping \\,\\, supports )  plot! ( v1 ,   label   =   L v_1: KDE \\, over \\, empirical \\, distribution ,   ls   =   : dash )  plot! ( v2 ,   label   =   L v_2: Normal(0.8, 0.4) ,   ls   =   : dot )  # plot each possible state as vline  vline! ( v3 . values ,  \n     label   =   L v_3: \\, Discrete \\, population\\, [1,2,3], w/ \\, weights \\, [0.3, 0.4, 0.4] )   plot! ( v4 ,   label   =   L v_4: \\, Gamma(8, 0.4) )  pcombined   =   plot ( combine ( uvals ,   Weights ([ 0.1 ,   0.15 ,   0.1 ,   0.1 ]),   n   =   100000 ,   bw   =   0.02 ),  \n     title   =   L combine([v_1, v_2, v_3, v_4],  Weights([0.1, 0.15, 0.1, 0.1])) ,  \n     lc   =   : black ,   lw   =   2 )  plot ( p ,   pcombined ,   layout   =   ( 2 ,   1 ),   size   =   ( 800 ,   600 ),  \n     link   =   : x ,  \n     ylabel   =   Density , \n     tickfont   =   font ( 12 ), \n     legendfont   =   font ( 8 ),   fg_legend   =   : transparent ,   bg_legend   =   : transparent )", 
            "title": "Generic Weights"
        }, 
        {
            "location": "/uncertain_values/merging/#frequencyweights", 
            "text": "Using  FrequencyWeights , one may specify the number of times each of the uncertain values  should be sampled to form the pooled resampled draws on which the final kernel density  estimate is performed.  #  UncertainData . combine     Method .  1\n2 combine ( uvals :: Vector { AbstractUncertainValue },   weights :: FrequencyWeights ; \n     bw :: Union { Nothing ,   Real }   =   nothing )    Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in  uvals  according to their relative frequencies (the absolute number of draws provided by  weights ). Finally, a kernel density  estimate to the final distribution is computed over the  sum ( weights )  total draws.  The KDE bandwidth is controlled by  bw . By default,  bw   =   nothing ; in this case,  the bandwidth is determined using the  KernelDensity . default_bandwidth  function.   Tip  For very wide and close-to-normal distributions, the default bandwidth may work well.  If you're combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.   Example  1\n2\n3\n4\n5\n6\n7\n8\n9 v1   =   UncertainValue ( Normal ,   1 ,   0.3 )  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Normal ,   3.7 ,   0.8 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ];  # Two difference syntax options  combine ( uvals ,   FrequencyWeights ([ 100 ,   500 ,   343 ,   7000 ]))  combine ( uvals ,   pweights ([ 1410 ,   550 ,   223 ,   801 ]))    source  For example:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23 v1   =   UncertainValue ( UnivariateKDE ,   rand ( 4 : 0.25 : 6 ,   1000 ),   bandwidth   =   0.01 )  v2   =   UncertainValue ( Normal ,   0.8 ,   0.4 )  v3   =   UncertainValue ([ rand ()   for   i   =   1 : 3 ],   [ 0.3 ,   0.3 ,   0.4 ])  v4   =   UncertainValue ( Gamma ,   8 ,   0.4 )  uvals   =   [ v1 ,   v2 ,   v3 ,   v4 ];  p   =   plot ( title   =   L distributions \\,\\, with \\,\\, overlapping \\,\\, supports )  plot! ( v1 ,   label   =   L v_1: KDE \\, over \\, empirical \\, distribution ,   ls   =   : dash )  plot! ( v2 ,   label   =   L v_2: Normal(0.8, 0.4) ,   ls   =   : dot )  # plot each possible state as vline  vline! ( v3 . values ,  \n     label   =   L v_3: \\, Discrete \\, population\\, [1,2,3], w/ \\, weights \\, [0.3, 0.4, 0.4] )   plot! ( v4 ,   label   =   L v_4: \\, Gamma(8, 0.4) )  pcombined   =   plot ( combine ( uvals ,   FrequencyWeights ([ 10000 ,   20000 ,   3000 ,   5000 ]),   bw   =   0.05 ),  \n     title   =   L combine([v_1, v_2, v_3, v_4], FrequencyWeights([10000, 20000, 3000, 5000]) ,  \n     lc   =   : black ,   lw   =   2 )  plot ( p ,   pcombined ,   layout   =   ( 2 ,   1 ),   size   =   ( 800 ,   600 ),  \n     link   =   : x ,  \n     ylabel   =   Density , \n     tickfont   =   font ( 12 ), \n     legendfont   =   font ( 8 ),   fg_legend   =   : transparent ,   bg_legend   =   : transparent )", 
            "title": "FrequencyWeights"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_examples/", 
            "text": "First, load the necessary packages:\n\n\n1\nusing\n \nUncertainData\n,\n \nDistributions\n,\n \nKernelDensity\n,\n \nPlots\n\n\n\n\n\n\n\n\n\nExample 1: Uncertain values defined by theoretical distributions\n\n\n\n\nA uniformly distributed uncertain value\n\n\nConsider the following contrived example. We've measure a data value with a poor instrument  that tells us that the value lies between \n-\n2\n and \n3\n. However, we but that we know nothing  more about how the value is distributed on that interval. Then it may be reasonable to  represent that value as a uniform distribution on \n[\n-\n2\n,\n \n3\n]\n.\n\n\nTo construct an uncertain value following a uniform distribution, we use the constructor  for theoretical distributions with known parameters  (\nUncertainValue\n(\ndistribution\n,\n \nparams\n...)\n). \n\n\nThe uniform distribution is defined by its lower and upper bounds, so we'll provide  these bounds as the parameters.\n\n\n1\n2\n3\n4\nu\n \n=\n \nUncertainValue\n(\nUniform\n,\n \n1\n,\n \n2\n)\n\n\n\n# Plot the estimated density\n\n\nbar\n(\nu\n,\n \nlabel\n \n=\n \n,\n \nxlabel\n \n=\n \nvalue\n,\n \nylabel\n \n=\n \nprobability density\n)\n\n\n\n\n\n\n\n\n\n\n\nA normally distributed uncertain value\n\n\nA situation commonly encountered is to want to use someone else's data from a publication.  Usually, these values are reported as the mean or median, with some associated uncertainty.  Say we want to use an uncertain value which is normally distributed with mean \n2\n.\n1\n and  standard deviation \n0\n.\n3\n.\n\n\nNormal distributions also have two parameters, so we'll use the two-parameter constructor  as we did above. \n\n\n1\n2\n3\n4\nu\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2.1\n,\n \n0.3\n)\n\n\n\n# Plot the estimated density\n\n\nbar\n(\nu\n,\n \nlabel\n \n=\n \n,\n \nxlabel\n \n=\n \nvalue\n,\n \nylabel\n \n=\n \nprobability density\n)\n\n\n\n\n\n\n\n\n\n\n\nOther distributions\n\n\nYou may define uncertain values following any of the  \nsupported distributions\n. \n\n\n\n\nExample 2: Uncertain values defined by kernel density estimated distributions\n\n\nOne may also be given a a distribution of numbers that's not quite normally distributed.  How to represent this uncertainty? Easy: we use a kernel density estimate to the distribution.\n\n\nLet's define a complicated distribution which is a mixture of two different normal  distributions, then draw a sample of numbers from it.\n\n\n1\n2\nM\n \n=\n \nMixtureModel\n([\nNormal\n(\n-\n5\n,\n \n0.5\n),\n \nNormal\n(\n0.2\n)])\n\n\nsome_sample\n \n=\n \nrand\n(\nM\n,\n \n250\n)\n\n\n\n\n\n\n\nNow, pretend that \nsome_sample\n is a list of measurements we got from somewhere.  KDE estimates to the distribution can be defined implicitly or explicitly as follows:\n\n\n1\n2\n3\n4\n5\n# If the only argument to `UncertainValue()` is a vector of number, KDE will be triggered.\n\n\nu\n \n=\n \nUncertainValue\n(\nrand\n(\nM\n,\n \n250\n))\n \n\n\n# You may also tell the constructor explicitly that you want KDE. \n\n\nu\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nrand\n(\nM\n,\n \n250\n))\n\n\n\n\n\n\n\nNow, let's plot the resulting distribution. \nNote: this is not the original mixture of  Gaussians we started out with, it's the kernel density estimate to that mixture!\n\n\n1\n2\n# Plot the estimated distribution.\n\n\nplot\n(\nu\n,\n \nxlabel\n \n=\n \nValue\n,\n \nylabel\n \n=\n \nProbability density\n)\n\n\n\n\n\n\n\n\n\n\n\nExample 3: Uncertain values defined by theoretical distributions fitted to empirical data\n\n\nOne may also be given a dataset whose histogram looks a lot like a theoretical distribution. We may then select a theoretical distribution and fit its parameters to the empirical data.\n\n\nSay our data was a sample that looks like it obeys Gamma distribution.\n\n\n1\n2\n# Draw a 2000-point sample from a Gamma distribution with parameters \u03b1 = 1.7 and \u03b8 = 5.5\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(\n1.7\n,\n \n5.5\n),\n \n2000\n)\n\n\n\n\n\n\n\nTo perform a parameter estimation, simply provide the distribution as the first  argument and the sample as the second argument to the \nUncertainValue\n constructor.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n# Take a sample from a Gamma distribution with parameters \u03b1 = 1.7 and \u03b8 = 5.5 and \n\n\n# create a histogram of the sample.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(\n1.7\n,\n \n5.5\n),\n \n2000\n)\n\n\n\np1\n \n=\n \nhistogram\n(\nsome_sample\n,\n \nnormalize\n \n=\n \ntrue\n,\n\n    \nfc\n \n=\n \n:\nblack\n,\n \nlc\n \n=\n \n:\nblack\n,\n\n    \nlabel\n \n=\n \n,\n \nxlabel\n \n=\n \nvalue\n,\n \nylabel\n \n=\n \ndensity\n)\n\n\n\n# For the uncertain value representation, fit a gamma distribution to the sample. \n\n\n# Then, compare the histogram obtained from the original distribution to that obtained \n\n\n# when resampling the fitted distribution\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nsome_sample\n)\n\n\n\n# Resample the fitted theoretical distribution\n\n\np2\n \n=\n \nhistogram\n(\nresample\n(\nuv\n,\n \n10000\n),\n \nnormalize\n \n=\n \ntrue\n,\n\n    \nfc\n \n=\n \n:\nblue\n,\n \nlc\n \n=\n \n:\nblue\n,\n\n    \nlabel\n \n=\n \n,\n \nxlabel\n \n=\n \nvalue\n,\n \nylabel\n \n=\n \ndensity\n)\n\n\n\nplot\n(\np1\n,\n \np2\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nx\n)\n\n\n\n\n\n\n\nAs expected, the histograms closely match (but are not exact because we estimated the distribution using a limited sample).", 
            "title": "Extended examples"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_examples/#example_1_uncertain_values_defined_by_theoretical_distributions", 
            "text": "", 
            "title": "Example 1: Uncertain values defined by theoretical distributions"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_examples/#a_uniformly_distributed_uncertain_value", 
            "text": "Consider the following contrived example. We've measure a data value with a poor instrument  that tells us that the value lies between  - 2  and  3 . However, we but that we know nothing  more about how the value is distributed on that interval. Then it may be reasonable to  represent that value as a uniform distribution on  [ - 2 ,   3 ] .  To construct an uncertain value following a uniform distribution, we use the constructor  for theoretical distributions with known parameters  ( UncertainValue ( distribution ,   params ...) ).   The uniform distribution is defined by its lower and upper bounds, so we'll provide  these bounds as the parameters.  1\n2\n3\n4 u   =   UncertainValue ( Uniform ,   1 ,   2 )  # Plot the estimated density  bar ( u ,   label   =   ,   xlabel   =   value ,   ylabel   =   probability density )", 
            "title": "A uniformly distributed uncertain value"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_examples/#a_normally_distributed_uncertain_value", 
            "text": "A situation commonly encountered is to want to use someone else's data from a publication.  Usually, these values are reported as the mean or median, with some associated uncertainty.  Say we want to use an uncertain value which is normally distributed with mean  2 . 1  and  standard deviation  0 . 3 .  Normal distributions also have two parameters, so we'll use the two-parameter constructor  as we did above.   1\n2\n3\n4 u   =   UncertainValue ( Normal ,   2.1 ,   0.3 )  # Plot the estimated density  bar ( u ,   label   =   ,   xlabel   =   value ,   ylabel   =   probability density )", 
            "title": "A normally distributed uncertain value"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_examples/#other_distributions", 
            "text": "You may define uncertain values following any of the   supported distributions .", 
            "title": "Other distributions"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_examples/#example_2_uncertain_values_defined_by_kernel_density_estimated_distributions", 
            "text": "One may also be given a a distribution of numbers that's not quite normally distributed.  How to represent this uncertainty? Easy: we use a kernel density estimate to the distribution.  Let's define a complicated distribution which is a mixture of two different normal  distributions, then draw a sample of numbers from it.  1\n2 M   =   MixtureModel ([ Normal ( - 5 ,   0.5 ),   Normal ( 0.2 )])  some_sample   =   rand ( M ,   250 )    Now, pretend that  some_sample  is a list of measurements we got from somewhere.  KDE estimates to the distribution can be defined implicitly or explicitly as follows:  1\n2\n3\n4\n5 # If the only argument to `UncertainValue()` is a vector of number, KDE will be triggered.  u   =   UncertainValue ( rand ( M ,   250 ))   # You may also tell the constructor explicitly that you want KDE.   u   =   UncertainValue ( UnivariateKDE ,   rand ( M ,   250 ))    Now, let's plot the resulting distribution.  Note: this is not the original mixture of  Gaussians we started out with, it's the kernel density estimate to that mixture!  1\n2 # Plot the estimated distribution.  plot ( u ,   xlabel   =   Value ,   ylabel   =   Probability density )", 
            "title": "Example 2: Uncertain values defined by kernel density estimated distributions"
        }, 
        {
            "location": "/uncertain_values/uncertainvalues_examples/#example_3_uncertain_values_defined_by_theoretical_distributions_fitted_to_empirical_data", 
            "text": "One may also be given a dataset whose histogram looks a lot like a theoretical distribution. We may then select a theoretical distribution and fit its parameters to the empirical data.  Say our data was a sample that looks like it obeys Gamma distribution.  1\n2 # Draw a 2000-point sample from a Gamma distribution with parameters \u03b1 = 1.7 and \u03b8 = 5.5  some_sample   =   rand ( Gamma ( 1.7 ,   5.5 ),   2000 )    To perform a parameter estimation, simply provide the distribution as the first  argument and the sample as the second argument to the  UncertainValue  constructor.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19 # Take a sample from a Gamma distribution with parameters \u03b1 = 1.7 and \u03b8 = 5.5 and   # create a histogram of the sample.  some_sample   =   rand ( Gamma ( 1.7 ,   5.5 ),   2000 )  p1   =   histogram ( some_sample ,   normalize   =   true , \n     fc   =   : black ,   lc   =   : black , \n     label   =   ,   xlabel   =   value ,   ylabel   =   density )  # For the uncertain value representation, fit a gamma distribution to the sample.   # Then, compare the histogram obtained from the original distribution to that obtained   # when resampling the fitted distribution  uv   =   UncertainValue ( Gamma ,   some_sample )  # Resample the fitted theoretical distribution  p2   =   histogram ( resample ( uv ,   10000 ),   normalize   =   true , \n     fc   =   : blue ,   lc   =   : blue , \n     label   =   ,   xlabel   =   value ,   ylabel   =   density )  plot ( p1 ,   p2 ,   layout   =   ( 2 ,   1 ),   link   =   : x )    As expected, the histograms closely match (but are not exact because we estimated the distribution using a limited sample).", 
            "title": "Example 3: Uncertain values defined by theoretical distributions fitted to empirical data"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_datasets_overview/", 
            "text": "Types of uncertain value collections\n\n\nIf dealing with several uncertain values, it may be useful to represent them as an uncertain dataset. This way, one may trivially, for example, compute statistics for a dataset consisting of samples with different types of uncertainties.\n\n\n\n\nUncertain dataset types\n\n\nYou can collect your uncertain values in the following collections:\n\n\n\n\nThe \nUncertainValueDataset\n type is    just a wrapper for a vector of uncertain values.\n\n\nThe \nUncertainIndexDataset\n type    behaves just as \nUncertainValueDataset\n, but has certain resampling methods such as \nsequential resampling\n associated with them.\n\n\nThe \nUncertainIndexValueDataset\n    type allows you to be explicit that you're working with datasets where both the    \nindices\n and the    \ndata values\n are uncertain.    This may be useful when you, for example, want to draw realizations of your    dataset while simultaneously enforcing    \nsequential resampling\n    models. One example is resampling while ensuring the draws have    \nstrictly increasing\n    age models.\n\n\n\n\nThere's also a generic uncertain dataset type for when you don't care about distinguishing  between indices and data values:\n\n\n\n\nUncertainDataset\n contains uncertain indices.\n\n\n\n\n\n\nVectors of uncertain values\n\n\n\n\nVectors of uncertain values, i.e. \nVector\n{\n:\nAbstractUncertainvalue\n}\n, will work    seamlessly for many applications, but not for all mathematical operations and statistical    algorithms. For that, rather use one of the uncertain dataset types above\n\n\n\n\n\n\nCollection types\n\n\nThroughout the documentation you may encounter the following type union:\n\n\n#\n\n\nUncertainData\n.\nUncertainDatasets\n.\nUVAL_COLLECTION_TYPES\n \n \nConstant\n.\n\n\n1\n2\n3\n4\nUVAL_COLLECTION_TYPES\n \n=\n \nUnion\n{\nUD\n,\n \nUV\n}\n \nwhere\n \n{\n\n    \nUD\n \n:\n \nAbstractUncertainValueDataset\n,\n \n    \nUV\n \n:\n \nAbstractVector\n{\nT\n}\n \nwhere\n \n{\n\n        \nT\n \n:\n \nAbstractUncertainValue\n}}\n\n\n\n\n\n\n\nA type union used to represent types of uncertain values. \n\n\nsource", 
            "title": "Types of uncertain datasets"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_datasets_overview/#types_of_uncertain_value_collections", 
            "text": "If dealing with several uncertain values, it may be useful to represent them as an uncertain dataset. This way, one may trivially, for example, compute statistics for a dataset consisting of samples with different types of uncertainties.", 
            "title": "Types of uncertain value collections"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_datasets_overview/#uncertain_dataset_types", 
            "text": "You can collect your uncertain values in the following collections:   The  UncertainValueDataset  type is    just a wrapper for a vector of uncertain values.  The  UncertainIndexDataset  type    behaves just as  UncertainValueDataset , but has certain resampling methods such as  sequential resampling  associated with them.  The  UncertainIndexValueDataset     type allows you to be explicit that you're working with datasets where both the     indices  and the     data values  are uncertain.    This may be useful when you, for example, want to draw realizations of your    dataset while simultaneously enforcing     sequential resampling     models. One example is resampling while ensuring the draws have     strictly increasing     age models.   There's also a generic uncertain dataset type for when you don't care about distinguishing  between indices and data values:   UncertainDataset  contains uncertain indices.", 
            "title": "Uncertain dataset types"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_datasets_overview/#vectors_of_uncertain_values", 
            "text": "Vectors of uncertain values, i.e.  Vector { : AbstractUncertainvalue } , will work    seamlessly for many applications, but not for all mathematical operations and statistical    algorithms. For that, rather use one of the uncertain dataset types above", 
            "title": "Vectors of uncertain values"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_datasets_overview/#collection_types", 
            "text": "Throughout the documentation you may encounter the following type union:  #  UncertainData . UncertainDatasets . UVAL_COLLECTION_TYPES     Constant .  1\n2\n3\n4 UVAL_COLLECTION_TYPES   =   Union { UD ,   UV }   where   { \n     UD   :   AbstractUncertainValueDataset ,  \n     UV   :   AbstractVector { T }   where   { \n         T   :   AbstractUncertainValue }}    A type union used to represent types of uncertain values.   source", 
            "title": "Collection types"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_index_dataset/", 
            "text": "Uncertain index datasets\n\n\n\n\nDocumentation\n\n\n#\n\n\nUncertainData\n.\nUncertainDatasets\n.\nUncertainIndexDataset\n \n \nType\n.\n\n\n1\nUncertainIndexDataset\n\n\n\n\n\n\n\nGeneric dataset containing uncertain indices.\n\n\nFields\n\n\n\n\nindices\n::\nAbstractVector\n{\nAbstractUncertainValue\n}\n: The uncertain values.\n\n\n\n\nsource\n\n\n\n\nDescription\n\n\nUncertainIndexDataset\ns is an uncertain dataset type that represents the indices  corresponding to an \nUncertainValueDataset\n.\n\n\nIt is meant to be used for the \nindices\n field in \nUncertainIndexValueDataset\ns instances.\n\n\n\n\nDefining uncertain index datasets\n\n\n\n\nExample 1: increasing index uncertainty through time\n\n\n\n\nDefining the indices\n\n\nSay we had a dataset of 20 values for which the uncertainties are normally distributed  with increasing standard deviation through time.\n\n\n1\n2\n3\ntime_inds\n \n=\n \n1\n:\n13\n\n\nuvals\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \nind\n,\n \nrand\n(\nUniform\n())\n \n+\n \n(\nind\n \n/\n \n6\n))\n \nfor\n \nind\n \nin\n \ntime_inds\n]\n\n\ninds\n \n=\n \nUncertainIndexDataset\n(\nuvals\n)\n\n\n\n\n\n\n\nThat's it. We can also plot the 33\nrd\n to 67\nth\n percentile range for the indices.\n\n\n1\nplot\n(\ninds\n,\n \n[\n0\n.\n33\n,\n \n0\n.\n67\n])", 
            "title": "Uncertain index dataset"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_index_dataset/#uncertain_index_datasets", 
            "text": "", 
            "title": "Uncertain index datasets"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_index_dataset/#documentation", 
            "text": "#  UncertainData . UncertainDatasets . UncertainIndexDataset     Type .  1 UncertainIndexDataset    Generic dataset containing uncertain indices.  Fields   indices :: AbstractVector { AbstractUncertainValue } : The uncertain values.   source", 
            "title": "Documentation"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_index_dataset/#description", 
            "text": "UncertainIndexDataset s is an uncertain dataset type that represents the indices  corresponding to an  UncertainValueDataset .  It is meant to be used for the  indices  field in  UncertainIndexValueDataset s instances.", 
            "title": "Description"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_index_dataset/#defining_uncertain_index_datasets", 
            "text": "", 
            "title": "Defining uncertain index datasets"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_index_dataset/#example_1_increasing_index_uncertainty_through_time", 
            "text": "", 
            "title": "Example 1: increasing index uncertainty through time"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_index_dataset/#defining_the_indices", 
            "text": "Say we had a dataset of 20 values for which the uncertainties are normally distributed  with increasing standard deviation through time.  1\n2\n3 time_inds   =   1 : 13  uvals   =   [ UncertainValue ( Normal ,   ind ,   rand ( Uniform ())   +   ( ind   /   6 ))   for   ind   in   time_inds ]  inds   =   UncertainIndexDataset ( uvals )    That's it. We can also plot the 33 rd  to 67 th  percentile range for the indices.  1 plot ( inds ,   [ 0 . 33 ,   0 . 67 ])", 
            "title": "Defining the indices"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_value_dataset/", 
            "text": "Uncertain value datasets\n\n\n\n\nDocumentation\n\n\n#\n\n\nUncertainData\n.\nUncertainDatasets\n.\nUncertainValueDataset\n \n \nType\n.\n\n\n1\nUncertainValueDataset\n\n\n\n\n\n\n\nA dataset of uncertain values.\n\n\nFields\n\n\n\n\nvalues\n::\nAbstractVector\n{\n:\nAbstractUncertainValue\n}\n: The uncertain values. Each value is   represented by an \nAbstractUncertainValue\n.\n\n\n\n\nsource\n\n\n\n\nDescription\n\n\nUncertainValueDataset\ns is an uncertain dataset type that has no explicit index  associated with its uncertain values. This type may come with some extra functionality  that the generic \nUncertainDataset\n type does not support. \n\n\nUse this type when you want to be explicit about the values representing data values, as opposed to \nindices\n. \n\n\n\n\nDefining uncertain value datasets\n\n\n\n\nExample 1: constructing an \nUncertainValueDataset\n from uncertain values\n\n\nLet's create a random walk and pretend it represents fluctuations in the mean of an observed dataset. Assume that each data point is normally distributed, and that the \ni\ni\n-th observation has standard deviation \n\\sigma_i \\in [0.3, 0.5]\n\\sigma_i \\in [0.3, 0.5]\n.\n\n\nRepresenting these data as an \nUncertainValueDataset\n is done as follows:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\no1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0\n,\n \n0.5\n)\n\n\no2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2.0\n,\n \n0.1\n)\n\n\no3\n \n=\n \nUncertainValue\n(\nUniform\n,\n \n0\n,\n \n4\n)\n\n\no4\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nrand\n(\n100\n))\n\n\no5\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n4\n,\n \n5\n)\n\n\no6\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n4\n,\n \n5\n)\n\n\no7\n \n=\n \nUncertainValue\n(\nFrechet\n,\n \n1\n,\n \n2\n)\n\n\no8\n \n=\n \nUncertainValue\n(\nBetaPrime\n,\n \n1\n,\n \n2\n)\n\n\no9\n \n=\n \nUncertainValue\n(\nBetaBinomial\n,\n \n10\n,\n \n3\n,\n \n2\n)\n\n\no10\n \n=\n \nUncertainValue\n(\nBinomial\n,\n \n10\n,\n \n0.3\n)\n\n\n\nuvals\n \n=\n \n[\no1\n,\n \no2\n,\n \no3\n,\n \no4\n,\n \no5\n,\n \no6\n,\n \no7\n,\n \no8\n,\n \no9\n,\n \no10\n]\n\n\nd\n \n=\n \nUncertainValueDataset\n(\nuvals\n)\n\n\n\n\n\n\n\nThe built-in plot recipes makes it a breeze to plot the dataset. Here, we'll plot the  20\nth\n to 80\nth\n percentile range error bars. \n\n\n1\nplot\n(\nd\n,\n \n[\n0.2\n,\n \n0.8\n])", 
            "title": "Uncertain value dataset"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_value_dataset/#uncertain_value_datasets", 
            "text": "", 
            "title": "Uncertain value datasets"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_value_dataset/#documentation", 
            "text": "#  UncertainData . UncertainDatasets . UncertainValueDataset     Type .  1 UncertainValueDataset    A dataset of uncertain values.  Fields   values :: AbstractVector { : AbstractUncertainValue } : The uncertain values. Each value is   represented by an  AbstractUncertainValue .   source", 
            "title": "Documentation"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_value_dataset/#description", 
            "text": "UncertainValueDataset s is an uncertain dataset type that has no explicit index  associated with its uncertain values. This type may come with some extra functionality  that the generic  UncertainDataset  type does not support.   Use this type when you want to be explicit about the values representing data values, as opposed to  indices .", 
            "title": "Description"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_value_dataset/#defining_uncertain_value_datasets", 
            "text": "", 
            "title": "Defining uncertain value datasets"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_value_dataset/#example_1_constructing_an_uncertainvaluedataset_from_uncertain_values", 
            "text": "Let's create a random walk and pretend it represents fluctuations in the mean of an observed dataset. Assume that each data point is normally distributed, and that the  i i -th observation has standard deviation  \\sigma_i \\in [0.3, 0.5] \\sigma_i \\in [0.3, 0.5] .  Representing these data as an  UncertainValueDataset  is done as follows:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 o1   =   UncertainValue ( Normal ,   0 ,   0.5 )  o2   =   UncertainValue ( Normal ,   2.0 ,   0.1 )  o3   =   UncertainValue ( Uniform ,   0 ,   4 )  o4   =   UncertainValue ( Uniform ,   rand ( 100 ))  o5   =   UncertainValue ( Beta ,   4 ,   5 )  o6   =   UncertainValue ( Gamma ,   4 ,   5 )  o7   =   UncertainValue ( Frechet ,   1 ,   2 )  o8   =   UncertainValue ( BetaPrime ,   1 ,   2 )  o9   =   UncertainValue ( BetaBinomial ,   10 ,   3 ,   2 )  o10   =   UncertainValue ( Binomial ,   10 ,   0.3 )  uvals   =   [ o1 ,   o2 ,   o3 ,   o4 ,   o5 ,   o6 ,   o7 ,   o8 ,   o9 ,   o10 ]  d   =   UncertainValueDataset ( uvals )    The built-in plot recipes makes it a breeze to plot the dataset. Here, we'll plot the  20 th  to 80 th  percentile range error bars.   1 plot ( d ,   [ 0.2 ,   0.8 ])", 
            "title": "Example 1: constructing an UncertainValueDataset from uncertain values"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/", 
            "text": "Uncertain index-value datasets\n\n\n\n\nDocumentation\n\n\n#\n\n\nUncertainData\n.\nUncertainDatasets\n.\nUncertainIndexValueDataset\n \n \nType\n.\n\n\n1\n2\n3\nUncertainIndexValueDataset\n{\n\n    \nIDXTYP\n:\nAbstractUncertainIndexDataset\n,\n \n    \nVALSTYP\n:\nAbstractUncertainValueDataset\n}\n\n\n\n\n\n\n\nA generic dataset type consisting of a set of uncertain \nindices\n (e.g. time, depth, order, etc...) and a set of uncertain \nvalues\n. \n\n\nThe i-th index is assumed to correspond to the i-th value. For example, if  \ndata\n is an instance of a \nUncertainIndexValueDataset\n, then \n\n\n\n\ndata\n.\nindices\n[\n2\n]\n is the index for the value \ndata\n.\nvalues\n[\n2\n]\n\n\ndata\n.\nvalues\n[\n7\n]\n is the value for the index \ndata\n.\nindices\n[\n7\n]\n.\n\n\ndata\n[\n3\n]\n is an index-value tuple \n(\ndata\n.\nindices\n[\n3\n],\n \ndata\n.\nvalues\n[\n3\n])\n.\n\n\n\n\nFields\n\n\n\n\nindices\n::\nT\n \nwhere\n \n{\nT\n \n:\n \nAbstractUncertainIndexDataset\n}\n: The uncertain indices,   represented by some type of uncertain index dataset.\n\n\nvalues\n::\nT\n  \nwhere\n \n{\nT\n \n:\n \nAbstractUncertainValueDataset\n}\n: The uncertain values,   represented by some type of uncertain index dataset.\n\n\n\n\nExample\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n# Simulate some data values measured a specific times.\n\n\ntimes\n \n=\n \n1\n:\n100\n\n\nvalues\n \n=\n \nsin\n.\n(\n0.0\n:\n0.1\n:\n100.0\n)\n\n\n\n# Assume the data were measured by a device with normally distributed\n\n\n# measurement uncertainties with fluctuating standard deviations\n\n\n\u03c3_range\n \n=\n \n(\n0.1\n,\n \n0.7\n)\n\n\n\nuncertain_values\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \nval\n,\n \nrand\n(\nUniform\n(\n\u03c3_range\n...\n)))\n \n    \nfor\n \nval\n \nin\n \nvalues\n]\n\n\n\n# Assume the clock used to record the times is uncertain, but with uniformly \n\n\n# distributed noise that doesn\nt change through time.\n\n\nuncertain_times\n \n=\n \n[\nUncertainValue\n(\nUniform\n,\n \nt\n-\n0.1\n,\n \nt\n+\n0.1\n)\n \nfor\n \nt\n \nin\n \ntimes\n]\n\n\n\n# Pair the time-value data. If vectors are provided to the constructor,\n\n\n# the first will be interpreted as the indices and the second as the values.\n\n\ndata\n \n=\n \nUncertainIndexValueDataset\n(\nuncertain_times\n,\n \nuncertain_values\n)\n\n\n\n# A safer option is to first convert to UncertainIndexDataset and \n\n\n# UncertainValueDataset, so you don\nt accidentally mix the indices \n\n\n# and the values.\n\n\nuidxs\n \n=\n \nUncertainIndexDataset\n(\nuncertain_times\n)\n\n\nuvals\n \n=\n \nUncertainValueDataset\n(\nuncertain_values\n)\n\n\n\ndata\n \n=\n \nUncertainIndexValueDataset\n(\nuidxs\n,\n \nuvals\n)\n\n\n\n\n\n\n\nsource\n\n\n\n\nDescription\n\n\nUncertainIndexValueDataset\ns have uncertainties associated with both the  indices (e.g. time, depth, etc) and the values of the data points.\n\n\n\n\nDefining an uncertain index-value dataset\n\n\n\n\nExample 1\n\n\n\n\nDefining the values\n\n\nLet's start by defining the uncertain data values and collecting them in  an \nUncertainValueDataset\n.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nUncertainData\n,\n \nPlots\n \n\ngr\n()\n\n\nr1\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \nrand\n(),\n \nrand\n())\n \nfor\n \ni\n \n=\n \n1\n:\n10\n]\n\n\nr2\n \n=\n \nUncertainValue\n(\nrand\n(\n10000\n))\n\n\nr3\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nrand\n(\n10000\n))\n\n\nr4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n-\n0.1\n,\n \n0.5\n)\n\n\nr5\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n0.4\n,\n \n0.8\n)\n\n\n\nu_values\n \n=\n \n[\nr1\n;\n \nr2\n;\n \nr3\n;\n \nr4\n;\n \nr5\n]\n\n\nudata\n \n=\n \nUncertainValueDataset\n(\nu_values\n);\n\n\n\n\n\n\n\n\n\nDefining the indices\n\n\nThe values were measures at some time indices by an inaccurate clock, so that the times  of measuring are normally distributed values with fluctuating standard deviations.\n\n\n1\n2\n3\nu_timeindices\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \ni\n,\n \nrand\n(\nUniform\n(\n0\n,\n \n1\n)))\n \n    \nfor\n \ni\n \n=\n \n1\n:\nlength\n(\nudata\n)]\n\n\nuindices\n \n=\n \nUncertainIndexDataset\n(\nu_timeindices\n);\n\n\n\n\n\n\n\n\n\nCombinining the indices and values\n\n\nNow, combine the uncertain time indices and measurements into an  \nUncertainIndexValueDataset\n.\n\n\n1\nx\n \n=\n \nUncertainIndexValueDataset\n(\nuindices\n,\n \nudata\n)\n\n\n\n\n\n\n\nThe built-in plot recipes make it easy to visualize the dataset.  By default, plotting the dataset plots the median value of the index and the measurement  (only for scatter plots), along with the 33\nrd\n to 67\nth\n percentile range error bars in both  directions.\n\n\n1\nplot\n(\nx\n)\n\n\n\n\n\n\n\n\n\nYou can also tune the error bars by calling  \nplot\n(\nudata\n::\nUncertainIndexValueDataset\n,\n \nidx_quantiles\n,\n \nval_quantiles\n)\n, explicitly  specifying the quantiles in each direction, like so:\n\n\n1\nplot\n(\nx\n,\n \n[\n0.05\n,\n \n0.95\n],\n \n[\n0.05\n,\n \n0.95\n])\n\n\n\n\n\n\n\n\n\n\n\nExample 2\n\n\n\n\nDefining the indices\n\n\nSay we had a dataset of 20 values for which the uncertainties are normally distributed  with increasing standard deviation through time.\n\n\n1\n2\n3\ntime_inds\n \n=\n \n1\n:\n13\n\n\nuvals\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \nind\n,\n \nrand\n(\nUniform\n())\n \n+\n \n(\nind\n \n/\n \n6\n))\n \nfor\n \nind\n \nin\n \ntime_inds\n]\n\n\ninds\n \n=\n \nUncertainIndexDataset\n(\nuvals\n)\n\n\n\n\n\n\n\nThat's it. We can also plot the 33\nrd\n to 67\nth\n percentile range for the indices.\n\n\n1\nplot\n(\ninds\n,\n \n[\n0\n.\n33\n,\n \n0\n.\n67\n])\n\n\n\n\n\n\n\n\n\n\n\nDefining the values\n\n\nLet's define some uncertain values that are associated with the indices.\n\n\n1\n2\n3\n4\n5\n6\nu1\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nrand\n(\nGamma\n(),\n \n500\n))\n\n\nu2\n \n=\n \nUncertainValue\n(\nrand\n(\nMixtureModel\n([\nNormal\n(\n1\n,\n \n0.3\n),\n \nNormal\n(\n0.1\n,\n \n0.1\n)]),\n \n500\n))\n\n\nuvals3\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \nrand\n(),\n \nrand\n())\n \nfor\n \ni\n \n=\n \n1\n:\n11\n]\n\n\n\nmeasurements\n \n=\n \n[\nu1\n;\n \nu2\n;\n \nuvals3\n]\n\n\ndatavals\n \n=\n \nUncertainValueDataset\n(\nmeasurements\n)\n\n\n\n\n\n\n\n\n\n\n\nCombinining the indices and values\n\n\nNow, we combine the indices and the corresponding data.\n\n\n1\nd\n \n=\n \nUncertainIndexValueDataset\n(\ninds\n,\n \ndatavals\n)\n\n\n\n\n\n\n\nPlot the dataset with error bars in both directions, using the 20\nth\n to 80\nth\n percentile  range for the indices and the 33\nrd\n to 67\nth\n percentile range for the data values. \n\n\n1\nplot\n(\nd\n,\n \n[\n0.2\n,\n \n0.8\n],\n \n[\n0.33\n,\n \n0.67\n])", 
            "title": "Uncertain index-value dataset"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#uncertain_index-value_datasets", 
            "text": "", 
            "title": "Uncertain index-value datasets"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#documentation", 
            "text": "#  UncertainData . UncertainDatasets . UncertainIndexValueDataset     Type .  1\n2\n3 UncertainIndexValueDataset { \n     IDXTYP : AbstractUncertainIndexDataset ,  \n     VALSTYP : AbstractUncertainValueDataset }    A generic dataset type consisting of a set of uncertain  indices  (e.g. time, depth, order, etc...) and a set of uncertain  values .   The i-th index is assumed to correspond to the i-th value. For example, if   data  is an instance of a  UncertainIndexValueDataset , then    data . indices [ 2 ]  is the index for the value  data . values [ 2 ]  data . values [ 7 ]  is the value for the index  data . indices [ 7 ] .  data [ 3 ]  is an index-value tuple  ( data . indices [ 3 ],   data . values [ 3 ]) .   Fields   indices :: T   where   { T   :   AbstractUncertainIndexDataset } : The uncertain indices,   represented by some type of uncertain index dataset.  values :: T    where   { T   :   AbstractUncertainValueDataset } : The uncertain values,   represented by some type of uncertain index dataset.   Example   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26 # Simulate some data values measured a specific times.  times   =   1 : 100  values   =   sin . ( 0.0 : 0.1 : 100.0 )  # Assume the data were measured by a device with normally distributed  # measurement uncertainties with fluctuating standard deviations  \u03c3_range   =   ( 0.1 ,   0.7 )  uncertain_values   =   [ UncertainValue ( Normal ,   val ,   rand ( Uniform ( \u03c3_range ... )))  \n     for   val   in   values ]  # Assume the clock used to record the times is uncertain, but with uniformly   # distributed noise that doesn t change through time.  uncertain_times   =   [ UncertainValue ( Uniform ,   t - 0.1 ,   t + 0.1 )   for   t   in   times ]  # Pair the time-value data. If vectors are provided to the constructor,  # the first will be interpreted as the indices and the second as the values.  data   =   UncertainIndexValueDataset ( uncertain_times ,   uncertain_values )  # A safer option is to first convert to UncertainIndexDataset and   # UncertainValueDataset, so you don t accidentally mix the indices   # and the values.  uidxs   =   UncertainIndexDataset ( uncertain_times )  uvals   =   UncertainValueDataset ( uncertain_values )  data   =   UncertainIndexValueDataset ( uidxs ,   uvals )    source", 
            "title": "Documentation"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#description", 
            "text": "UncertainIndexValueDataset s have uncertainties associated with both the  indices (e.g. time, depth, etc) and the values of the data points.", 
            "title": "Description"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#defining_an_uncertain_index-value_dataset", 
            "text": "", 
            "title": "Defining an uncertain index-value dataset"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#example_1", 
            "text": "", 
            "title": "Example 1"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#defining_the_values", 
            "text": "Let's start by defining the uncertain data values and collecting them in  an  UncertainValueDataset .   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   UncertainData ,   Plots   gr ()  r1   =   [ UncertainValue ( Normal ,   rand (),   rand ())   for   i   =   1 : 10 ]  r2   =   UncertainValue ( rand ( 10000 ))  r3   =   UncertainValue ( Uniform ,   rand ( 10000 ))  r4   =   UncertainValue ( Normal ,   - 0.1 ,   0.5 )  r5   =   UncertainValue ( Gamma ,   0.4 ,   0.8 )  u_values   =   [ r1 ;   r2 ;   r3 ;   r4 ;   r5 ]  udata   =   UncertainValueDataset ( u_values );", 
            "title": "Defining the values"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#defining_the_indices", 
            "text": "The values were measures at some time indices by an inaccurate clock, so that the times  of measuring are normally distributed values with fluctuating standard deviations.  1\n2\n3 u_timeindices   =   [ UncertainValue ( Normal ,   i ,   rand ( Uniform ( 0 ,   1 )))  \n     for   i   =   1 : length ( udata )]  uindices   =   UncertainIndexDataset ( u_timeindices );", 
            "title": "Defining the indices"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#combinining_the_indices_and_values", 
            "text": "Now, combine the uncertain time indices and measurements into an   UncertainIndexValueDataset .  1 x   =   UncertainIndexValueDataset ( uindices ,   udata )    The built-in plot recipes make it easy to visualize the dataset.  By default, plotting the dataset plots the median value of the index and the measurement  (only for scatter plots), along with the 33 rd  to 67 th  percentile range error bars in both  directions.  1 plot ( x )     You can also tune the error bars by calling   plot ( udata :: UncertainIndexValueDataset ,   idx_quantiles ,   val_quantiles ) , explicitly  specifying the quantiles in each direction, like so:  1 plot ( x ,   [ 0.05 ,   0.95 ],   [ 0.05 ,   0.95 ])", 
            "title": "Combinining the indices and values"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#example_2", 
            "text": "", 
            "title": "Example 2"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#defining_the_indices_1", 
            "text": "Say we had a dataset of 20 values for which the uncertainties are normally distributed  with increasing standard deviation through time.  1\n2\n3 time_inds   =   1 : 13  uvals   =   [ UncertainValue ( Normal ,   ind ,   rand ( Uniform ())   +   ( ind   /   6 ))   for   ind   in   time_inds ]  inds   =   UncertainIndexDataset ( uvals )    That's it. We can also plot the 33 rd  to 67 th  percentile range for the indices.  1 plot ( inds ,   [ 0 . 33 ,   0 . 67 ])", 
            "title": "Defining the indices"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#defining_the_values_1", 
            "text": "Let's define some uncertain values that are associated with the indices.  1\n2\n3\n4\n5\n6 u1   =   UncertainValue ( Gamma ,   rand ( Gamma (),   500 ))  u2   =   UncertainValue ( rand ( MixtureModel ([ Normal ( 1 ,   0.3 ),   Normal ( 0.1 ,   0.1 )]),   500 ))  uvals3   =   [ UncertainValue ( Normal ,   rand (),   rand ())   for   i   =   1 : 11 ]  measurements   =   [ u1 ;   u2 ;   uvals3 ]  datavals   =   UncertainValueDataset ( measurements )", 
            "title": "Defining the values"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_indexvalue_dataset/#combinining_the_indices_and_values_1", 
            "text": "Now, we combine the indices and the corresponding data.  1 d   =   UncertainIndexValueDataset ( inds ,   datavals )    Plot the dataset with error bars in both directions, using the 20 th  to 80 th  percentile  range for the indices and the 33 rd  to 67 th  percentile range for the data values.   1 plot ( d ,   [ 0.2 ,   0.8 ],   [ 0.33 ,   0.67 ])", 
            "title": "Combinining the indices and values"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_dataset/", 
            "text": "UncertainDataset\ns is a generic uncertain dataset type that has no explicit index  associated with its uncertain values.\n\n\nIt inherits all the behaviour of \nAbstractUncertainValueDataset\n, but may lack some  functionality that an \nUncertainValueDataset\n has.\n\n\nIf you don't care about distinguishing between  indices and data values, constructing instances of this data type requires five less key  presses than \nUncertainValueDataset\n.\n\n\n\n\nDocumentation\n\n\n#\n\n\nUncertainData\n.\nUncertainDatasets\n.\nUncertainDataset\n \n \nType\n.\n\n\n1\nUncertainDataset\n\n\n\n\n\n\n\nGeneric dataset containing uncertain values.\n\n\nFields\n\n\n\n\nvalues\n::\nAbstractVector\n{\n:\nAbstractUncertainValue\n}\n: The uncertain values.\n\n\n\n\nsource\n\n\n\n\nDefining an \nUncertainDataset\n from a collection of uncertain values\n\n\nLet's create a random walk and pretend it represents fluctuations in the mean of an observed dataset. Assume that each data point is normally distributed, and that the \ni\ni\n-th observation has standard deviation \n\\sigma_i \\in [0.3, 0.5]\n\\sigma_i \\in [0.3, 0.5]\n.\n\n\nRepresenting these data as an \nUncertainDataset\n is done as follows:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\nusing\n \nUncertainData\n,\n \nPlots\n\n\n\n# Create a random walk of 55 steps\n\n\nn\n \n=\n \n55\n\n\nrw\n \n=\n \ncumsum\n(\nrand\n(\nNormal\n(),\n \nn\n))\n\n\n\n# Represent each value of the random walk as an uncertain value and\n\n\n# collect them in an UncertainDataset\n\n\ndist\n \n=\n \nUniform\n(\n0.3\n,\n \n0.5\n)\n\n\nuncertainvals\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \nrw\n[\ni\n],\n \nrand\n(\ndist\n))\n \nfor\n \ni\n \n=\n \n1\n:\nn\n]\n\n\nD\n \n=\n \nUncertainDataset\n(\nuncertainvals\n)\n\n\n\n\n\n\n\nBy default, plotting the dataset will plot the median values (only for scatter plots) along with the 33\nrd\n to 67\nth\n percentile range error bars.\n\n\n1\nplot\n(\nD\n)\n\n\n\n\n\n\n\n\n\nYou can customize the error bars by explicitly providing the quantiles:\n\n\n1\nplot\n(\nD\n,\n \n[\n0.05\n,\n \n0.95\n])\n\n\n\n\n\n\n\n\n\n\n\nExample 2: mixing different types of uncertain values\n\n\nMixing different types of uncertain values also works. Let's create a dataset of uncertain values constructed in different ways.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nusing\n \nUncertainData\n,\n \nDistributions\n,\n \nPlots\n\n\n\n# Theoretical distributions\n\n\no1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0\n,\n \n0.5\n)\n\n\no2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2\n,\n \n0.3\n)\n\n\no3\n \n=\n \nUncertainValue\n(\nUniform\n,\n \n0\n,\n \n4\n)\n\n\n\n# Theoretical distributions fitted to data\n\n\no4\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nrand\n(\nUniform\n(),\n \n100\n))\n\n\no5\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nrand\n(\nGamma\n(\n2\n,\n \n3\n),\n \n5000\n))\n\n\n\n# Kernel density estimated distributions for some more complex data.\n\n\nM1\n \n=\n \nMixtureModel\n([\nNormal\n(\n-\n5\n,\n \n0.5\n),\n \nGamma\n(\n2\n,\n \n5\n),\n \nNormal\n(\n12\n,\n \n0.2\n)])\n\n\nM2\n \n=\n \nMixtureModel\n([\nNormal\n(\n-\n2\n,\n \n0.1\n),\n \nNormal\n(\n1\n,\n \n0.2\n)])\n\n\no6\n \n=\n \nUncertainValue\n(\nrand\n(\nM1\n,\n \n1000\n))\n\n\no7\n \n=\n \nUncertainValue\n(\nrand\n(\nM2\n,\n \n1000\n))\n\n\n\nD\n \n=\n \nUncertainDataset\n([\no1\n,\n \no2\n,\n \no3\n,\n \no4\n,\n \no5\n,\n \no6\n,\n \no7\n])\n\n\n\n\n\n\n\nNow, plot the uncertain dataset.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nusing\n \nPlots\n\n\n# Initialise the plot\n\n\np\n \n=\n \nplot\n(\nlegend\n \n=\n \nfalse\n,\n \nxlabel\n \n=\n \ntime step\n,\n \nylabel\n \n=\n \nvalue\n)\n\n\n\n# Plot the mean of the dataset\n\n\nplot!\n([\nmedian\n(\nD\n[\ni\n])\n \nfor\n \ni\n \n=\n \n1\n:\nlength\n(\nD\n)],\n \nlabel\n \n=\n \nmean\n,\n \nlc\n \n=\n \n:\nblue\n,\n \nlw\n \n=\n \n3\n)\n\n\n\nfor\n \ni\n \n=\n \n1\n:\n200\n\n    \nplot!\n(\np\n,\n \nresample\n(\nD\n),\n \nlw\n \n=\n \n0.4\n,\n \nl\u03b1\n \n=\n \n0.1\n,\n \nlc\n \n=\n \n:\nblack\n)\n\n\nend\n\n\n\np", 
            "title": "Generic uncertain dataset"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_dataset/#documentation", 
            "text": "#  UncertainData . UncertainDatasets . UncertainDataset     Type .  1 UncertainDataset    Generic dataset containing uncertain values.  Fields   values :: AbstractVector { : AbstractUncertainValue } : The uncertain values.   source", 
            "title": "Documentation"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_dataset/#defining_an_uncertaindataset_from_a_collection_of_uncertain_values", 
            "text": "Let's create a random walk and pretend it represents fluctuations in the mean of an observed dataset. Assume that each data point is normally distributed, and that the  i i -th observation has standard deviation  \\sigma_i \\in [0.3, 0.5] \\sigma_i \\in [0.3, 0.5] .  Representing these data as an  UncertainDataset  is done as follows:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 using   UncertainData ,   Plots  # Create a random walk of 55 steps  n   =   55  rw   =   cumsum ( rand ( Normal (),   n ))  # Represent each value of the random walk as an uncertain value and  # collect them in an UncertainDataset  dist   =   Uniform ( 0.3 ,   0.5 )  uncertainvals   =   [ UncertainValue ( Normal ,   rw [ i ],   rand ( dist ))   for   i   =   1 : n ]  D   =   UncertainDataset ( uncertainvals )    By default, plotting the dataset will plot the median values (only for scatter plots) along with the 33 rd  to 67 th  percentile range error bars.  1 plot ( D )     You can customize the error bars by explicitly providing the quantiles:  1 plot ( D ,   [ 0.05 ,   0.95 ])", 
            "title": "Defining an UncertainDataset from a collection of uncertain values"
        }, 
        {
            "location": "/uncertain_datasets/uncertain_dataset/#example_2_mixing_different_types_of_uncertain_values", 
            "text": "Mixing different types of uncertain values also works. Let's create a dataset of uncertain values constructed in different ways.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 using   UncertainData ,   Distributions ,   Plots  # Theoretical distributions  o1   =   UncertainValue ( Normal ,   0 ,   0.5 )  o2   =   UncertainValue ( Normal ,   2 ,   0.3 )  o3   =   UncertainValue ( Uniform ,   0 ,   4 )  # Theoretical distributions fitted to data  o4   =   UncertainValue ( Uniform ,   rand ( Uniform (),   100 ))  o5   =   UncertainValue ( Gamma ,   rand ( Gamma ( 2 ,   3 ),   5000 ))  # Kernel density estimated distributions for some more complex data.  M1   =   MixtureModel ([ Normal ( - 5 ,   0.5 ),   Gamma ( 2 ,   5 ),   Normal ( 12 ,   0.2 )])  M2   =   MixtureModel ([ Normal ( - 2 ,   0.1 ),   Normal ( 1 ,   0.2 )])  o6   =   UncertainValue ( rand ( M1 ,   1000 ))  o7   =   UncertainValue ( rand ( M2 ,   1000 ))  D   =   UncertainDataset ([ o1 ,   o2 ,   o3 ,   o4 ,   o5 ,   o6 ,   o7 ])    Now, plot the uncertain dataset.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 using   Plots  # Initialise the plot  p   =   plot ( legend   =   false ,   xlabel   =   time step ,   ylabel   =   value )  # Plot the mean of the dataset  plot! ([ median ( D [ i ])   for   i   =   1 : length ( D )],   label   =   mean ,   lc   =   : blue ,   lw   =   3 )  for   i   =   1 : 200 \n     plot! ( p ,   resample ( D ),   lw   =   0.4 ,   l\u03b1   =   0.1 ,   lc   =   : black )  end  p", 
            "title": "Example 2: mixing different types of uncertain values"
        }, 
        {
            "location": "/sampling_constraints/available_constraints/", 
            "text": "Available sampling constraints\n\n\nThe following sampling constraints are available. These constraints may be used in any resampling setting.\n\n\n\n\nStandard deviation\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nTruncateStd\n \n \nType\n.\n\n\n1\nTruncateStd\n(\nn\u03c3\n::\nNumber\n)\n\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated at the mean \u00b1 \nn\n\u03c3\n (\nn\n standard deviations).\n\n\nNotes\n\n\n\n\nBeware when you apply the \nTruncateStd\n constraint to a (usually a numeric)   population with a small value range. With \nn\n\u03c3\n small, you might end up with    a population mean \nbetween\n the actual values, so that the range    \n[\nmean\n(\npop\n)\n \n-\n \nn\n\u03c3\n*\nstd\n(\npop\n),\n \nmean\n(\npop\n)\n \n+\n \nn\n\u03c3\n*\nstd\n(\npop\n)]\n returns \nnothing\n.\n\n\n\n\nsource\n\n\n\n\nMinimum value\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nTruncateMinimum\n \n \nType\n.\n\n\n1\nTruncateMinimum\n(\nmin\n::\nNumber\n)\n\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated below at some specified minimum value.\n\n\nsource\n\n\n\n\nMaximum value\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nTruncateMaximum\n \n \nType\n.\n\n\n1\nTruncateMaximum\n(\nmax\n::\nNumber\n)\n\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated above at some specified maximum value.\n\n\nsource\n\n\n\n\nValue range\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nTruncateRange\n \n \nType\n.\n\n\n1\nTruncateRange\n(\nmin\n::\nNumber\n,\n \nmax\n::\nNumber\n)\n\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated at some range \n[\nmin\n,\n \nmax\n]\n.\n\n\nsource\n\n\n\n\nLower quantile\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nTruncateLowerQuantile\n \n \nType\n.\n\n\n1\nTruncateLowerQuantile\n(\nlower_quantile\n::\nFloat64\n)\n\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated below at some quantile.\n\n\nsource\n\n\n\n\nUpper quantile\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nTruncateUpperQuantile\n \n \nType\n.\n\n\n1\nTruncateUpperQuantile\n(\nupper_quantile\n::\nFloat64\n)\n\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated above at some quantile.\n\n\nsource\n\n\n\n\nQuantile range\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nTruncateQuantiles\n \n \nType\n.\n\n\n1\nTruncateQuantiles\n(\nlower_quantile\n::\nFloat64\n,\n \nupper_quantile\n::\nFloat64\n)\n\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated at some quantile quantile \n(\nlower_quantile\n,\n \nupper_quantile\n)\n.\n\n\nsource", 
            "title": "Regular constraints"
        }, 
        {
            "location": "/sampling_constraints/available_constraints/#available_sampling_constraints", 
            "text": "The following sampling constraints are available. These constraints may be used in any resampling setting.", 
            "title": "Available sampling constraints"
        }, 
        {
            "location": "/sampling_constraints/available_constraints/#standard_deviation", 
            "text": "#  UncertainData . SamplingConstraints . TruncateStd     Type .  1 TruncateStd ( n\u03c3 :: Number )    A constraint indicating that the distribution furnishing an uncertain value should be truncated at the mean \u00b1  n \u03c3  ( n  standard deviations).  Notes   Beware when you apply the  TruncateStd  constraint to a (usually a numeric)   population with a small value range. With  n \u03c3  small, you might end up with    a population mean  between  the actual values, so that the range     [ mean ( pop )   -   n \u03c3 * std ( pop ),   mean ( pop )   +   n \u03c3 * std ( pop )]  returns  nothing .   source", 
            "title": "Standard deviation"
        }, 
        {
            "location": "/sampling_constraints/available_constraints/#minimum_value", 
            "text": "#  UncertainData . SamplingConstraints . TruncateMinimum     Type .  1 TruncateMinimum ( min :: Number )    A constraint indicating that the distribution furnishing an uncertain value should be truncated below at some specified minimum value.  source", 
            "title": "Minimum value"
        }, 
        {
            "location": "/sampling_constraints/available_constraints/#maximum_value", 
            "text": "#  UncertainData . SamplingConstraints . TruncateMaximum     Type .  1 TruncateMaximum ( max :: Number )    A constraint indicating that the distribution furnishing an uncertain value should be truncated above at some specified maximum value.  source", 
            "title": "Maximum value"
        }, 
        {
            "location": "/sampling_constraints/available_constraints/#value_range", 
            "text": "#  UncertainData . SamplingConstraints . TruncateRange     Type .  1 TruncateRange ( min :: Number ,   max :: Number )    A constraint indicating that the distribution furnishing an uncertain value should be truncated at some range  [ min ,   max ] .  source", 
            "title": "Value range"
        }, 
        {
            "location": "/sampling_constraints/available_constraints/#lower_quantile", 
            "text": "#  UncertainData . SamplingConstraints . TruncateLowerQuantile     Type .  1 TruncateLowerQuantile ( lower_quantile :: Float64 )    A constraint indicating that the distribution furnishing an uncertain value should be truncated below at some quantile.  source", 
            "title": "Lower quantile"
        }, 
        {
            "location": "/sampling_constraints/available_constraints/#upper_quantile", 
            "text": "#  UncertainData . SamplingConstraints . TruncateUpperQuantile     Type .  1 TruncateUpperQuantile ( upper_quantile :: Float64 )    A constraint indicating that the distribution furnishing an uncertain value should be truncated above at some quantile.  source", 
            "title": "Upper quantile"
        }, 
        {
            "location": "/sampling_constraints/available_constraints/#quantile_range", 
            "text": "#  UncertainData . SamplingConstraints . TruncateQuantiles     Type .  1 TruncateQuantiles ( lower_quantile :: Float64 ,   upper_quantile :: Float64 )    A constraint indicating that the distribution furnishing an uncertain value should be truncated at some quantile quantile  ( lower_quantile ,   upper_quantile ) .  source", 
            "title": "Quantile range"
        }, 
        {
            "location": "/sampling_constraints/sequential_constraints/", 
            "text": "The following constraints may be used to impose sequential constraints when sampling a  collection of uncertain values element-wise. \n\n\n\n\nIncreasing\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nStrictlyIncreasing\n \n \nType\n.\n\n\n1\nStrictlyIncreasing\n\n\n\n\n\n\n\nA sampling constraint indicating element-wise sampling of the uncertain values in a dataset, such that the values of the draw are strictly increasing in magnitude.\n\n\nTypically used when there are known, physical constraints on the measurements. For example, geochemical measurements of sediments at different depths of a sediment core  are taken at physically separate depths in the core. Thus, the order of the indices cannot be flipped, and must be strictly decreasing/increasing. \n\n\nsource\n\n\n\n\nDecreasing\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nStrictlyDecreasing\n \n \nType\n.\n\n\n1\nStrictlyDecreasing\n\n\n\n\n\n\n\nA sampling constraint indicating element-wise sampling of the uncertain values in a dataset, such that the values of the draw are strictly decreasing in magnitude.\n\n\nTypically used when there are known, physical constraints on the measurements. For example, geochemical measurements of sediments at different depths of a sediment core  are taken at physically separate depths in the core. Thus, the order of the indices cannot be flipped, and must be strictly decreasing/increasing. \n\n\nsource", 
            "title": "List of sequential constraints"
        }, 
        {
            "location": "/sampling_constraints/sequential_constraints/#increasing", 
            "text": "#  UncertainData . SamplingConstraints . StrictlyIncreasing     Type .  1 StrictlyIncreasing    A sampling constraint indicating element-wise sampling of the uncertain values in a dataset, such that the values of the draw are strictly increasing in magnitude.  Typically used when there are known, physical constraints on the measurements. For example, geochemical measurements of sediments at different depths of a sediment core  are taken at physically separate depths in the core. Thus, the order of the indices cannot be flipped, and must be strictly decreasing/increasing.   source", 
            "title": "Increasing"
        }, 
        {
            "location": "/sampling_constraints/sequential_constraints/#decreasing", 
            "text": "#  UncertainData . SamplingConstraints . StrictlyDecreasing     Type .  1 StrictlyDecreasing    A sampling constraint indicating element-wise sampling of the uncertain values in a dataset, such that the values of the draw are strictly decreasing in magnitude.  Typically used when there are known, physical constraints on the measurements. For example, geochemical measurements of sediments at different depths of a sediment core  are taken at physically separate depths in the core. Thus, the order of the indices cannot be flipped, and must be strictly decreasing/increasing.   source", 
            "title": "Decreasing"
        }, 
        {
            "location": "/sampling_constraints/ordered_sequence_exists/", 
            "text": "There are a few built-in functions to check if your dataset allows the application of  certain \nsequential sampling constraints\n. These functions will check  whether a valid sequence through your collection of uncertain values exists, so that you  can know beforehand whether a particular resampling scheme is possible to apply to your data.\n\n\n\n\nStrictly increasing sequence\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nstrictly_increasing_sequence_exists\n \n \nFunction\n.\n\n\n1\n2\nstrictly_increasing_sequence_exists\n(\nudata\n::\nAbstractUncertainValueDataset\n;\n \n    \nquantiles\n \n=\n \n[\n0.0001\n,\n \n0.9999\n])\n\n\n\n\n\n\n\nDoes a path through the dataset exist? I.e, check that a strictly  increasing sequence can be found after first  constraining each distribution to the provided quantile range (this  is necessary because some distributions may have infinite support).\n\n\nsource\n\n\n\n\nStrictly decreasing sequence\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nstrictly_decreasing_sequence_exists\n \n \nFunction\n.\n\n\n1\n2\nstrictly_decreasing_sequence_exists\n(\nudata\n::\nAbstractUncertainValueDataset\n;\n\n    \nquantiles\n \n=\n \n[\n0.0001\n,\n \n0.9999\n])\n\n\n\n\n\n\n\nDoes a path through the dataset exist? I.e,  check that a strictly  decreasing sequence can be found after first  constraining each distribution to the provided quantile range (this  is necessary because some distributions may have infinite support).\n\n\nsource", 
            "title": "Existence of sequences"
        }, 
        {
            "location": "/sampling_constraints/ordered_sequence_exists/#strictly_increasing_sequence", 
            "text": "#  UncertainData . SamplingConstraints . strictly_increasing_sequence_exists     Function .  1\n2 strictly_increasing_sequence_exists ( udata :: AbstractUncertainValueDataset ;  \n     quantiles   =   [ 0.0001 ,   0.9999 ])    Does a path through the dataset exist? I.e, check that a strictly  increasing sequence can be found after first  constraining each distribution to the provided quantile range (this  is necessary because some distributions may have infinite support).  source", 
            "title": "Strictly increasing sequence"
        }, 
        {
            "location": "/sampling_constraints/ordered_sequence_exists/#strictly_decreasing_sequence", 
            "text": "#  UncertainData . SamplingConstraints . strictly_decreasing_sequence_exists     Function .  1\n2 strictly_decreasing_sequence_exists ( udata :: AbstractUncertainValueDataset ; \n     quantiles   =   [ 0.0001 ,   0.9999 ])    Does a path through the dataset exist? I.e,  check that a strictly  decreasing sequence can be found after first  constraining each distribution to the provided quantile range (this  is necessary because some distributions may have infinite support).  source", 
            "title": "Strictly decreasing sequence"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/", 
            "text": "Documentation\n\n\n#\n\n\nUncertainData\n.\nSamplingConstraints\n.\nconstrain\n \n \nMethod\n.\n\n\n1\nconstrain\n(\nuv\n::\nAbstractUncertainValue\n,\n \nconstraint\n::\nSamplingConstraint\n)\n\n\n\n\n\n\n\nApply the \nconstraint\n and truncate the support of the distribution furnishing the uncertain value \nuv\n. Returns a constrained uncertain value.\n\n\nsource\n\n\n\n\nExamples: constraining uncertain values\n\n\n\n\nTheoretical distributions\n\n\n\n\n\n\nTheoretical distribution\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nusing\n \nUncertainData\n,\n \nDistributions\n\n\n\n# Define an uncertain value furnished by a theoretical distribution\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1\n,\n \n0.5\n)\n\n\n\n# Constrain the support of the furnishing distribution using various\n\n\n# constraints\n\n\nuvc_lq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nuvc_uq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateUpperQuantile\n(\n0.8\n))\n\n\nuvc_q\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateQuantiles\n(\n0.2\n,\n \n0.8\n))\n\n\nuvc_min\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMinimum\n(\n0.5\n))\n\n\nuvc_max\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMaximum\n(\n1.5\n))\n\n\nuvc_range\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateRange\n(\n0.5\n,\n \n1.5\n))\n\n\n\n\n\n\n\n\n\n\nTheoretical distributions with fitted parameters\n\n\n\n\n\n\nTheoretical distribution with fitted parameters\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\nusing\n \nUncertainData\n,\n \nDistributions\n\n\n\n# Define an uncertain value furnished by a theoretical distribution with\n\n\n# parameters fitted to empirical data\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n-\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\n\n# Constrain the support of the furnishing distribution using various\n\n\n# constraints\n\n\nuvc_lq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nuvc_uq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateUpperQuantile\n(\n0.8\n))\n\n\nuvc_q\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateQuantiles\n(\n0.2\n,\n \n0.8\n))\n\n\nuvc_min\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMinimum\n(\n0.5\n))\n\n\nuvc_max\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMaximum\n(\n1.5\n))\n\n\nuvc_range\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateRange\n(\n0.5\n,\n \n1.5\n))\n\n\n\n\n\n\n\n\n\n\nKernel density estimated distributions\n\n\n\n\n\n\nKernel density estimated distribution\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n# Define an uncertain value furnished by a kernel density estimate to the\n\n\n# distribution of the empirical data\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nrand\n(\nUniform\n(\n10\n,\n \n15\n),\n \n1000\n))\n\n\n\n# Constrain the support of the furnishing distribution using various\n\n\n# constraints\n\n\nuvc_lq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nuvc_uq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateUpperQuantile\n(\n0.8\n))\n\n\nuvc_q\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateQuantiles\n(\n0.2\n,\n \n0.8\n))\n\n\nuvc_min\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMinimum\n(\n13\n))\n\n\nuvc_max\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMaximum\n(\n13\n))\n\n\nuvc_range\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateRange\n(\n11\n,\n \n12\n))\n\n\n\n\n\n\n\n\n\n\n(nested) weighted populations of uncertain values\n\n\nLet's define a complicated uncertain value that is defined by a nested weighted population.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n# Some subpopulations consisting of both scalar values and distributions\n\n\nsubpop1_members\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \n0\n,\n \n1\n),\n \nUncertainValue\n(\nUniform\n,\n \n-\n2\n,\n \n2\n),\n \n-\n5\n]\n\n\nsubpop2_members\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \n-\n2\n,\n \n1\n),\n \nUncertainValue\n(\nUniform\n,\n \n-\n6\n,\n \n-\n1\n),\n\n                    \n-\n3\n,\n \nUncertainValue\n(\nGamma\n,\n \n1\n,\n \n0.4\n)]\n\n\n\n# Define the probabilities of sampling the different population members within the \n\n\n# subpopulations. Weights are normalised, so we can input any numbers here indicating \n\n\n# relative importance\n\n\nsubpop1_probs\n \n=\n \n[\n1\n,\n \n2\n,\n \n1\n]\n\n\nsubpop2_probs\n \n=\n \n[\n0.1\n,\n \n0.2\n,\n \n0.3\n,\n \n0.1\n]\n\n\n\npop1\n \n=\n \nUncertainValue\n(\nsubpop1_members\n,\n \nsubpop1_probs\n)\n\n\npop2\n \n=\n \nUncertainValue\n(\nsubpop2_members\n,\n \nsubpop2_probs\n)\n\n\n\n# Define the probabilities of sampling the two subpopulations in the overall population.\n\n\npop_probs\n \n=\n \n[\n0.3\n,\n \n0.7\n]\n\n\n\n# Construct overall population\n\n\npop_mixed\n \n=\n \nUncertainValue\n([\npop1\n,\n \npop2\n],\n \npop_probs\n)\n\n\n\n\n\n\n\nNow we can draw samples from this nested population. Sampling directly from the  entire distribution is done by calling \nresample\n(\npop_mixed\n,\n \nn_draws\n)\n. However, in some cases we might want to constrain the sampling to some minimum, maximum  or range of values. You can do that by using sampling constraints.\n\n\n\n\nTruncateMinimum\n\n\nTo truncate the overall population below at some absolute value, use a \nTruncateMinimum\n sampling constraint.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nconstraint\n \n=\n \nTruncateMinimum\n(\n-\n1.1\n)\n\n\npop_mixed_constrained\n \n=\n \nconstrain\n(\npop_mixed\n,\n \nconstraint\n);\n\n\n\nn_draws\n \n=\n \n500\n\n\nx\n \n=\n \nresample\n(\npop_mixed\n,\n \nn_draws\n)\n\n\nxc\n \n=\n \nresample\n(\npop_mixed_constrained\n,\n \nn_draws\n)\n\n\n\np1\n \n=\n \nscatter\n(\nx\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling before constraint\n)\n\n\np2\n \n=\n \nscatter\n(\nxc\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling after constraint\n)\n\n\nhline!\n([\nconstraint\n.\nmin\n],\n \nlabel\n \n=\n \nTruncateMinimum(-1.1)\n)\n\n\nplot\n(\np1\n,\n \np2\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nboth\n,\n \nylims\n \n=\n \n(\n-\n3\n,\n \n3\n),\n \nms\n \n=\n \n1\n)\n\n\nxlabel!\n(\nSampling #\n);\n \nylabel!\n(\nValue\n)\n\n\n\n\n\n\n\n\n\n\n\nTruncateMaximum\n\n\nTo truncate the overall population above at some absolute value, use a \nTruncateMaximum\n sampling constraint.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nconstraint\n \n=\n \nTruncateMaximum\n(\n1.5\n)\n\n\npop_mixed_constrained\n \n=\n \nconstrain\n(\npop_mixed\n,\n \nconstraint\n);\n\n\n\nn_draws\n \n=\n \n500\n\n\nx\n \n=\n \nresample\n(\npop_mixed\n,\n \nn_draws\n)\n\n\nxc\n \n=\n \nresample\n(\npop_mixed_constrained\n,\n \nn_draws\n)\n\n\n\np1\n \n=\n \nscatter\n(\nx\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling before constraint\n)\n\n\np2\n \n=\n \nscatter\n(\nxc\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling after constraint\n)\n\n\nhline!\n([\nconstraint\n.\nmax\n],\n \nlabel\n \n=\n \nTruncateMaximum(1.5)\n)\n\n\nplot\n(\np1\n,\n \np2\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nboth\n,\n \nylims\n \n=\n \n(\n-\n3\n,\n \n3\n),\n \nms\n \n=\n \n1\n)\n\n\nxlabel!\n(\nSampling #\n);\n \nylabel!\n(\nValue\n)\n\n\n\n\n\n\n\n\n\n\n\nTruncateRange\n\n\nTo truncate the overall population above at some range of values, use a \nTruncateRange\n sampling constraint.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nconstraint\n \n=\n \nTruncateRange\n(\n-\n1.5\n,\n \n1.7\n)\n\n\npop_mixed_constrained\n \n=\n \nconstrain\n(\npop_mixed\n,\n \nconstraint\n);\n\n\n\nn_draws\n \n=\n \n500\n\n\nx\n \n=\n \nresample\n(\npop_mixed\n,\n \nn_draws\n)\n\n\nxc\n \n=\n \nresample\n(\npop_mixed_constrained\n,\n \nn_draws\n)\n\n\n\np1\n \n=\n \nscatter\n(\nx\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling before constraint\n)\n\n\np2\n \n=\n \nscatter\n(\nxc\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling after constraint\n)\n\n\nhline!\n([\nconstraint\n.\nmin\n,\n \nconstraint\n.\nmax\n],\n \nlabel\n \n=\n \nTruncateRange(-1.5, 1.7)\n)\n\n\n\nplot\n(\np1\n,\n \np2\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nboth\n,\n \nylims\n \n=\n \n(\n-\n3\n,\n \n3\n),\n \nms\n \n=\n \n1\n)\n\n\nxlabel!\n(\nSampling #\n);\n \nylabel!\n(\nValue\n)\n\n\n\n\n\n\n\n\n\n\n\nTruncateLowerQuantile\n\n\nTo truncate the overall population below at some quantile of  the overall population, use a \nTruncateLowerQuantile\n sampling constraint.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\nconstraint\n \n=\n \nTruncateLowerQuantile\n(\n0.2\n)\n\n\n\n# Constrain the population below at the lower 20th percentile\n\n\n# Resample the entire population (and its subpopulations) according to \n\n\n# their probabilities 30000 times to determine the percentile bound.\n\n\nn_draws\n \n=\n \n30000\n\n\npop_mixed_constrained\n \n=\n \nconstrain\n(\npop_mixed\n,\n \nconstraint\n,\n \nn_draws\n);\n\n\n\n# Calculate quantile using the same number of samples for plotting.\n\n\n# Will not be exactly the same as the quantile actually used for \n\n\n# truncating, except in the limit n -\n \u221e\n\n\nq\n \n=\n \nquantile\n(\nresample\n(\npop_mixed\n,\n \nn_draws\n),\n \nconstraint\n.\nlower_quantile\n)\n\n\n\nn_draws_plot\n \n=\n \n3000\n\n\nx\n \n=\n \nresample\n(\npop_mixed\n,\n \nn_draws_plot\n)\n\n\nxc\n \n=\n \nresample\n(\npop_mixed_constrained\n,\n \nn_draws_plot\n)\n\n\n\np1\n \n=\n \nscatter\n(\nx\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling before constraint\n)\n\n\np2\n \n=\n \nscatter\n(\nxc\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling after constraint\n)\n\n\nhline!\n([\nlq\n],\n \nlabel\n \n=\n \nTruncateLowerQuantile(0.2)\n)\n\n\nplot\n(\np1\n,\n \np2\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nboth\n,\n \nms\n \n=\n \n1\n,\n \nylims\n \n=\n \n(\n-\n6\n,\n \n4\n))\n\n\nxlabel!\n(\nSampling #\n);\n \nylabel!\n(\nValue\n)\n\n\n\n\n\n\n\n\n\n\n\nTruncateUpperQuantile\n\n\nTo truncate the overall population below at some quantile of  the overall population, use a \nTruncateUpperQuantile\n sampling constraint.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\nconstraint\n \n=\n \nTruncateUpperQuantile\n(\n0.8\n)\n\n\n\n# Constrain the population below at the lower 20th percentile\n\n\n# Resample the entire population (and its subpopulations) according to \n\n\n# their probabilities 30000 times to determine the percentile bound.\n\n\nn_resample_draws\n \n=\n \n30000\n\n\npop_mixed_constrained\n \n=\n \nconstrain\n(\npop_mixed\n,\n \nconstraint\n,\n \nn_resample_draws\n);\n\n\n\n# Calculate quantile using the same number of samples for plotting.\n\n\n# Will not be exactly the same as the quantile actually used for \n\n\n# truncating, except in the limit n_resample_draws -\n \u221e\n\n\nq\n \n=\n \nquantile\n(\nresample\n(\npop_mixed\n,\n \nn_resample_draws\n),\n \nconstraint\n.\nupper_quantile\n)\n\n\n\nn_plot_draws\n \n=\n \n3000\n\n\nx\n \n=\n \nresample\n(\npop_mixed\n,\n \nn_plot_draws\n)\n\n\nxc\n \n=\n \nresample\n(\npop_mixed_constrained\n,\n \nn_plot_draws\n)\n\n\n\np1\n \n=\n \nscatter\n(\nx\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling before constraint\n)\n\n\np2\n \n=\n \nscatter\n(\nxc\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling after constraint\n)\n\n\nhline!\n([\nq\n],\n \nlabel\n \n=\n \nTruncateUpperQuantile(0.8)\n)\n\n\nplot\n(\np1\n,\n \np2\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nboth\n,\n \nms\n \n=\n \n1\n,\n \nylims\n \n=\n \n(\n-\n6\n,\n \n4\n))\n\n\nxlabel!\n(\nSampling #\n);\n \nylabel!\n(\nValue\n)\n\n\n\n\n\n\n\n\n\n\n\nTruncateQuantiles\n\n\nTo truncate the overall population below at some quantile of  the overall population, use a \nTruncateQuantiles\n sampling constraint.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\nconstraint\n \n=\n \nTruncateQuantiles\n(\n0.2\n,\n \n0.8\n)\n\n\n\n# Constrain the population below at the lower 20th percentile\n\n\n# Resample the entire population (and its subpopulations) according to \n\n\n# their probabilities 30000 times to determine the percentile bound.\n\n\nn_resample_draws\n \n=\n \n30000\n\n\npop_mixed_constrained\n \n=\n \nconstrain\n(\npop_mixed\n,\n \nconstraint\n,\n \nn_resample_draws\n);\n\n\n\n# Calculate quantile using the same number of samples for plotting.\n\n\n# Will not be exactly the same as the quantile actually used for \n\n\n# truncating, except in the limit n_resample_draws -\n \u221e\n\n\ns\n \n=\n \nresample\n(\npop_mixed\n,\n \nn_resample_draws\n)\n\n\nqs\n \n=\n \nquantile\n(\ns\n,\n \n[\nconstraint\n.\nlower_quantile\n,\n \nconstraint\n.\nupper_quantile\n])\n\n\n\nn_plot_draws\n \n=\n \n3000\n\n\nx\n \n=\n \nresample\n(\npop_mixed\n,\n \nn_plot_draws\n)\n\n\nxc\n \n=\n \nresample\n(\npop_mixed_constrained\n,\n \nn_plot_draws\n)\n\n\n\np1\n \n=\n \nscatter\n(\nx\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling before constraint\n)\n\n\np2\n \n=\n \nscatter\n(\nxc\n,\n \nlabel\n \n=\n \n,\n \ntitle\n \n=\n \nresampling after constraint\n)\n\n\nhline!\n([\nqs\n],\n \nlabel\n \n=\n \nTruncateQuantiles(0.2, 0.8)\n)\n\n\n\nplot\n(\np1\n,\n \np2\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nboth\n,\n \nms\n \n=\n \n1\n,\n \nylims\n \n=\n \n(\n-\n6\n,\n \n4\n))\n\n\nxlabel!\n(\nSampling #\n);\n \nylabel!\n(\nValue\n)", 
            "title": "Constraining uncertain values"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#documentation", 
            "text": "#  UncertainData . SamplingConstraints . constrain     Method .  1 constrain ( uv :: AbstractUncertainValue ,   constraint :: SamplingConstraint )    Apply the  constraint  and truncate the support of the distribution furnishing the uncertain value  uv . Returns a constrained uncertain value.  source", 
            "title": "Documentation"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#examples_constraining_uncertain_values", 
            "text": "", 
            "title": "Examples: constraining uncertain values"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#theoretical_distributions", 
            "text": "Theoretical distribution   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 using   UncertainData ,   Distributions  # Define an uncertain value furnished by a theoretical distribution  uv   =   UncertainValue ( Normal ,   1 ,   0.5 )  # Constrain the support of the furnishing distribution using various  # constraints  uvc_lq   =   constrain ( uv ,   TruncateLowerQuantile ( 0.2 ))  uvc_uq   =   constrain ( uv ,   TruncateUpperQuantile ( 0.8 ))  uvc_q   =   constrain ( uv ,   TruncateQuantiles ( 0.2 ,   0.8 ))  uvc_min   =   constrain ( uv ,   TruncateMinimum ( 0.5 ))  uvc_max   =   constrain ( uv ,   TruncateMaximum ( 1.5 ))  uvc_range   =   constrain ( uv ,   TruncateRange ( 0.5 ,   1.5 ))", 
            "title": "Theoretical distributions"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#theoretical_distributions_with_fitted_parameters", 
            "text": "Theoretical distribution with fitted parameters   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14 using   UncertainData ,   Distributions  # Define an uncertain value furnished by a theoretical distribution with  # parameters fitted to empirical data  uv   =   UncertainValue ( Normal ,   rand ( Normal ( - 1 ,   0.2 ),   1000 ))  # Constrain the support of the furnishing distribution using various  # constraints  uvc_lq   =   constrain ( uv ,   TruncateLowerQuantile ( 0.2 ))  uvc_uq   =   constrain ( uv ,   TruncateUpperQuantile ( 0.8 ))  uvc_q   =   constrain ( uv ,   TruncateQuantiles ( 0.2 ,   0.8 ))  uvc_min   =   constrain ( uv ,   TruncateMinimum ( 0.5 ))  uvc_max   =   constrain ( uv ,   TruncateMaximum ( 1.5 ))  uvc_range   =   constrain ( uv ,   TruncateRange ( 0.5 ,   1.5 ))", 
            "title": "Theoretical distributions with fitted parameters"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#kernel_density_estimated_distributions", 
            "text": "Kernel density estimated distribution   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 # Define an uncertain value furnished by a kernel density estimate to the  # distribution of the empirical data  uv   =   UncertainValue ( UnivariateKDE ,   rand ( Uniform ( 10 ,   15 ),   1000 ))  # Constrain the support of the furnishing distribution using various  # constraints  uvc_lq   =   constrain ( uv ,   TruncateLowerQuantile ( 0.2 ))  uvc_uq   =   constrain ( uv ,   TruncateUpperQuantile ( 0.8 ))  uvc_q   =   constrain ( uv ,   TruncateQuantiles ( 0.2 ,   0.8 ))  uvc_min   =   constrain ( uv ,   TruncateMinimum ( 13 ))  uvc_max   =   constrain ( uv ,   TruncateMaximum ( 13 ))  uvc_range   =   constrain ( uv ,   TruncateRange ( 11 ,   12 ))", 
            "title": "Kernel density estimated distributions"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#nested_weighted_populations_of_uncertain_values", 
            "text": "Let's define a complicated uncertain value that is defined by a nested weighted population.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19 # Some subpopulations consisting of both scalar values and distributions  subpop1_members   =   [ UncertainValue ( Normal ,   0 ,   1 ),   UncertainValue ( Uniform ,   - 2 ,   2 ),   - 5 ]  subpop2_members   =   [ UncertainValue ( Normal ,   - 2 ,   1 ),   UncertainValue ( Uniform ,   - 6 ,   - 1 ), \n                     - 3 ,   UncertainValue ( Gamma ,   1 ,   0.4 )]  # Define the probabilities of sampling the different population members within the   # subpopulations. Weights are normalised, so we can input any numbers here indicating   # relative importance  subpop1_probs   =   [ 1 ,   2 ,   1 ]  subpop2_probs   =   [ 0.1 ,   0.2 ,   0.3 ,   0.1 ]  pop1   =   UncertainValue ( subpop1_members ,   subpop1_probs )  pop2   =   UncertainValue ( subpop2_members ,   subpop2_probs )  # Define the probabilities of sampling the two subpopulations in the overall population.  pop_probs   =   [ 0.3 ,   0.7 ]  # Construct overall population  pop_mixed   =   UncertainValue ([ pop1 ,   pop2 ],   pop_probs )    Now we can draw samples from this nested population. Sampling directly from the  entire distribution is done by calling  resample ( pop_mixed ,   n_draws ) . However, in some cases we might want to constrain the sampling to some minimum, maximum  or range of values. You can do that by using sampling constraints.", 
            "title": "(nested) weighted populations of uncertain values"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#truncateminimum", 
            "text": "To truncate the overall population below at some absolute value, use a  TruncateMinimum  sampling constraint.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 constraint   =   TruncateMinimum ( - 1.1 )  pop_mixed_constrained   =   constrain ( pop_mixed ,   constraint );  n_draws   =   500  x   =   resample ( pop_mixed ,   n_draws )  xc   =   resample ( pop_mixed_constrained ,   n_draws )  p1   =   scatter ( x ,   label   =   ,   title   =   resampling before constraint )  p2   =   scatter ( xc ,   label   =   ,   title   =   resampling after constraint )  hline! ([ constraint . min ],   label   =   TruncateMinimum(-1.1) )  plot ( p1 ,   p2 ,   layout   =   ( 2 ,   1 ),   link   =   : both ,   ylims   =   ( - 3 ,   3 ),   ms   =   1 )  xlabel! ( Sampling # );   ylabel! ( Value )", 
            "title": "TruncateMinimum"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#truncatemaximum", 
            "text": "To truncate the overall population above at some absolute value, use a  TruncateMaximum  sampling constraint.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 constraint   =   TruncateMaximum ( 1.5 )  pop_mixed_constrained   =   constrain ( pop_mixed ,   constraint );  n_draws   =   500  x   =   resample ( pop_mixed ,   n_draws )  xc   =   resample ( pop_mixed_constrained ,   n_draws )  p1   =   scatter ( x ,   label   =   ,   title   =   resampling before constraint )  p2   =   scatter ( xc ,   label   =   ,   title   =   resampling after constraint )  hline! ([ constraint . max ],   label   =   TruncateMaximum(1.5) )  plot ( p1 ,   p2 ,   layout   =   ( 2 ,   1 ),   link   =   : both ,   ylims   =   ( - 3 ,   3 ),   ms   =   1 )  xlabel! ( Sampling # );   ylabel! ( Value )", 
            "title": "TruncateMaximum"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#truncaterange", 
            "text": "To truncate the overall population above at some range of values, use a  TruncateRange  sampling constraint.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 constraint   =   TruncateRange ( - 1.5 ,   1.7 )  pop_mixed_constrained   =   constrain ( pop_mixed ,   constraint );  n_draws   =   500  x   =   resample ( pop_mixed ,   n_draws )  xc   =   resample ( pop_mixed_constrained ,   n_draws )  p1   =   scatter ( x ,   label   =   ,   title   =   resampling before constraint )  p2   =   scatter ( xc ,   label   =   ,   title   =   resampling after constraint )  hline! ([ constraint . min ,   constraint . max ],   label   =   TruncateRange(-1.5, 1.7) )  plot ( p1 ,   p2 ,   layout   =   ( 2 ,   1 ),   link   =   : both ,   ylims   =   ( - 3 ,   3 ),   ms   =   1 )  xlabel! ( Sampling # );   ylabel! ( Value )", 
            "title": "TruncateRange"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#truncatelowerquantile", 
            "text": "To truncate the overall population below at some quantile of  the overall population, use a  TruncateLowerQuantile  sampling constraint.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22 constraint   =   TruncateLowerQuantile ( 0.2 )  # Constrain the population below at the lower 20th percentile  # Resample the entire population (and its subpopulations) according to   # their probabilities 30000 times to determine the percentile bound.  n_draws   =   30000  pop_mixed_constrained   =   constrain ( pop_mixed ,   constraint ,   n_draws );  # Calculate quantile using the same number of samples for plotting.  # Will not be exactly the same as the quantile actually used for   # truncating, except in the limit n -  \u221e  q   =   quantile ( resample ( pop_mixed ,   n_draws ),   constraint . lower_quantile )  n_draws_plot   =   3000  x   =   resample ( pop_mixed ,   n_draws_plot )  xc   =   resample ( pop_mixed_constrained ,   n_draws_plot )  p1   =   scatter ( x ,   label   =   ,   title   =   resampling before constraint )  p2   =   scatter ( xc ,   label   =   ,   title   =   resampling after constraint )  hline! ([ lq ],   label   =   TruncateLowerQuantile(0.2) )  plot ( p1 ,   p2 ,   layout   =   ( 2 ,   1 ),   link   =   : both ,   ms   =   1 ,   ylims   =   ( - 6 ,   4 ))  xlabel! ( Sampling # );   ylabel! ( Value )", 
            "title": "TruncateLowerQuantile"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#truncateupperquantile", 
            "text": "To truncate the overall population below at some quantile of  the overall population, use a  TruncateUpperQuantile  sampling constraint.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22 constraint   =   TruncateUpperQuantile ( 0.8 )  # Constrain the population below at the lower 20th percentile  # Resample the entire population (and its subpopulations) according to   # their probabilities 30000 times to determine the percentile bound.  n_resample_draws   =   30000  pop_mixed_constrained   =   constrain ( pop_mixed ,   constraint ,   n_resample_draws );  # Calculate quantile using the same number of samples for plotting.  # Will not be exactly the same as the quantile actually used for   # truncating, except in the limit n_resample_draws -  \u221e  q   =   quantile ( resample ( pop_mixed ,   n_resample_draws ),   constraint . upper_quantile )  n_plot_draws   =   3000  x   =   resample ( pop_mixed ,   n_plot_draws )  xc   =   resample ( pop_mixed_constrained ,   n_plot_draws )  p1   =   scatter ( x ,   label   =   ,   title   =   resampling before constraint )  p2   =   scatter ( xc ,   label   =   ,   title   =   resampling after constraint )  hline! ([ q ],   label   =   TruncateUpperQuantile(0.8) )  plot ( p1 ,   p2 ,   layout   =   ( 2 ,   1 ),   link   =   : both ,   ms   =   1 ,   ylims   =   ( - 6 ,   4 ))  xlabel! ( Sampling # );   ylabel! ( Value )", 
            "title": "TruncateUpperQuantile"
        }, 
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#truncatequantiles", 
            "text": "To truncate the overall population below at some quantile of  the overall population, use a  TruncateQuantiles  sampling constraint.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24 constraint   =   TruncateQuantiles ( 0.2 ,   0.8 )  # Constrain the population below at the lower 20th percentile  # Resample the entire population (and its subpopulations) according to   # their probabilities 30000 times to determine the percentile bound.  n_resample_draws   =   30000  pop_mixed_constrained   =   constrain ( pop_mixed ,   constraint ,   n_resample_draws );  # Calculate quantile using the same number of samples for plotting.  # Will not be exactly the same as the quantile actually used for   # truncating, except in the limit n_resample_draws -  \u221e  s   =   resample ( pop_mixed ,   n_resample_draws )  qs   =   quantile ( s ,   [ constraint . lower_quantile ,   constraint . upper_quantile ])  n_plot_draws   =   3000  x   =   resample ( pop_mixed ,   n_plot_draws )  xc   =   resample ( pop_mixed_constrained ,   n_plot_draws )  p1   =   scatter ( x ,   label   =   ,   title   =   resampling before constraint )  p2   =   scatter ( xc ,   label   =   ,   title   =   resampling after constraint )  hline! ([ qs ],   label   =   TruncateQuantiles(0.2, 0.8) )  plot ( p1 ,   p2 ,   layout   =   ( 2 ,   1 ),   link   =   : both ,   ms   =   1 ,   ylims   =   ( - 6 ,   4 ))  xlabel! ( Sampling # );   ylabel! ( Value )", 
            "title": "TruncateQuantiles"
        }, 
        {
            "location": "/resampling/resampling_overview/", 
            "text": "Uncertain values\n  are trivially resampled by drawing random numbers from their furnishing distributions/populations.\n\n\nIf needed, you may choose to  \nconstrain\n an uncertain value before resampling, using one of the available  \nsampling constraints\n.\n\n\nThe \nresample\n function is used to resample uncertain values. For detailed instructions on how to sample uncertain values and datasets of uncertain  values, see the following pages:\n\n\n\n\nResampling uncertain values\n\n\nResampling uncertain value datasets\n\n\nResampling uncertain index-value datasets", 
            "title": "Overview"
        }, 
        {
            "location": "/resampling/resampling_uncertain_values/", 
            "text": "Uncertain values may be resampled by drawing random number from the distributions furnishing them.\n\n\n\n\nDocumentation\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\nresample\n(\nuv\n::\nAbstractUncertainValue\n)\n\n\n\n\n\n\n\nSample the uncertain value once, drawing values from the entire support of the probability  distribution furnishing it.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\nresample\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nSample the uncertain value \nn\n times, drawing values from the entire support of the  probability distribution furnishing it.\n\n\nsource\n\n\n\n\nExamples\n\n\n\n\n\n\nResample once\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\nresample\n(\nuv_theoretical\n)\n\n\nresample\n(\nuv_theoretical_fitted\n)\n\n\nresample\n(\nuv_kde\n)\n\n\n\n\n\n\n\n\nResample n times\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\nn\n \n=\n \n500\n\n\nresample\n(\nuv_theoretical\n,\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nn\n)\n\n\n\n\n\n\n\n\nResampling can also be performed with constraints.\n\n\n\n\nresample\n(\nuv\n::\nAbstractUncertainValue\n,\n \nconstraint\n::\nSamplingConstraint\n)\n   samples the uncertain value once, drawing from a restricted   range of the support of the the probability distribution furnishing it.\n\n\nresample\n(\nuv\n::\nAbstractUncertainValue\n,\n \nconstraint\n::\nSamplingConstraint\n,\n \nn\n::\nInt\n)\n   samples the uncertain value \nn\n times, drawing values from a restricted   range of the support of the the probability distribution furnishing it.\n\n\n\n\nAvailable sampling constraints are:\n\n\n\n\nTruncateStd\n(\nn\n\u03c3\n::\nInt\n)\n\n\nTruncateMinimum\n(\nmin\n::\nNumber\n)\n\n\nTruncateMaximum\n(\nmax\n::\nNumber\n)\n\n\nTruncateRange\n(\nmin\n::\nNumber\n,\n \nmax\n::\nNumber\n)\n\n\nTruncateLowerQuantile\n(\nlower_quantile\n::\nFloat64\n)\n\n\nTruncateUpperQuantile\n(\nupper_quantile\n::\nFloat64\n)\n\n\nTruncateQuantiles\n(\nlower_quantile\n::\nFloat64\n,\n \nupper_quantile\n::\nFloat64\n)\n\n\n\n\nFor full documentation of the constraints, see the  \navailable constraints\n in the menu.\n\n\n\n\n\n\nLower quantile\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values must be higher than the 0.2-th quantile of the distribution\n\n\n# furnishing the value.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateLowerQuantile\n(\n0.2\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateLowerQuantile\n(\n0.2\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\n\n\n\n\n\n\nUpper quantile\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value  with the restriction that the sampled\n\n\n# values must be lower than the 0.95-th quantile of the distribution\n\n\n# furnishing the value.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateUpperQuantile\n(\n0.95\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateUpperQuantile\n(\n0.95\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateUpperQuantile\n(\n0.95\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateUpperQuantile\n(\n0.95\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateUpperQuantile\n(\n0.95\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateUpperQuantile\n(\n0.95\n))\n\n\n\n\n\n\n\n\nQuantile range\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values must be within the (0.025, 0.975) quantile range.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n))\n\n\n\n\n\n\n\n\nMinimum\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values have -2 as a lower bound.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateMinimum\n(\n-\n2\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateMinimum\n(\n-\n2\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateMinimum\n(\n-\n2\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateMinimum\n(\n-\n2\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateMinimum\n(\n-\n2\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateMinimum\n(\n-\n2\n))\n\n\n\n\n\n\n\n\nMaximum\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values have 3 as an upper bound.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateMaximum\n(\n3\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateMaximum\n(\n3\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateMaximum\n(\n3\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateMaximum\n(\n3\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateMaximum\n(\n3\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateMaximum\n(\n3\n))\n\n\n\n\n\n\n\n\nRange\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values must have values on the interval [-1, 1]. We first sample once,\n\n\n# then 50 times.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n))", 
            "title": "Resampling uncertain values"
        }, 
        {
            "location": "/resampling/resampling_uncertain_values/#documentation", 
            "text": "#  UncertainData . Resampling . resample     Method .  1 resample ( uv :: AbstractUncertainValue )    Sample the uncertain value once, drawing values from the entire support of the probability  distribution furnishing it.  source  #  UncertainData . Resampling . resample     Method .  1 resample ( uv :: AbstractUncertainValue ,   n :: Int )    Sample the uncertain value  n  times, drawing values from the entire support of the  probability distribution furnishing it.  source", 
            "title": "Documentation"
        }, 
        {
            "location": "/resampling/resampling_uncertain_values/#examples", 
            "text": "Resample once   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  resample ( uv_theoretical )  resample ( uv_theoretical_fitted )  resample ( uv_kde )     Resample n times   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  n   =   500  resample ( uv_theoretical ,   n )  resample ( uv_theoretical_fitted ,   n )  resample ( uv_kde ,   n )     Resampling can also be performed with constraints.   resample ( uv :: AbstractUncertainValue ,   constraint :: SamplingConstraint )    samples the uncertain value once, drawing from a restricted   range of the support of the the probability distribution furnishing it.  resample ( uv :: AbstractUncertainValue ,   constraint :: SamplingConstraint ,   n :: Int )    samples the uncertain value  n  times, drawing values from a restricted   range of the support of the the probability distribution furnishing it.   Available sampling constraints are:   TruncateStd ( n \u03c3 :: Int )  TruncateMinimum ( min :: Number )  TruncateMaximum ( max :: Number )  TruncateRange ( min :: Number ,   max :: Number )  TruncateLowerQuantile ( lower_quantile :: Float64 )  TruncateUpperQuantile ( upper_quantile :: Float64 )  TruncateQuantiles ( lower_quantile :: Float64 ,   upper_quantile :: Float64 )   For full documentation of the constraints, see the   available constraints  in the menu.    Lower quantile   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values must be higher than the 0.2-th quantile of the distribution  # furnishing the value.  resample ( uv_theoretical ,   TruncateLowerQuantile ( 0.2 ))  resample ( uv_theoretical_fitted ,   TruncateLowerQuantile ( 0.2 ))  resample ( uv_kde ,   TruncateLowerQuantile ( 0.2 ))  n   =   100  resample ( uv_theoretical ,   TruncateLowerQuantile ( 0.2 ),   n )  resample ( uv_theoretical_fitted ,   TruncateLowerQuantile ( 0.2 ),   n )  resample ( uv_kde ,   TruncateLowerQuantile ( 0.2 ))     Upper quantile   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value  with the restriction that the sampled  # values must be lower than the 0.95-th quantile of the distribution  # furnishing the value.  resample ( uv_theoretical ,   TruncateUpperQuantile ( 0.95 ))  resample ( uv_theoretical_fitted ,   TruncateUpperQuantile ( 0.95 ))  resample ( uv_kde ,   TruncateUpperQuantile ( 0.95 ))  n   =   100  resample ( uv_theoretical ,   TruncateUpperQuantile ( 0.95 ),   n )  resample ( uv_theoretical_fitted ,   TruncateUpperQuantile ( 0.95 ),   n )  resample ( uv_kde ,   TruncateUpperQuantile ( 0.95 ))     Quantile range   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values must be within the (0.025, 0.975) quantile range.  resample ( uv_theoretical ,   TruncateQuantiles ( 0.025 ,   0.975 ))  resample ( uv_theoretical_fitted ,   TruncateQuantiles ( 0.025 ,   0.975 ))  resample ( uv_kde ,   TruncateQuantiles ( 0.025 ,   0.975 ))  n   =   100  resample ( uv_theoretical ,   TruncateQuantiles ( 0.025 ,   0.975 ),   n )  resample ( uv_theoretical_fitted ,   TruncateQuantiles ( 0.025 ,   0.975 ),   n )  resample ( uv_kde ,   TruncateQuantiles ( 0.025 ,   0.975 ))     Minimum   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values have -2 as a lower bound.  resample ( uv_theoretical ,   TruncateMinimum ( - 2 ))  resample ( uv_theoretical_fitted ,   TruncateMinimum ( - 2 ))  resample ( uv_kde ,   TruncateMinimum ( - 2 ))  n   =   100  resample ( uv_theoretical ,   TruncateMinimum ( - 2 ),   n )  resample ( uv_theoretical_fitted ,   TruncateMinimum ( - 2 ),   n )  resample ( uv_kde ,   TruncateMinimum ( - 2 ))     Maximum   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values have 3 as an upper bound.  resample ( uv_theoretical ,   TruncateMaximum ( 3 ))  resample ( uv_theoretical_fitted ,   TruncateMaximum ( 3 ))  resample ( uv_kde ,   TruncateMaximum ( 3 ))  n   =   100  resample ( uv_theoretical ,   TruncateMaximum ( 3 ),   n )  resample ( uv_theoretical_fitted ,   TruncateMaximum ( 3 ),   n )  resample ( uv_kde ,   TruncateMaximum ( 3 ))     Range   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values must have values on the interval [-1, 1]. We first sample once,  # then 50 times.  resample ( uv_theoretical ,   TruncateRange ( - 1 ,   1 ))  resample ( uv_theoretical_fitted ,   TruncateRange ( - 1 ,   1 ))  resample ( uv_kde ,   TruncateRange ( - 1 ,   1 ))  n   =   100  resample ( uv_theoretical ,   TruncateRange ( - 1 ,   1 ),   n )  resample ( uv_theoretical_fitted ,   TruncateRange ( - 1 ,   1 ),   n )  resample ( uv_kde ,   TruncateRange ( - 1 ,   1 ))", 
            "title": "Examples"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/", 
            "text": "Collections of uncertain values are resampled by element-wise sampling the  furnishing distributions of the uncertain values in the collection. You may sample the collection as it is, or apply \nsampling constraints\n that limit the  support of the individual data value distributions.\n\n\n\n\nMethod documentation\n\n\nThe following methods will work for any collection type included in the \nUVAL_COLLECTION_TYPES\n type union.\n\n\n\n\nSingle realisation\n\n\n\n\nNo constraint\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\nresample\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nconstraint\n::\nSamplingConstraint\n,\n \nn\n::\nInt\n)\n \n-\n \nVector\n{\nVector\n{\nT\n}}\n \nwhere\n \nT\n\n\n\n\n\n\n\nResample \nx\n (a collection of uncertain values) once by drawing a single random number from  each of the uncertain values in \nx\n.\n\n\nSee also \nUVAL_COLLECTION_TYPES\n.\n\n\nExample\n\n\n1\n2\n3\n4\n5\n# Generate some uncertain values represented by gamma distributions\n\n\nuvals\n \n=\n \n[\nUncertainValue\n(\nGamma\n(\ni\n,\n \nrand\n()))\n \nfor\n \ni\n \n=\n \n1\n:\n100\n]\n\n\n\n# Resample the collection once \n\n\nresample\n(\nuvals\n)\n\n\n\n\n\n\n\nsource\n\n\n\n\nSame constraint applied to all values\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\nresample\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nconstraint\n::\nSamplingConstraint\n)\n \n-\n \nVector\n{\nT\n}\n \nwhere\n \nT\n\n\n\n\n\n\n\nResample \nx\n (a collection of uncertain values) once, applying the provided sampling \nconstraint\n.\n\n\nReturns a \nlength\n(\nx\n)\n-element vector. The \ni\n-th element of this vector is generated by  truncating the \ni\n-th uncertain value by the sampling \nconstraint\n, then drawing a single random  number from the truncated value.\n\n\nSee also \nUVAL_COLLECTION_TYPES\n.\n\n\nExample\n\n\n1\n2\n3\n4\n5\n6\n7\n# Generate some uncertain values where the `i`-th value is given by a normal \n\n\n# distribution with mean `i` and a standard deviation drawn from a uniform \n\n\n# distribution on `[0, 1]`.\n\n\nuvals\n \n=\n \n[\nUncertainValue\n(\nNormal\n(\ni\n,\n \nrand\n()))\n \nfor\n \ni\n \n=\n \n1\n:\n100\n]\n\n\n\n# Truncate each distribution at +- 0.5 standard deviations, then resample. \n\n\nresample\n(\nuvals\n,\n \nTruncateStd\n(\n0.5\n))\n\n\n\n\n\n\n\nsource\n\n\n\n\nDifferent constraints applied to each value\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\nresample\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nconstraint\n::\nVector\n{\n:\nSamplingConstraint\n})\n \n-\n \nVector\n{\nT\n}\n \nwhere\n \nT\n\n\n\n\n\n\n\nResample \nx\n (a collection of uncertain values) once, applying the provided sampling \nconstraint\ns. The number of constraints must match the number of elements in \nx\n.\n\n\nReturns a \nlength\n(\nx\n)\n-element vector. The \ni\n-th element of this vector is generated by  truncating the \ni\n-th uncertain value by the \ni\n-th sampling \nconstraint\n, then drawing a single random  number from the truncated value. \n\n\nSee also \nUVAL_COLLECTION_TYPES\n.\n\n\nExample\n\n\n1\n2\n3\n4\n5\n6\n7\n# Generate some uncertain values where the `i`-th value is given by a normal \n\n\n# distribution with mean `i` and a standard deviation drawn from a uniform \n\n\n# distribution on `[0, 1]`.\n\n\nuvals\n \n=\n \n[\nUncertainValue\n(\nNormal\n(\ni\n,\n \nrand\n()))\n \nfor\n \ni\n \n=\n \n1\n:\n100\n]\n\n\n\n# Truncate each distribution at +- 0.5 standard deviations, then resample. \n\n\nresample\n(\nuvals\n,\n \nTruncateStd\n(\n0.5\n))\n\n\n\n\n\n\n\nsource\n\n\n\n\nMultiple realisations\n\n\n\n\nNo constraint\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\nresample\n(\nuvd\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n \n-\n \nVector\n{\nVector\n{\nT\n}}\n\n\n\n\n\n\n\nDraw \nn\n realisations of an uncertain value dataset according to the distributions of the uncertain values comprising it.\n\n\nSee also \nUVAL_COLLECTION_TYPES\n. \n\n\nExample\n\n\n1\n2\n3\n4\n5\n# Generate some uncertain values represented by gamma distributions\n\n\nuvals\n \n=\n \n[\nUncertainValue\n(\nGamma\n(\ni\n,\n \nrand\n()))\n \nfor\n \ni\n \n=\n \n1\n:\n100\n]\n\n\n\n# Resample the collection once \n\n\nresample\n(\nuvals\n)\n\n\n\n\n\n\n\nsource\n\n\n\n\nSame constraint applied to all values\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\nresample\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nconstraint\n::\nSamplingConstraint\n,\n \nn\n::\nInt\n)\n \n-\n \nVector\n{\nVector\n{\nT\n}}\n \nwhere\n \nT\n\n\n\n\n\n\n\nResample \nx\n (a collection of uncertain values) \nn\n times, applying the provided sampling \nconstraint\n.\n\n\nReturns an \nn\n-element vector of \nlength\n(\nx\n)\n-element vectors. Each of these vectors is an independent  draw from \nx\n. The \ni\n-th element of each draw is generated by truncating the \ni\n-th uncertain value by  the sampling \nconstraint\n, then drawing a single random number from the truncated value.\n\n\nSee also \nUVAL_COLLECTION_TYPES\n.\n\n\nExample\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n# Generate some uncertain values where the `i`-th value is given by a normal \n\n\n# distribution with mean `i` and a standard deviation drawn from a uniform \n\n\n# distribution on `[0, 1]`.\n\n\nuvals\n \n=\n \n[\nUncertainValue\n(\nNormal\n(\ni\n,\n \nrand\n()))\n \nfor\n \ni\n \n=\n \n1\n:\n100\n]\n\n\n\n# Truncate the first 50 elements at the 90th percentile range, and the \n\n\n# last 50 elements at the 40th percentile range.\n\n\nconstraints\n \n=\n \n[\ni\n \n=\n \n50\n \n?\n \nTruncateQuantiles\n(\n0.05\n,\n \n0.95\n)\n \n:\n \nTruncateQuantiles\n(\n0.3\n,\n \n0.7\n)\n \nfor\n \ni\n \n=\n \n1\n:\n100\n]\n\n\n\n# Truncate the distributions, then draw ten independent realisations of the collection subject\n\n\n# to the provided constraints.\n\n\nresample\n(\nuvals\n,\n \nconstraints\n,\n \n10\n)\n\n\n\n\n\n\n\nsource\n\n\n\n\nDifferent constraints applied to each value\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\nresample\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nconstraint\n::\nVector\n{\n:\nSamplingConstraint\n},\n \nn\n::\nInt\n)\n \n-\n \nVector\n{\nVector\n{\nT\n}}\n \nwhere\n \nT\n\n\n\n\n\n\n\nResample \nx\n (a collection of uncertain values) \nn\n times, applying the provided sampling \nconstraint\ns.\n\n\nReturns an \nn\n-element vector of \nlength\n(\nx\n)\n-element vectors. Each of these vectors is an independent  draw from \nx\n. The \ni\n-th element of each draw is generated by truncating the \ni\n-th uncertain value by  the \ni\n-th sampling \nconstraint\n, then drawing a single random number from the truncated value.\n\n\nSee also \nUVAL_COLLECTION_TYPES\n.\n\n\nExample\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n# Generate some uncertain values where the `i`-th value is given by a normal \n\n\n# distribution with mean `i` and a standard deviation drawn from a uniform \n\n\n# distribution on `[0, 1]`.\n\n\nuvals\n \n=\n \n[\nUncertainValue\n(\nNormal\n(\ni\n,\n \nrand\n()))\n \nfor\n \ni\n \n=\n \n1\n:\n100\n]\n\n\n\n# Truncate the first 50 elements at `\u00b1 0.5` standard deviations, and the \n\n\n# last 50 elements at `\u00b1 1.2` standar deviations.\n\n\nconstraints\n \n=\n \n[\ni\n \n=\n \n50\n \n?\n \nTruncateStd\n(\n0.5\n)\n \n:\n \nTruncateStd\n(\n1.2\n)\n \nfor\n \ni\n \n=\n \n1\n:\n100\n]\n\n\n\n# Apply the constraints element-wise, then draw ten independent realisations \n\n\n# of the collection subject to those constraints.\n\n\nresample\n(\nuvals\n,\n \nconstraints\n,\n \n10\n)\n\n\n\n\n\n\n\nsource\n\n\n\n\nExamples\n\n\n\n\nResampling with sampling constraints\n\n\nConsider the following example where we had a bunch of different measurements. \n\n\nThe first ten measurements (\nr1\n) are normally distributed values with mean \n\u03bc\n \n=\n \n0\n \n\u00b1\n \n0\n.\n4\n  and standard deviation \n\u03c3\n \n=\n \n0\n.\n5\n \n\u00b1\n \n0\n.\n1\n. The next measurement \nr2\n is actually a sample  consisting of 9850 replicates. Upon plotting it, we see that it has some complex  distribution which  we have to estimate using a kernel density approach (calling  \nUncertainValue\n without any additional argument triggers kernel density estimation).  Next, we have distribution \nr3\n that upon plotting looks uniform, so we approximate it by a  uniform distribution. Finally, the last two uncertain values \nr4\n and \nr5\n are represented  by a normal and a gamma distribution with known parameters.\n\n\nTo plot these data, we gather them in an \nUncertainDataset\n.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\ndist1\n \n=\n \nUniform\n(\n-\n0.4\n,\n \n0.4\n)\n\n\ndist2\n \n=\n \nUniform\n(\n-\n0.1\n,\n \n0.1\n)\n\n\nr1\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \n0\n \n+\n \nrand\n(\ndist\n),\n \n0.5\n \n+\n \nrand\n(\ndist2\n))\n \nfor\n \ni\n \n=\n \n1\n:\n10\n]\n\n \n# now drawn from a uniform distribution, but simulates \n\n\nr2\n \n=\n \nUncertainValue\n(\nrand\n(\n9850\n))\n\n\nr3\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nrand\n(\n10000\n))\n\n\nr4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n-\n0.1\n,\n \n0.5\n)\n\n\nr5\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n0.4\n,\n \n0.8\n)\n\n\n\nuvals\n \n=\n \n[\nr1\n;\n \nr2\n;\n \nr3\n;\n \nr4\n;\n \nr5\n]\n\n\nudata\n \n=\n \nUncertainDataset\n(\nuvals\n);\n\n\n\n\n\n\n\nBy default, the plot recipe for uncertain datasets will plot the median value with the  33\nrd\n to 67\nth\n percentile range (roughly equivalent to a one standard deviation for  normally distributed values). You may change the percentile range by providing a two-element vector to the plot function.\n\n\nLet's demonstrate this by creating a function that plots the uncertain values with  errors bars covering the 0.1\nst\n to 99.9\nth\n, the 5\nth\n to 95\nth\n, and the 33\nrd\n to 67\nth\n percentile  ranges. The function will also take a sampling constraint, then resample the dataset  a number of times and plot the individual realizations as lines. \n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\nusing\n \nUncertainData\n,\n \nPlots\n\n\n\nfunction\n \nresample_plot\n(\ndata\n,\n \nsampling_constraint\n;\n \nn_resample_draws\n \n=\n \n40\n)\n \n    \np\n \n=\n \nplot\n(\nlw\n \n=\n \n0.5\n)\n\n    \nscatter!\n(\ndata\n,\n \n[\n0.001\n,\n \n0.999\n],\n \nseriescolor\n \n=\n \n:\nblack\n)\n\n    \nscatter!\n(\ndata\n,\n \n[\n0.05\n,\n \n0.95\n],\n \nseriescolor\n \n=\n \n:\nred\n)\n\n    \nscatter!\n(\ndata\n,\n \n[\n0.33\n,\n \n0.67\n],\n \nseriescolor\n \n=\n \n:\ngreen\n)\n\n\n    \nplot!\n(\nresample\n(\ndata\n,\n \nsampling_constraint\n,\n \nn_resample_draws\n),\n \n        \nlc\n \n=\n \n:\nblack\n,\n \nlw\n \n=\n \n0.3\n,\n \nl\u03b1\n \n=\n \n0.5\n)\n\n    \nreturn\n \np\n\n\nend\n\n\n\n# Now, resample using some different constraints and compare the plots\n\n\np1\n \n=\n \nresample_plot\n(\nudata\n,\n \nNoConstraint\n())\n\n\ntitle!\n(\nNo constraints\n)\n\n\np2\n \n=\n \nresample_plot\n(\nudata\n,\n \nTruncateQuantiles\n(\n0.05\n,\n \n0.95\n))\n\n\ntitle!\n(\n5th to 95th quantile range\n)\n\n\np3\n \n=\n \nresample_plot\n(\nudata\n,\n \nTruncateQuantiles\n(\n0.33\n,\n \n0.67\n))\n\n\ntitle!\n(\n33th to 67th quantile range\n)\n\n\np4\n \n=\n \nresample_plot\n(\nudata\n,\n \nTruncateMaximum\n(\n0.7\n))\n\n\ntitle!\n(\nTruncate at maximum value = 0.7\n)\n\n\n\nplot\n(\np1\n,\n \np2\n,\n \np3\n,\n \np4\n,\n \nlayout\n \n=\n \n(\n4\n,\n \n1\n),\n \ntitlefont\n \n=\n \nfont\n(\n8\n))\n\n\n\n\n\n\n\nThis produces the following plot:\n\n\n\n\n\n\nWhat happens when applying invalid constraints to a dataset?\n\n\nIn the example above, the resampling worked fine because all the constraints were  applicable to the data. However, it could happen that the constraint is not applicable  to all uncertain values in the dataset. For example, applying a \nTruncateMaximum\n(\n2\n)\n  constraint to an uncertain value \nu\n defined by \nu\n \n=\n \nUncertainValue\n(\nUniform\n,\n \n4\n,\n \n5\n)\n would  not work, because the support of \nu\n would be empty after applying the constraint.\n\n\nTo check if a constraint yields a nonempty truncated uncertain value, use the  \nsupport_intersection\n function. If the result of \n`\nsupport_intersection\n(\nuval1\n,\n \nuval2\n)\n  for two uncertain values \nuval1\n and \nuval2\n is the empty set \n\u2205\n, then you'll run into  trouble.\n\n\nTo check for such cases for an entire dataset, you can use the  \nverify_constraints\n(\nudata\n::\nAbstractUncertainValueDataset\n,\n \nconstraint\n::\nSamplingConstraint\n)\n  function. It will apply the constraint to each value and return the indices of the values  for which applying the constraint would result in a furnishing distribution whose support  is the empty set.", 
            "title": "Resampling uncertain datasets"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#method_documentation", 
            "text": "The following methods will work for any collection type included in the  UVAL_COLLECTION_TYPES  type union.", 
            "title": "Method documentation"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#single_realisation", 
            "text": "", 
            "title": "Single realisation"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#no_constraint", 
            "text": "#  UncertainData . Resampling . resample     Method .  1 resample ( x :: UVAL_COLLECTION_TYPES ,   constraint :: SamplingConstraint ,   n :: Int )   -   Vector { Vector { T }}   where   T    Resample  x  (a collection of uncertain values) once by drawing a single random number from  each of the uncertain values in  x .  See also  UVAL_COLLECTION_TYPES .  Example  1\n2\n3\n4\n5 # Generate some uncertain values represented by gamma distributions  uvals   =   [ UncertainValue ( Gamma ( i ,   rand ()))   for   i   =   1 : 100 ]  # Resample the collection once   resample ( uvals )    source", 
            "title": "No constraint"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#same_constraint_applied_to_all_values", 
            "text": "#  UncertainData . Resampling . resample     Method .  1 resample ( x :: UVAL_COLLECTION_TYPES ,   constraint :: SamplingConstraint )   -   Vector { T }   where   T    Resample  x  (a collection of uncertain values) once, applying the provided sampling  constraint .  Returns a  length ( x ) -element vector. The  i -th element of this vector is generated by  truncating the  i -th uncertain value by the sampling  constraint , then drawing a single random  number from the truncated value.  See also  UVAL_COLLECTION_TYPES .  Example  1\n2\n3\n4\n5\n6\n7 # Generate some uncertain values where the `i`-th value is given by a normal   # distribution with mean `i` and a standard deviation drawn from a uniform   # distribution on `[0, 1]`.  uvals   =   [ UncertainValue ( Normal ( i ,   rand ()))   for   i   =   1 : 100 ]  # Truncate each distribution at +- 0.5 standard deviations, then resample.   resample ( uvals ,   TruncateStd ( 0.5 ))    source", 
            "title": "Same constraint applied to all values"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#different_constraints_applied_to_each_value", 
            "text": "#  UncertainData . Resampling . resample     Method .  1 resample ( x :: UVAL_COLLECTION_TYPES ,   constraint :: Vector { : SamplingConstraint })   -   Vector { T }   where   T    Resample  x  (a collection of uncertain values) once, applying the provided sampling  constraint s. The number of constraints must match the number of elements in  x .  Returns a  length ( x ) -element vector. The  i -th element of this vector is generated by  truncating the  i -th uncertain value by the  i -th sampling  constraint , then drawing a single random  number from the truncated value.   See also  UVAL_COLLECTION_TYPES .  Example  1\n2\n3\n4\n5\n6\n7 # Generate some uncertain values where the `i`-th value is given by a normal   # distribution with mean `i` and a standard deviation drawn from a uniform   # distribution on `[0, 1]`.  uvals   =   [ UncertainValue ( Normal ( i ,   rand ()))   for   i   =   1 : 100 ]  # Truncate each distribution at +- 0.5 standard deviations, then resample.   resample ( uvals ,   TruncateStd ( 0.5 ))    source", 
            "title": "Different constraints applied to each value"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#multiple_realisations", 
            "text": "", 
            "title": "Multiple realisations"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#no_constraint_1", 
            "text": "#  UncertainData . Resampling . resample     Method .  1 resample ( uvd :: UVAL_COLLECTION_TYPES ,   n :: Int )   -   Vector { Vector { T }}    Draw  n  realisations of an uncertain value dataset according to the distributions of the uncertain values comprising it.  See also  UVAL_COLLECTION_TYPES .   Example  1\n2\n3\n4\n5 # Generate some uncertain values represented by gamma distributions  uvals   =   [ UncertainValue ( Gamma ( i ,   rand ()))   for   i   =   1 : 100 ]  # Resample the collection once   resample ( uvals )    source", 
            "title": "No constraint"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#same_constraint_applied_to_all_values_1", 
            "text": "#  UncertainData . Resampling . resample     Method .  1 resample ( x :: UVAL_COLLECTION_TYPES ,   constraint :: SamplingConstraint ,   n :: Int )   -   Vector { Vector { T }}   where   T    Resample  x  (a collection of uncertain values)  n  times, applying the provided sampling  constraint .  Returns an  n -element vector of  length ( x ) -element vectors. Each of these vectors is an independent  draw from  x . The  i -th element of each draw is generated by truncating the  i -th uncertain value by  the sampling  constraint , then drawing a single random number from the truncated value.  See also  UVAL_COLLECTION_TYPES .  Example   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 # Generate some uncertain values where the `i`-th value is given by a normal   # distribution with mean `i` and a standard deviation drawn from a uniform   # distribution on `[0, 1]`.  uvals   =   [ UncertainValue ( Normal ( i ,   rand ()))   for   i   =   1 : 100 ]  # Truncate the first 50 elements at the 90th percentile range, and the   # last 50 elements at the 40th percentile range.  constraints   =   [ i   =   50   ?   TruncateQuantiles ( 0.05 ,   0.95 )   :   TruncateQuantiles ( 0.3 ,   0.7 )   for   i   =   1 : 100 ]  # Truncate the distributions, then draw ten independent realisations of the collection subject  # to the provided constraints.  resample ( uvals ,   constraints ,   10 )    source", 
            "title": "Same constraint applied to all values"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#different_constraints_applied_to_each_value_1", 
            "text": "#  UncertainData . Resampling . resample     Method .  1 resample ( x :: UVAL_COLLECTION_TYPES ,   constraint :: Vector { : SamplingConstraint },   n :: Int )   -   Vector { Vector { T }}   where   T    Resample  x  (a collection of uncertain values)  n  times, applying the provided sampling  constraint s.  Returns an  n -element vector of  length ( x ) -element vectors. Each of these vectors is an independent  draw from  x . The  i -th element of each draw is generated by truncating the  i -th uncertain value by  the  i -th sampling  constraint , then drawing a single random number from the truncated value.  See also  UVAL_COLLECTION_TYPES .  Example   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 # Generate some uncertain values where the `i`-th value is given by a normal   # distribution with mean `i` and a standard deviation drawn from a uniform   # distribution on `[0, 1]`.  uvals   =   [ UncertainValue ( Normal ( i ,   rand ()))   for   i   =   1 : 100 ]  # Truncate the first 50 elements at `\u00b1 0.5` standard deviations, and the   # last 50 elements at `\u00b1 1.2` standar deviations.  constraints   =   [ i   =   50   ?   TruncateStd ( 0.5 )   :   TruncateStd ( 1.2 )   for   i   =   1 : 100 ]  # Apply the constraints element-wise, then draw ten independent realisations   # of the collection subject to those constraints.  resample ( uvals ,   constraints ,   10 )    source", 
            "title": "Different constraints applied to each value"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#resampling_with_sampling_constraints", 
            "text": "Consider the following example where we had a bunch of different measurements.   The first ten measurements ( r1 ) are normally distributed values with mean  \u03bc   =   0   \u00b1   0 . 4   and standard deviation  \u03c3   =   0 . 5   \u00b1   0 . 1 . The next measurement  r2  is actually a sample  consisting of 9850 replicates. Upon plotting it, we see that it has some complex  distribution which  we have to estimate using a kernel density approach (calling   UncertainValue  without any additional argument triggers kernel density estimation).  Next, we have distribution  r3  that upon plotting looks uniform, so we approximate it by a  uniform distribution. Finally, the last two uncertain values  r4  and  r5  are represented  by a normal and a gamma distribution with known parameters.  To plot these data, we gather them in an  UncertainDataset .   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 dist1   =   Uniform ( - 0.4 ,   0.4 )  dist2   =   Uniform ( - 0.1 ,   0.1 )  r1   =   [ UncertainValue ( Normal ,   0   +   rand ( dist ),   0.5   +   rand ( dist2 ))   for   i   =   1 : 10 ] \n  # now drawn from a uniform distribution, but simulates   r2   =   UncertainValue ( rand ( 9850 ))  r3   =   UncertainValue ( Uniform ,   rand ( 10000 ))  r4   =   UncertainValue ( Normal ,   - 0.1 ,   0.5 )  r5   =   UncertainValue ( Gamma ,   0.4 ,   0.8 )  uvals   =   [ r1 ;   r2 ;   r3 ;   r4 ;   r5 ]  udata   =   UncertainDataset ( uvals );    By default, the plot recipe for uncertain datasets will plot the median value with the  33 rd  to 67 th  percentile range (roughly equivalent to a one standard deviation for  normally distributed values). You may change the percentile range by providing a two-element vector to the plot function.  Let's demonstrate this by creating a function that plots the uncertain values with  errors bars covering the 0.1 st  to 99.9 th , the 5 th  to 95 th , and the 33 rd  to 67 th  percentile  ranges. The function will also take a sampling constraint, then resample the dataset  a number of times and plot the individual realizations as lines.    1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24 using   UncertainData ,   Plots  function   resample_plot ( data ,   sampling_constraint ;   n_resample_draws   =   40 )  \n     p   =   plot ( lw   =   0.5 ) \n     scatter! ( data ,   [ 0.001 ,   0.999 ],   seriescolor   =   : black ) \n     scatter! ( data ,   [ 0.05 ,   0.95 ],   seriescolor   =   : red ) \n     scatter! ( data ,   [ 0.33 ,   0.67 ],   seriescolor   =   : green ) \n\n     plot! ( resample ( data ,   sampling_constraint ,   n_resample_draws ),  \n         lc   =   : black ,   lw   =   0.3 ,   l\u03b1   =   0.5 ) \n     return   p  end  # Now, resample using some different constraints and compare the plots  p1   =   resample_plot ( udata ,   NoConstraint ())  title! ( No constraints )  p2   =   resample_plot ( udata ,   TruncateQuantiles ( 0.05 ,   0.95 ))  title! ( 5th to 95th quantile range )  p3   =   resample_plot ( udata ,   TruncateQuantiles ( 0.33 ,   0.67 ))  title! ( 33th to 67th quantile range )  p4   =   resample_plot ( udata ,   TruncateMaximum ( 0.7 ))  title! ( Truncate at maximum value = 0.7 )  plot ( p1 ,   p2 ,   p3 ,   p4 ,   layout   =   ( 4 ,   1 ),   titlefont   =   font ( 8 ))    This produces the following plot:", 
            "title": "Resampling with sampling constraints"
        }, 
        {
            "location": "/resampling/resampling_uncertain_datasets/#what_happens_when_applying_invalid_constraints_to_a_dataset", 
            "text": "In the example above, the resampling worked fine because all the constraints were  applicable to the data. However, it could happen that the constraint is not applicable  to all uncertain values in the dataset. For example, applying a  TruncateMaximum ( 2 )   constraint to an uncertain value  u  defined by  u   =   UncertainValue ( Uniform ,   4 ,   5 )  would  not work, because the support of  u  would be empty after applying the constraint.  To check if a constraint yields a nonempty truncated uncertain value, use the   support_intersection  function. If the result of  ` support_intersection ( uval1 ,   uval2 )   for two uncertain values  uval1  and  uval2  is the empty set  \u2205 , then you'll run into  trouble.  To check for such cases for an entire dataset, you can use the   verify_constraints ( udata :: AbstractUncertainValueDataset ,   constraint :: SamplingConstraint )   function. It will apply the constraint to each value and return the indices of the values  for which applying the constraint would result in a furnishing distribution whose support  is the empty set.", 
            "title": "What happens when applying invalid constraints to a dataset?"
        }, 
        {
            "location": "/resampling/resampling_uncertain_indexvalue_datasets/", 
            "text": "Resampling \nUncertainIndexValueDataset\ns is done in the same manner as for uncertain  values and \nUncertainDatasets\n. \n\n\nSee also the list of  \navailable sampling constraints\n.\n\n\n\n\nMethod documentation\n\n\n\n\nNo constraints\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\nresample\n(\nudata\n::\nUncertainIndexValueDataset\n)\n \n-\n \nTuple\n{\nVector\n{\nFloat64\n},\n \nVector\n{\nFloat64\n}}\n\n\n\n\n\n\n\nResample an uncertain index-value dataset in an element-wise manner.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\nresample\n(\nudata\n::\nUncertainIndexValueDataset\n,\n \n    \nn\n::\nInt\n)\n \n-\n \nVector\n{\nTuple\n{\nVector\n{\nFloat64\n},\n \nVector\n{\nFloat64\n}}}\n\n\n\n\n\n\n\nResample \nn\n realizations an uncertain index-value dataset in an element-wise manner. \n\n\nsource\n\n\n\n\nSame constraint to both indices and data values\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\nresample\n(\nudata\n::\nUncertainIndexValueDataset\n,\n \n    \nconstraint\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}})\n \n-\n \nTuple\n{\nVector\n{\nFloat64\n},\n \nVector\n{\nFloat64\n}}\n\n\n\n\n\n\n\nResample an uncertain index-value dataset in an element-wise manner. \n\n\nEnforces the provided sampling \nconstraint\n to all uncertain values in the dataset, both  indices and data values.\n\n\nIf a single constraint is provided, then that constraint will be applied to all values. If a  vector of constraints (as many as there are values) is provided, then the constraints are  applied element-wise to both the indices and the data values.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\n3\nresample\n(\nudata\n::\nUncertainIndexValueDataset\n,\n \n    \nconstraint\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}},\n\n    \nn\n::\nInt\n)\n \n-\n \nTuple\n{\nVector\n{\nFloat64\n},\n \nVector\n{\nFloat64\n}}\n\n\n\n\n\n\n\nResample \nn\n realizations of an uncertain index-value dataset in an element-wise manner. \n\n\nEnforces the provided sampling \nconstraint\n to all uncertain values in the dataset, both  indices and data values.\n\n\nIf a single constraint is provided, that constraint will be applied to all values. If a  vector of constraints (as many as there are values) is provided, then the constraints are  applied element-wise to both the indices and the data values.\n\n\nsource\n\n\n\n\nDifferent constraints to indices and data values\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\n3\nresample\n(\nudata\n::\nUncertainIndexValueDataset\n,\n \n    \nconstraint_idxs\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}},\n \n    \nconstraint_vals\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}})\n \n-\n \nTuple\n{\nVector\n{\nFloat64\n},\n \nVector\n{\nFloat64\n}}\n\n\n\n\n\n\n\nResample an uncertain index-value dataset in an element-wise manner. \n\n\nEnforces separate sampling constraints to the indices and to the data values. \n\n\nIf a single constraint is provided, that constraint will be applied to all values. If a  vector of constraints (as many as there are values) is provided, then the constraints are  applied element-wise.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\n3\n4\nresample\n(\nudata\n::\nUncertainIndexValueDataset\n,\n \n    \nconstraint_idxs\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}},\n \n    \nconstraint_vals\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}},\n\n    \nn\n::\nInt\n)\n \n-\n \nVector\n{\nTuple\n{\nVector\n{\nFloat64\n},\n \nVector\n{\nFloat64\n}}}\n\n\n\n\n\n\n\nResample \nn\n realizations of an uncertain index-value dataset in an element-wise manner. \n\n\nEnforces separate sampling constraints to the indices and to the data values. \n\n\nIf a single constraint is provided, that constraint will be applied to all values. If a  vector of constraints (as many as there are values) is provided, then the constraints are  applied element-wise.\n\n\nsource\n\n\n\n\nExamples\n\n\n\n\nSame constraint for all uncertain values\n\n\nFirst, let's define some data to work on.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nusing\n \nUncertainData\n,\n \nPlots\n\n\ngr\n()\n\n\nr1\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \nrand\n(),\n \nrand\n())\n \nfor\n \ni\n \n=\n \n1\n:\n10\n]\n\n\nr2\n \n=\n \nUncertainValue\n(\nrand\n(\n10000\n))\n\n\nr3\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nrand\n(\n10000\n))\n\n\nr4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n-\n0.1\n,\n \n0.5\n)\n\n\nr5\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n0.4\n,\n \n0.8\n)\n\n\n\nu_values\n \n=\n \n[\nr1\n;\n \nr2\n;\n \nr3\n;\n \nr4\n;\n \nr5\n]\n\n\nu_timeindices\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \ni\n,\n \nrand\n(\nUniform\n(\n0\n,\n \n1\n)))\n \nfor\n \ni\n \n=\n \n1\n:\nlength\n(\nu_values\n)]\n\n\nuindices\n \n=\n \nUncertainDataset\n(\nu_timeindices\n);\n\n\nudata\n \n=\n \nUncertainDataset\n(\nu_values\n);\n\n\n\n# Now, gather uncertain indices and uncertain data values\n\n\nx\n \n=\n \nUncertainIndexValueDataset\n(\nuindices\n,\n \nudata\n)\n\n\n\n\n\n\n\nBy default, the plot recipe shows the median and 33\nrd\n to 67\nth\n percentile range error bars.  Let's use the default plot recipe, and add some line plots with resampled realizations  of the dataset.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\np\n \n=\n \nplot\n(\nx\n)\n\n\n\nfor\n \ni\n \n=\n \n1\n:\n100\n\n    \ns\n \n=\n \nresample\n(\nx\n,\n \nTruncateQuantiles\n(\n0.33\n,\n \n0.67\n),\n \nTruncateQuantiles\n(\n0.33\n,\n \n0.67\n))\n\n    \nscatter!\n(\np\n,\n \ns\n[\n1\n],\n \ns\n[\n2\n],\n \nlabel\n \n=\n \n,\n \nlw\n \n=\n \n0.3\n,\n \nl\u03b1\n \n=\n \n0.1\n,\n \nlc\n \n=\n \n:\nblack\n,\n\n            \nmc\n \n=\n \n:\nblack\n,\n \nms\n \n=\n \n0.5\n,\n \nm\u03b1\n \n=\n \n0.4\n)\n\n    \nplot!\n(\np\n,\n \ns\n[\n1\n],\n \ns\n[\n2\n],\n \nlabel\n \n=\n \n,\n \nlw\n \n=\n \n0.3\n,\n \nl\u03b1\n \n=\n \n0.1\n,\n \nlc\n \n=\n \n:\nblack\n,\n\n            \nmc\n \n=\n \n:\nblack\n,\n \nms\n \n=\n \n0.5\n,\n \nm\u03b1\n \n=\n \n0.4\n)\n\n\nend\n\n\np\n\n\n\n\n\n\n\n\n\nThis would of course also work with any other sampling constraint that is valid for your  dataset. Let's demonstrate with a few more examples.\n\n\n\n\nDifferent constraints for indices and data values\n\n\nLet's say that we want to treat the uncertainties of the indices (time, in this case)  separately from the uncertainties of the data values. \n\n\nFirst, let's define a dataset to work on.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\nusing\n \nUncertainData\n,\n \nPlots\n\n\ngr\n()\n\n\nr1\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \nrand\n(),\n \nrand\n())\n \nfor\n \ni\n \n=\n \n1\n:\n10\n]\n\n\nr2\n \n=\n \nUncertainValue\n(\nrand\n(\n10000\n))\n\n\nr3\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nrand\n(\n10000\n))\n\n\nr4\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n-\n0.1\n,\n \n0.5\n)\n\n\nr5\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n0.4\n,\n \n0.8\n)\n\n\n\nu_values\n \n=\n \n[\nr1\n;\n \nr2\n;\n \nr3\n;\n \nr4\n;\n \nr5\n]\n\n\nu_timeindices\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \ni\n,\n \nrand\n(\nUniform\n(\n0\n,\n \n1\n)))\n \nfor\n \ni\n \n=\n \n1\n:\nlength\n(\nu_values\n)]\n\n\nuindices\n \n=\n \nUncertainDataset\n(\nu_timeindices\n);\n\n\nudata\n \n=\n \nUncertainDataset\n(\nu_values\n);\n\n\n\n# Now, gather uncertain indices and uncertain data values\n\n\nx\n \n=\n \nUncertainIndexValueDataset\n(\nuindices\n,\n \nudata\n)\n\n\n\n\n\n\n\nLet's pretend every 2\nnd\n time index has many outliers which we don't trust, so we restrict  resampling of those values to the 30\nth\n to 70\nth\n percentile range. For the remaining time  indices, there are some outliers outliers, but these are concentrated at the lower end of  the distributions, so we'll resample by truncating the furnishing distributions below at  the 10\nth\n percentile.\n\n\nFor the data values, we pretend that the same applies: every 2\nnd\n value has a bunch of  outliers, so we restrict the support of the distributions of those uncertain values to  1.5 standard deviations around the mean. For the remaining data values, we'll resample  from the the 20\nth\n to 80\nth\n percentile range.\n\n\nNow, define the constraints as described:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n# Define the constraints\n\n\nn_vals\n \n=\n \nlength\n(\nx\n)\n\n\n\nindex_constraints\n \n=\n \nVector\n{\nSamplingConstraint\n}(\nundef\n,\n \nn_vals\n)\n\n\nvalue_constraints\n \n=\n \nVector\n{\nSamplingConstraint\n}(\nundef\n,\n \nn_vals\n)\n\n\n\nfor\n \ni\n \n=\n \n1\n:\nn_vals\n\n    \nif\n \ni\n \n%\n \n2\n \n==\n \n0\n\n        \nindex_constraints\n[\ni\n]\n \n=\n \nTruncateQuantiles\n(\n0.3\n,\n \n0.7\n)\n\n        \nvalue_constraints\n[\ni\n]\n \n=\n \nTruncateStd\n(\n1.5\n)\n\n    \nelse\n\n        \nindex_constraints\n[\ni\n]\n \n=\n \nTruncateLowerQuantile\n(\n0.1\n)\n\n        \nvalue_constraints\n[\ni\n]\n \n=\n \nTruncateQuantiles\n(\n0.2\n,\n \n0.8\n)\n  \n    \nend\n\n\nend\n\n\n\n\n\n\n\nFinally, plot the realizations.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n# Resample a bunch of times and plot the realizations both as lines as scatter points\n\n\np\n \n=\n \nplot\n(\nxlabel\n \n=\n \nIndex\n,\n \nylabel\n \n=\n \nValue\n)\n\n\nfor\n \ni\n \n=\n \n1\n:\n500\n\n    \ns\n \n=\n \nresample\n(\nx\n,\n \nindex_constraints\n,\n \nvalue_constraints\n)\n\n    \nscatter!\n(\np\n,\n \ns\n[\n1\n],\n \ns\n[\n2\n],\n \nlabel\n \n=\n \n,\n \nlw\n \n=\n \n0.3\n,\n \nl\u03b1\n \n=\n \n0.1\n,\n \nlc\n \n=\n \n:\nblack\n,\n\n            \nmc\n \n=\n \n:\nblack\n,\n \nms\n \n=\n \n0.5\n,\n \nm\u03b1\n \n=\n \n0.4\n)\n\n    \nplot!\n(\np\n,\n \ns\n[\n1\n],\n \ns\n[\n2\n],\n \nlabel\n \n=\n \n,\n \nlw\n \n=\n \n0.3\n,\n \nl\u03b1\n \n=\n \n0.1\n,\n \nlc\n \n=\n \n:\nblack\n,\n\n            \nmc\n \n=\n \n:\nblack\n,\n \nms\n \n=\n \n0.5\n,\n \nm\u03b1\n \n=\n \n0.4\n)\n\n\nend\n\n\np", 
            "title": "Resampling uncertain index-value datasets"
        }, 
        {
            "location": "/resampling/resampling_uncertain_indexvalue_datasets/#method_documentation", 
            "text": "", 
            "title": "Method documentation"
        }, 
        {
            "location": "/resampling/resampling_uncertain_indexvalue_datasets/#no_constraints", 
            "text": "#  UncertainData . Resampling . resample     Method .  1 resample ( udata :: UncertainIndexValueDataset )   -   Tuple { Vector { Float64 },   Vector { Float64 }}    Resample an uncertain index-value dataset in an element-wise manner.  source  #  UncertainData . Resampling . resample     Method .  1\n2 resample ( udata :: UncertainIndexValueDataset ,  \n     n :: Int )   -   Vector { Tuple { Vector { Float64 },   Vector { Float64 }}}    Resample  n  realizations an uncertain index-value dataset in an element-wise manner.   source", 
            "title": "No constraints"
        }, 
        {
            "location": "/resampling/resampling_uncertain_indexvalue_datasets/#same_constraint_to_both_indices_and_data_values", 
            "text": "#  UncertainData . Resampling . resample     Method .  1\n2 resample ( udata :: UncertainIndexValueDataset ,  \n     constraint :: Union { SamplingConstraint ,   Vector { SamplingConstraint }})   -   Tuple { Vector { Float64 },   Vector { Float64 }}    Resample an uncertain index-value dataset in an element-wise manner.   Enforces the provided sampling  constraint  to all uncertain values in the dataset, both  indices and data values.  If a single constraint is provided, then that constraint will be applied to all values. If a  vector of constraints (as many as there are values) is provided, then the constraints are  applied element-wise to both the indices and the data values.  source  #  UncertainData . Resampling . resample     Method .  1\n2\n3 resample ( udata :: UncertainIndexValueDataset ,  \n     constraint :: Union { SamplingConstraint ,   Vector { SamplingConstraint }}, \n     n :: Int )   -   Tuple { Vector { Float64 },   Vector { Float64 }}    Resample  n  realizations of an uncertain index-value dataset in an element-wise manner.   Enforces the provided sampling  constraint  to all uncertain values in the dataset, both  indices and data values.  If a single constraint is provided, that constraint will be applied to all values. If a  vector of constraints (as many as there are values) is provided, then the constraints are  applied element-wise to both the indices and the data values.  source", 
            "title": "Same constraint to both indices and data values"
        }, 
        {
            "location": "/resampling/resampling_uncertain_indexvalue_datasets/#different_constraints_to_indices_and_data_values", 
            "text": "#  UncertainData . Resampling . resample     Method .  1\n2\n3 resample ( udata :: UncertainIndexValueDataset ,  \n     constraint_idxs :: Union { SamplingConstraint ,   Vector { SamplingConstraint }},  \n     constraint_vals :: Union { SamplingConstraint ,   Vector { SamplingConstraint }})   -   Tuple { Vector { Float64 },   Vector { Float64 }}    Resample an uncertain index-value dataset in an element-wise manner.   Enforces separate sampling constraints to the indices and to the data values.   If a single constraint is provided, that constraint will be applied to all values. If a  vector of constraints (as many as there are values) is provided, then the constraints are  applied element-wise.  source  #  UncertainData . Resampling . resample     Method .  1\n2\n3\n4 resample ( udata :: UncertainIndexValueDataset ,  \n     constraint_idxs :: Union { SamplingConstraint ,   Vector { SamplingConstraint }},  \n     constraint_vals :: Union { SamplingConstraint ,   Vector { SamplingConstraint }}, \n     n :: Int )   -   Vector { Tuple { Vector { Float64 },   Vector { Float64 }}}    Resample  n  realizations of an uncertain index-value dataset in an element-wise manner.   Enforces separate sampling constraints to the indices and to the data values.   If a single constraint is provided, that constraint will be applied to all values. If a  vector of constraints (as many as there are values) is provided, then the constraints are  applied element-wise.  source", 
            "title": "Different constraints to indices and data values"
        }, 
        {
            "location": "/resampling/resampling_uncertain_indexvalue_datasets/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/resampling/resampling_uncertain_indexvalue_datasets/#same_constraint_for_all_uncertain_values", 
            "text": "First, let's define some data to work on.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 using   UncertainData ,   Plots  gr ()  r1   =   [ UncertainValue ( Normal ,   rand (),   rand ())   for   i   =   1 : 10 ]  r2   =   UncertainValue ( rand ( 10000 ))  r3   =   UncertainValue ( Uniform ,   rand ( 10000 ))  r4   =   UncertainValue ( Normal ,   - 0.1 ,   0.5 )  r5   =   UncertainValue ( Gamma ,   0.4 ,   0.8 )  u_values   =   [ r1 ;   r2 ;   r3 ;   r4 ;   r5 ]  u_timeindices   =   [ UncertainValue ( Normal ,   i ,   rand ( Uniform ( 0 ,   1 )))   for   i   =   1 : length ( u_values )]  uindices   =   UncertainDataset ( u_timeindices );  udata   =   UncertainDataset ( u_values );  # Now, gather uncertain indices and uncertain data values  x   =   UncertainIndexValueDataset ( uindices ,   udata )    By default, the plot recipe shows the median and 33 rd  to 67 th  percentile range error bars.  Let's use the default plot recipe, and add some line plots with resampled realizations  of the dataset.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 p   =   plot ( x )  for   i   =   1 : 100 \n     s   =   resample ( x ,   TruncateQuantiles ( 0.33 ,   0.67 ),   TruncateQuantiles ( 0.33 ,   0.67 )) \n     scatter! ( p ,   s [ 1 ],   s [ 2 ],   label   =   ,   lw   =   0.3 ,   l\u03b1   =   0.1 ,   lc   =   : black , \n             mc   =   : black ,   ms   =   0.5 ,   m\u03b1   =   0.4 ) \n     plot! ( p ,   s [ 1 ],   s [ 2 ],   label   =   ,   lw   =   0.3 ,   l\u03b1   =   0.1 ,   lc   =   : black , \n             mc   =   : black ,   ms   =   0.5 ,   m\u03b1   =   0.4 )  end  p     This would of course also work with any other sampling constraint that is valid for your  dataset. Let's demonstrate with a few more examples.", 
            "title": "Same constraint for all uncertain values"
        }, 
        {
            "location": "/resampling/resampling_uncertain_indexvalue_datasets/#different_constraints_for_indices_and_data_values", 
            "text": "Let's say that we want to treat the uncertainties of the indices (time, in this case)  separately from the uncertainties of the data values.   First, let's define a dataset to work on.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 using   UncertainData ,   Plots  gr ()  r1   =   [ UncertainValue ( Normal ,   rand (),   rand ())   for   i   =   1 : 10 ]  r2   =   UncertainValue ( rand ( 10000 ))  r3   =   UncertainValue ( Uniform ,   rand ( 10000 ))  r4   =   UncertainValue ( Normal ,   - 0.1 ,   0.5 )  r5   =   UncertainValue ( Gamma ,   0.4 ,   0.8 )  u_values   =   [ r1 ;   r2 ;   r3 ;   r4 ;   r5 ]  u_timeindices   =   [ UncertainValue ( Normal ,   i ,   rand ( Uniform ( 0 ,   1 )))   for   i   =   1 : length ( u_values )]  uindices   =   UncertainDataset ( u_timeindices );  udata   =   UncertainDataset ( u_values );  # Now, gather uncertain indices and uncertain data values  x   =   UncertainIndexValueDataset ( uindices ,   udata )    Let's pretend every 2 nd  time index has many outliers which we don't trust, so we restrict  resampling of those values to the 30 th  to 70 th  percentile range. For the remaining time  indices, there are some outliers outliers, but these are concentrated at the lower end of  the distributions, so we'll resample by truncating the furnishing distributions below at  the 10 th  percentile.  For the data values, we pretend that the same applies: every 2 nd  value has a bunch of  outliers, so we restrict the support of the distributions of those uncertain values to  1.5 standard deviations around the mean. For the remaining data values, we'll resample  from the the 20 th  to 80 th  percentile range.  Now, define the constraints as described:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 # Define the constraints  n_vals   =   length ( x )  index_constraints   =   Vector { SamplingConstraint }( undef ,   n_vals )  value_constraints   =   Vector { SamplingConstraint }( undef ,   n_vals )  for   i   =   1 : n_vals \n     if   i   %   2   ==   0 \n         index_constraints [ i ]   =   TruncateQuantiles ( 0.3 ,   0.7 ) \n         value_constraints [ i ]   =   TruncateStd ( 1.5 ) \n     else \n         index_constraints [ i ]   =   TruncateLowerQuantile ( 0.1 ) \n         value_constraints [ i ]   =   TruncateQuantiles ( 0.2 ,   0.8 )   \n     end  end    Finally, plot the realizations.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 # Resample a bunch of times and plot the realizations both as lines as scatter points  p   =   plot ( xlabel   =   Index ,   ylabel   =   Value )  for   i   =   1 : 500 \n     s   =   resample ( x ,   index_constraints ,   value_constraints ) \n     scatter! ( p ,   s [ 1 ],   s [ 2 ],   label   =   ,   lw   =   0.3 ,   l\u03b1   =   0.1 ,   lc   =   : black , \n             mc   =   : black ,   ms   =   0.5 ,   m\u03b1   =   0.4 ) \n     plot! ( p ,   s [ 1 ],   s [ 2 ],   label   =   ,   lw   =   0.3 ,   l\u03b1   =   0.1 ,   lc   =   : black , \n             mc   =   : black ,   ms   =   0.5 ,   m\u03b1   =   0.4 )  end  p", 
            "title": "Different constraints for indices and data values"
        }, 
        {
            "location": "/resampling/sequential/resampling_uncertaindatasets_sequential/", 
            "text": "In addition to the  \ngeneric sampling constraints\n,  you may impose sequential sampling constraints when resampling an uncertain dataset. \n\n\n\n\nIs a particular constraint applicable?\n\n\nNot all \nsequential sampling constraints\n  may be applicable to your dataset. Use  \nthese functions\n to check whether a  particular constraint is possible to apply to your dataset. \n\n\n\n\nSyntax\n\n\n\n\nSequential constraint only\n\n\nA dataset may be sampling imposing a sequential sampling constraint, but leaving the  furnishing distributions untouched otherwise.\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\n3\nresample\n(\nudata\n::\nAbstractUncertainValueDataset\n,\n \n    \nsequential_constraint\n::\nSequentialSamplingConstraint\n;\n\n    \nquantiles\n \n=\n \n[\n0.0001\n,\n \n0.9999\n])\n\n\n\n\n\n\n\nResample a dataset by imposing a sequential sampling constraint. \n\n\nBefore drawing the realization, all furnishing distributions are truncated to the provided  \nquantiles\n range. This is to avoid problems in case some distributions have infinite  support.\n\n\nsource\n\n\n\n\nRegular constraint(s) + sequential constraint\n\n\nAnother option is to first impose constraints on the furnishing distributions, then  applying the sequential sampling constraint.\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\n3\n4\nresample\n(\nudata\n::\nAbstractUncertainValueDataset\n,\n \n    \nconstraint\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}},\n \n    \nsequential_constraint\n::\nSequentialSamplingConstraint\n;\n\n    \nquantiles\n \n=\n \n[\n0.0001\n,\n \n0.9999\n])\n\n\n\n\n\n\n\nResample a dataset by first imposing regular sampling constraints on the furnishing  distributions, then applying a sequential sampling constraint. \n\n\nBefore drawing the realization, all furnishing distributions are truncated to the provided  \nquantiles\n range. This is to avoid problems in case some distributions have infinite  support.\n\n\nsource\n\n\n\n\nList of sequential resampling schemes\n\n\n\n\nStrictlyIncreasing\n sequences.\n\n\nStrictlyDecreasing\n sequences.", 
            "title": "Overview"
        }, 
        {
            "location": "/resampling/sequential/resampling_uncertaindatasets_sequential/#is_a_particular_constraint_applicable", 
            "text": "Not all  sequential sampling constraints   may be applicable to your dataset. Use   these functions  to check whether a  particular constraint is possible to apply to your dataset.", 
            "title": "Is a particular constraint applicable?"
        }, 
        {
            "location": "/resampling/sequential/resampling_uncertaindatasets_sequential/#syntax", 
            "text": "", 
            "title": "Syntax"
        }, 
        {
            "location": "/resampling/sequential/resampling_uncertaindatasets_sequential/#sequential_constraint_only", 
            "text": "A dataset may be sampling imposing a sequential sampling constraint, but leaving the  furnishing distributions untouched otherwise.  #  UncertainData . Resampling . resample     Method .  1\n2\n3 resample ( udata :: AbstractUncertainValueDataset ,  \n     sequential_constraint :: SequentialSamplingConstraint ; \n     quantiles   =   [ 0.0001 ,   0.9999 ])    Resample a dataset by imposing a sequential sampling constraint.   Before drawing the realization, all furnishing distributions are truncated to the provided   quantiles  range. This is to avoid problems in case some distributions have infinite  support.  source", 
            "title": "Sequential constraint only"
        }, 
        {
            "location": "/resampling/sequential/resampling_uncertaindatasets_sequential/#regular_constraints_sequential_constraint", 
            "text": "Another option is to first impose constraints on the furnishing distributions, then  applying the sequential sampling constraint.  #  UncertainData . Resampling . resample     Method .  1\n2\n3\n4 resample ( udata :: AbstractUncertainValueDataset ,  \n     constraint :: Union { SamplingConstraint ,   Vector { SamplingConstraint }},  \n     sequential_constraint :: SequentialSamplingConstraint ; \n     quantiles   =   [ 0.0001 ,   0.9999 ])    Resample a dataset by first imposing regular sampling constraints on the furnishing  distributions, then applying a sequential sampling constraint.   Before drawing the realization, all furnishing distributions are truncated to the provided   quantiles  range. This is to avoid problems in case some distributions have infinite  support.  source", 
            "title": "Regular constraint(s) + sequential constraint"
        }, 
        {
            "location": "/resampling/sequential/resampling_uncertaindatasets_sequential/#list_of_sequential_resampling_schemes", 
            "text": "StrictlyIncreasing  sequences.  StrictlyDecreasing  sequences.", 
            "title": "List of sequential resampling schemes"
        }, 
        {
            "location": "/resampling/sequential/strictly_increasing/", 
            "text": "The default constructor for a strictly increasing sequential sampling constraint is  \nStrictlyIncreasing\n. To specify how the sequence is sampled, provide an  \nOrderedSamplingAlgorithm\n as an argument to the constructor.\n\n\n\n\nCompatible ordering algorithms\n\n\n\n\nStrictlyIncreasing\n(\nStartToEnd\n())\n (the default)\n\n\n\n\n\n\nDocumentation\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\n3\n4\nresample\n(\nudata\n::\nAbstractUncertainValueDataset\n,\n \n    \nconstraint\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}},\n\n    \nsequential_constraint\n::\nStrictlyIncreasing\n{\nOrderedSamplingAlgorithm\n};\n\n    \nquantiles\n \n=\n \n[\n0.0001\n,\n \n0.9999\n])\n\n\n\n\n\n\n\nDraw a sequence of values strictly increasing in magnitude from the dataset, sampling  each of the furnishing distributions once each, after first truncating the supports  of the values in the dataset using the provided \nconstraint\ns.\n\n\nArguments:\n\n\n\n\nudata\n: An uncertain dataset.\n\n\nconstraint\n: Sampling constraint(s) to apply to each of the values in the dataset    before drawing the sequence of increasing values.\n\n\nsequential_constraint\n: An instance of a \nStrictlyIncreasing\n sequential    sampling constraint. For example, \nStrictlyIncreasing\n(\nStartToEnd\n())\n indicates    that a strictly increasing sequence should be created in one go from start to    finish (as opposed to chunking the data set first, then gluing partial sequences    together afterwards).\n\n\nquantiles\n: A two-element vector representing a quantile range which is used    to truncate the supports values in the dataset before drawing the sequence of    increasing values. This deals with distributions with infinite support.\n\n\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\nresample\n(\nudata\n::\nDT\n,\n \nsequential_constraint\n::\nStrictlyIncreasing\n{\nT\n};\n\n    \nquantiles\n \n=\n \n[\n0.0001\n,\n \n0.9999\n])\n \nwhere\n \n{\nDT\n \n:\n \nAbstractUncertainValueDataset\n,\n \nT\n \n:\n \nStartToEnd\n}\n\n\n\n\n\n\n\nElement-wise resample the uncertain values in the dataset such that each preceding value  is strictly less in magnitude than the next one. \n\n\nArguments:\n\n\n\n\nudata\n: An uncertain dataset.\n\n\nsequential_constraint\n: An instance of a \nStrictlyIncreasing\n sequential    sampling constraint.\n\n\nordered_sampling_alg\n: An instance of a \nStartToEnd\n ordered    sampling constraint, indicating that the sequence of increasing values should    be created in one go from start to finish (as opposed to chunking the data set    first, then gluing partial sequences together afterwards).\n\n\nquantiles\n: A two-element vector representing a quantile range which is used    to truncate the supports values in the dataset before drawing the sequence of    increasing values. This deals with distributions with infinite support.\n\n\n\n\nsource\n\n\n\n\nExamples\n\n\n\n\nExample 1: strictly increasing sequences\n\n\nLet's compare how the realizations look for the situation where no sequential sampling constraint is imposed versus enforcing strictly increasing sequences.\n\n\nWe start by creating some uncertain data with increasing magnitude and zero overlap between  values, so we're guaranteed that a strictly increasing sequence through the dataset exists.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nusing\n \nUncertainData\n,\n \nPlots\n \n\n\n\nN\n \n=\n \n10\n\n\nu_timeindices\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \ni\n,\n \nrand\n(\nUniform\n(\n0.1\n,\n \n2\n)))\n \nfor\n \ni\n \n=\n \n1\n:\nN\n]\n\n\nu\n \n=\n \nUncertainDataset\n(\nu_timeindices\n)\n\n\n\np_increasing\n \n=\n \nplot\n(\nu\n,\n \n[\n0.0001\n,\n \n0.9999\n],\n \nlegend\n \n=\n \nfalse\n,\n\n    \nxlabel\n \n=\n \nindex\n,\n \nylabel\n \n=\n \nvalue\n)\n\n\np_regular\n \n=\n \nplot\n(\nu\n,\n \n[\n0.0001\n,\n \n0.9999\n],\n \nlegend\n \n=\n \nfalse\n,\n\n    \nylabel\n \n=\n \nvalue\n,\n \nxaxis\n \n=\n \nfalse\n)\n\n\n\nfor\n \ni\n \n=\n \n1\n:\n1000\n\n    \nplot!\n(\np_increasing\n,\n \nresample\n(\nu\n,\n \nStrictlyIncreasing\n()),\n \nlw\n \n=\n \n0.2\n,\n \nlc\n \n=\n \n:\nblack\n,\n \nl\u03b1\n \n=\n \n0.1\n)\n\n    \nplot!\n(\np_regular\n,\n \nresample\n(\nu\n),\n \nlw\n \n=\n \n0.2\n,\n \nlc\n \n=\n \n:\nblack\n,\n \nl\u03b1\n \n=\n \n0.2\n)\n\n\nend\n \n\n\nplot\n(\np_regular\n,\n \np_increasing\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nx\n,\n \nsize\n \n=\n \n(\n400\n,\n \n500\n))\n\n\n\n\n\n\n\n\n\nValues of the realizations where strictly increasing sequences are imposed clearly are  limited by the next values in the dataset. For the regular sampling, however, realizations  jump wildly, with both positive and negative first differences.\n\n\n\n\nExample 2: regular constraints + strictly increasing sequences\n\n\nYou may also combine regular sampling constraints with sequential resampling schemes.  Here's one example. We use the same data as in example 1 above, but when drawing increasing  sequences, we only resample from within one standard deviation around the mean.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\np_increasing\n \n=\n \nplot\n(\nu\n,\n \n[\n0.0001\n,\n \n0.9999\n],\n \nlegend\n \n=\n \nfalse\n,\n\n    \nxlabel\n \n=\n \nindex\n,\n \nylabel\n \n=\n \nvalue\n)\n\n\np_regular\n \n=\n \nplot\n(\nu\n,\n \n[\n0.0001\n,\n \n0.9999\n],\n \nlegend\n \n=\n \nfalse\n,\n\n    \nylabel\n \n=\n \nvalue\n,\n \nxaxis\n \n=\n \nfalse\n)\n\n\n\nfor\n \ni\n \n=\n \n1\n:\n1000\n\n    \nplot!\n(\np_increasing\n,\n \nresample\n(\nu\n,\n \nTruncateStd\n(\n1\n),\n \nStrictlyIncreasing\n()),\n \nlw\n \n=\n \n0.2\n,\n \n        \nlc\n \n=\n \n:\nblack\n,\n \nl\u03b1\n \n=\n \n0.1\n)\n\n    \nplot!\n(\np_regular\n,\n \nresample\n(\nu\n),\n \nlw\n \n=\n \n0.2\n,\n \nlc\n \n=\n \n:\nblack\n,\n \nl\u03b1\n \n=\n \n0.2\n)\n\n\nend\n \n\n\nplot\n(\np_regular\n,\n \np_increasing\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nx\n,\n \nsize\n \n=\n \n(\n400\n,\n \n500\n))", 
            "title": "Strictly increasing"
        }, 
        {
            "location": "/resampling/sequential/strictly_increasing/#compatible_ordering_algorithms", 
            "text": "StrictlyIncreasing ( StartToEnd ())  (the default)", 
            "title": "Compatible ordering algorithms"
        }, 
        {
            "location": "/resampling/sequential/strictly_increasing/#documentation", 
            "text": "#  UncertainData . Resampling . resample     Method .  1\n2\n3\n4 resample ( udata :: AbstractUncertainValueDataset ,  \n     constraint :: Union { SamplingConstraint ,   Vector { SamplingConstraint }}, \n     sequential_constraint :: StrictlyIncreasing { OrderedSamplingAlgorithm }; \n     quantiles   =   [ 0.0001 ,   0.9999 ])    Draw a sequence of values strictly increasing in magnitude from the dataset, sampling  each of the furnishing distributions once each, after first truncating the supports  of the values in the dataset using the provided  constraint s.  Arguments:   udata : An uncertain dataset.  constraint : Sampling constraint(s) to apply to each of the values in the dataset    before drawing the sequence of increasing values.  sequential_constraint : An instance of a  StrictlyIncreasing  sequential    sampling constraint. For example,  StrictlyIncreasing ( StartToEnd ())  indicates    that a strictly increasing sequence should be created in one go from start to    finish (as opposed to chunking the data set first, then gluing partial sequences    together afterwards).  quantiles : A two-element vector representing a quantile range which is used    to truncate the supports values in the dataset before drawing the sequence of    increasing values. This deals with distributions with infinite support.   source  #  UncertainData . Resampling . resample     Method .  1\n2 resample ( udata :: DT ,   sequential_constraint :: StrictlyIncreasing { T }; \n     quantiles   =   [ 0.0001 ,   0.9999 ])   where   { DT   :   AbstractUncertainValueDataset ,   T   :   StartToEnd }    Element-wise resample the uncertain values in the dataset such that each preceding value  is strictly less in magnitude than the next one.   Arguments:   udata : An uncertain dataset.  sequential_constraint : An instance of a  StrictlyIncreasing  sequential    sampling constraint.  ordered_sampling_alg : An instance of a  StartToEnd  ordered    sampling constraint, indicating that the sequence of increasing values should    be created in one go from start to finish (as opposed to chunking the data set    first, then gluing partial sequences together afterwards).  quantiles : A two-element vector representing a quantile range which is used    to truncate the supports values in the dataset before drawing the sequence of    increasing values. This deals with distributions with infinite support.   source", 
            "title": "Documentation"
        }, 
        {
            "location": "/resampling/sequential/strictly_increasing/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/resampling/sequential/strictly_increasing/#example_1_strictly_increasing_sequences", 
            "text": "Let's compare how the realizations look for the situation where no sequential sampling constraint is imposed versus enforcing strictly increasing sequences.  We start by creating some uncertain data with increasing magnitude and zero overlap between  values, so we're guaranteed that a strictly increasing sequence through the dataset exists.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 using   UncertainData ,   Plots   N   =   10  u_timeindices   =   [ UncertainValue ( Normal ,   i ,   rand ( Uniform ( 0.1 ,   2 )))   for   i   =   1 : N ]  u   =   UncertainDataset ( u_timeindices )  p_increasing   =   plot ( u ,   [ 0.0001 ,   0.9999 ],   legend   =   false , \n     xlabel   =   index ,   ylabel   =   value )  p_regular   =   plot ( u ,   [ 0.0001 ,   0.9999 ],   legend   =   false , \n     ylabel   =   value ,   xaxis   =   false )  for   i   =   1 : 1000 \n     plot! ( p_increasing ,   resample ( u ,   StrictlyIncreasing ()),   lw   =   0.2 ,   lc   =   : black ,   l\u03b1   =   0.1 ) \n     plot! ( p_regular ,   resample ( u ),   lw   =   0.2 ,   lc   =   : black ,   l\u03b1   =   0.2 )  end   plot ( p_regular ,   p_increasing ,   layout   =   ( 2 ,   1 ),   link   =   : x ,   size   =   ( 400 ,   500 ))     Values of the realizations where strictly increasing sequences are imposed clearly are  limited by the next values in the dataset. For the regular sampling, however, realizations  jump wildly, with both positive and negative first differences.", 
            "title": "Example 1: strictly increasing sequences"
        }, 
        {
            "location": "/resampling/sequential/strictly_increasing/#example_2_regular_constraints_strictly_increasing_sequences", 
            "text": "You may also combine regular sampling constraints with sequential resampling schemes.  Here's one example. We use the same data as in example 1 above, but when drawing increasing  sequences, we only resample from within one standard deviation around the mean.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 p_increasing   =   plot ( u ,   [ 0.0001 ,   0.9999 ],   legend   =   false , \n     xlabel   =   index ,   ylabel   =   value )  p_regular   =   plot ( u ,   [ 0.0001 ,   0.9999 ],   legend   =   false , \n     ylabel   =   value ,   xaxis   =   false )  for   i   =   1 : 1000 \n     plot! ( p_increasing ,   resample ( u ,   TruncateStd ( 1 ),   StrictlyIncreasing ()),   lw   =   0.2 ,  \n         lc   =   : black ,   l\u03b1   =   0.1 ) \n     plot! ( p_regular ,   resample ( u ),   lw   =   0.2 ,   lc   =   : black ,   l\u03b1   =   0.2 )  end   plot ( p_regular ,   p_increasing ,   layout   =   ( 2 ,   1 ),   link   =   : x ,   size   =   ( 400 ,   500 ))", 
            "title": "Example 2: regular constraints + strictly increasing sequences"
        }, 
        {
            "location": "/resampling/sequential/strictly_decreasing/", 
            "text": "The default constructor for a strictly decreasing sequential sampling constraint is  \nStrictlyDecreasing\n. To specify how the sequence is sampled, provide an  \nOrderedSamplingAlgorithm\n as an argument to the constructor.\n\n\n\n\nDocumentation\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\n3\n4\nresample\n(\nudata\n::\nAbstractUncertainValueDataset\n,\n \n    \nconstraint\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}},\n\n    \nsequential_constraint\n::\nStrictlyDecreasing\n{\nOrderedSamplingAlgorithm\n};\n\n    \nquantiles\n \n=\n \n[\n0.0001\n,\n \n0.9999\n])\n\n\n\n\n\n\n\nDraw a sequence of values strictly decreasing in magnitude from the dataset, sampling  each of the furnishing distributions once each, after first truncating the supports  of the values in the dataset using the provided \nconstraint\ns.\n\n\nArguments:\n\n\n\n\nudata\n: An uncertain dataset.\n\n\nconstraint\n: Sampling constraint(s) to apply to each of the values in the dataset\n\n\n\n\nbefore drawing the sequence of decreasing values.\n\n\n\n\nsequential_constraint\n: An instance of a \nStrictlyDecreasing\n sequential\n\n\n\n\nsampling constraint. For example, \nStrictlyDecreasing\n(\nStartToEnd\n())\n indicates  that a strictly decreasing sequence should be created in one go from start to  finish (as opposed to chunking the data set first, then gluing partial sequences  together afterwards).\n\n\n\n\nquantiles\n: A two-element vector representing a quantile range which is used\n\n\n\n\nto truncate the supports values in the dataset before drawing the sequence of  decreasing values. This deals with distributions with infinite support.\n\n\nsource\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\nresample\n(\nudata\n::\nDT\n,\n \nsequential_constraint\n::\nStrictlyDecreasing\n{\nT\n};\n\n    \nquantiles\n \n=\n \n[\n0.0001\n,\n \n0.9999\n])\n \nwhere\n \n{\nDT\n \n:\n \nAbstractUncertainValueDataset\n,\n \nT\n \n:\n \nStartToEnd\n}\n\n\n\n\n\n\n\nElement-wise resample the uncertain values in the dataset such that each preceding value  is strictly larger in magnitude than the next one. \n\n\nArguments:\n\n\n\n\nudata\n: An uncertain dataset.\n\n\nsequential_constraint\n: An instance of a \nStrictlyDecreasing\n sequential    sampling constraint.\n\n\nordered_sampling_alg\n: An instance of a \nStartToEnd\n ordered    sampling constraint, indicating that the sequence of decreasing values should    be created in one go from start to finish (as opposed to chunking the data set    first, then gluing partial sequences together afterwards).\n\n\nquantiles\n: A two-element vector representing a quantile range which is used    to truncate the supports values in the dataset before drawing the sequence of    decreasing values. This deals with distributions with infinite support.\n\n\n\n\nsource\n\n\n\n\nCompatible ordering algorithms\n\n\n\n\nStrictlyDecreasing\n(\nStartToEnd\n())\n (the default)\n\n\n\n\n\n\nExamples\n\n\n\n\nExample: Strictly decreasing sequences + regular constraints\n\n\nWe'll start by creating some uncertain data with decreasing magnitude and just minor  overlap between values, so we're reasonably sure we can create strictly decreasing sequences.\n\n\n1\n2\n3\n4\nusing\n \nUncertainData\n,\n \nPlots\n \n\nN\n \n=\n \n20\n\n\nu_timeindices\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \ni\n,\n \nrand\n(\nUniform\n(\n0.1\n,\n \n)))\n \nfor\n \ni\n \n=\n \nN\n:-\n1\n:\n1\n]\n\n\nu\n \n=\n \nUncertainDataset\n(\nu_timeindices\n)\n\n\n\n\n\n\n\nNow, we'll create three different plots. In all plots, we plot the 0.00001th to 0.99999\nth\n  (black) and 33\nrd\n to 67\nth\n (red) percentile range error bars. For the first plot, we'll  resample the data without any constraints. For the second plot, we'll resample without  imposing any constraints on the furnishing distirbution, but enforcing strictly decreasing sequences when drawing realizations. For the third plot, we'll first truncate all  furnishing distributions to their 33\nrd\n to 67\nth\n percentile range, then draw realizations  whose consecutively value are strictly decreasing in magnitude.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n# Plot the data with 0.00001th to 0.99999th error bars in both directions\n\n\nqs\n \n=\n \n[\n0.0001\n,\n \n0.9999\n]\n\n\np_noconstraint\n \n=\n \nplot\n(\nu\n,\n \nqs\n,\n \nlegend\n \n=\n \nfalse\n,\n \nxaxis\n \n=\n \nfalse\n,\n\n    \ntitle\n \n=\n \nNoConstraint()\n)\n \n\np_decreasing\n \n=\n \nplot\n(\nu\n,\n \nqs\n,\n \nlegend\n \n=\n \nfalse\n,\n \nxaxis\n \n=\n \nfalse\n,\n \n    \ntitle\n \n=\n \nStrictlyDecreasing()\n)\n\n\np_decreasing_constraint\n \n=\n \nplot\n(\nu\n,\n \nqs\n,\n \nlegend\n \n=\n \nfalse\n,\n \nxaxis\n \n=\n \nfalse\n,\n\n    \ntitle\n \n=\n \nTruncateQuantiles(0.33, 0.67) + StriclyDecreasing()\n)\n\n\n\n# Add 33rd to 67th percentile range error bars to all plots. \n\n\nplot!\n(\np_noconstraint\n,\n \nu\n,\n \n[\n0.33\n,\n \n0.67\n],\n \nmsc\n \n=\n \n:\nred\n)\n\n\nplot!\n(\np_decreasing\n,\n \nu\n,\n \n[\n0.33\n,\n \n0.67\n],\n \nmsc\n \n=\n \n:\nred\n)\n\n\nplot!\n(\np_decreasing_constraint\n,\n \nu\n,\n \n[\n0.33\n,\n \n0.67\n],\n \nmsc\n \n=\n \n:\nred\n)\n\n\n\nfor\n \ni\n \n=\n \n1\n:\n300\n\n    \nplot!\n(\np_noconstraint\n,\n \nresample\n(\nu\n,\n \nNoConstraint\n()),\n \nlw\n \n=\n \n0.2\n,\n \nlc\n \n=\n \n:\nblack\n,\n \nl\u03b1\n \n=\n \n0.2\n)\n\n    \nplot!\n(\np_decreasing\n,\n \nresample\n(\nu\n,\n \nStrictlyDecreasing\n()),\n \nlw\n \n=\n \n0.2\n,\n \nlc\n \n=\n \n:\nblack\n,\n \nl\u03b1\n \n=\n \n0.1\n)\n\n    \nplot!\n(\np_decreasing_constraint\n,\n \nresample\n(\nu\n,\n \nTruncateQuantiles\n(\n0.33\n,\n \n0.67\n),\n \nStrictlyDecreasing\n()),\n \nlw\n \n=\n \n0.2\n,\n \nlc\n \n=\n \n:\nblack\n,\n \nl\u03b1\n \n=\n \n0.1\n)\n\n\nend\n \n\n\nplot\n(\np_noconstraint\n,\n \np_decreasing\n,\n \np_decreasing_constraint\n,\n \nlink\n \n=\n \n:\nx\n,\n\n    \nlayout\n \n=\n \n(\n3\n,\n \n1\n),\n \nsize\n \n=\n \n(\n300\n,\n \n600\n),\n \ntitlefont\n \n=\n \nfont\n(\n8\n))", 
            "title": "Strictly decreasing"
        }, 
        {
            "location": "/resampling/sequential/strictly_decreasing/#documentation", 
            "text": "#  UncertainData . Resampling . resample     Method .  1\n2\n3\n4 resample ( udata :: AbstractUncertainValueDataset ,  \n     constraint :: Union { SamplingConstraint ,   Vector { SamplingConstraint }}, \n     sequential_constraint :: StrictlyDecreasing { OrderedSamplingAlgorithm }; \n     quantiles   =   [ 0.0001 ,   0.9999 ])    Draw a sequence of values strictly decreasing in magnitude from the dataset, sampling  each of the furnishing distributions once each, after first truncating the supports  of the values in the dataset using the provided  constraint s.  Arguments:   udata : An uncertain dataset.  constraint : Sampling constraint(s) to apply to each of the values in the dataset   before drawing the sequence of decreasing values.   sequential_constraint : An instance of a  StrictlyDecreasing  sequential   sampling constraint. For example,  StrictlyDecreasing ( StartToEnd ())  indicates  that a strictly decreasing sequence should be created in one go from start to  finish (as opposed to chunking the data set first, then gluing partial sequences  together afterwards).   quantiles : A two-element vector representing a quantile range which is used   to truncate the supports values in the dataset before drawing the sequence of  decreasing values. This deals with distributions with infinite support.  source  #  UncertainData . Resampling . resample     Method .  1\n2 resample ( udata :: DT ,   sequential_constraint :: StrictlyDecreasing { T }; \n     quantiles   =   [ 0.0001 ,   0.9999 ])   where   { DT   :   AbstractUncertainValueDataset ,   T   :   StartToEnd }    Element-wise resample the uncertain values in the dataset such that each preceding value  is strictly larger in magnitude than the next one.   Arguments:   udata : An uncertain dataset.  sequential_constraint : An instance of a  StrictlyDecreasing  sequential    sampling constraint.  ordered_sampling_alg : An instance of a  StartToEnd  ordered    sampling constraint, indicating that the sequence of decreasing values should    be created in one go from start to finish (as opposed to chunking the data set    first, then gluing partial sequences together afterwards).  quantiles : A two-element vector representing a quantile range which is used    to truncate the supports values in the dataset before drawing the sequence of    decreasing values. This deals with distributions with infinite support.   source", 
            "title": "Documentation"
        }, 
        {
            "location": "/resampling/sequential/strictly_decreasing/#compatible_ordering_algorithms", 
            "text": "StrictlyDecreasing ( StartToEnd ())  (the default)", 
            "title": "Compatible ordering algorithms"
        }, 
        {
            "location": "/resampling/sequential/strictly_decreasing/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/resampling/sequential/strictly_decreasing/#example_strictly_decreasing_sequences_regular_constraints", 
            "text": "We'll start by creating some uncertain data with decreasing magnitude and just minor  overlap between values, so we're reasonably sure we can create strictly decreasing sequences.  1\n2\n3\n4 using   UncertainData ,   Plots   N   =   20  u_timeindices   =   [ UncertainValue ( Normal ,   i ,   rand ( Uniform ( 0.1 ,   )))   for   i   =   N :- 1 : 1 ]  u   =   UncertainDataset ( u_timeindices )    Now, we'll create three different plots. In all plots, we plot the 0.00001th to 0.99999 th   (black) and 33 rd  to 67 th  (red) percentile range error bars. For the first plot, we'll  resample the data without any constraints. For the second plot, we'll resample without  imposing any constraints on the furnishing distirbution, but enforcing strictly decreasing sequences when drawing realizations. For the third plot, we'll first truncate all  furnishing distributions to their 33 rd  to 67 th  percentile range, then draw realizations  whose consecutively value are strictly decreasing in magnitude.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22 # Plot the data with 0.00001th to 0.99999th error bars in both directions  qs   =   [ 0.0001 ,   0.9999 ]  p_noconstraint   =   plot ( u ,   qs ,   legend   =   false ,   xaxis   =   false , \n     title   =   NoConstraint() )   p_decreasing   =   plot ( u ,   qs ,   legend   =   false ,   xaxis   =   false ,  \n     title   =   StrictlyDecreasing() )  p_decreasing_constraint   =   plot ( u ,   qs ,   legend   =   false ,   xaxis   =   false , \n     title   =   TruncateQuantiles(0.33, 0.67) + StriclyDecreasing() )  # Add 33rd to 67th percentile range error bars to all plots.   plot! ( p_noconstraint ,   u ,   [ 0.33 ,   0.67 ],   msc   =   : red )  plot! ( p_decreasing ,   u ,   [ 0.33 ,   0.67 ],   msc   =   : red )  plot! ( p_decreasing_constraint ,   u ,   [ 0.33 ,   0.67 ],   msc   =   : red )  for   i   =   1 : 300 \n     plot! ( p_noconstraint ,   resample ( u ,   NoConstraint ()),   lw   =   0.2 ,   lc   =   : black ,   l\u03b1   =   0.2 ) \n     plot! ( p_decreasing ,   resample ( u ,   StrictlyDecreasing ()),   lw   =   0.2 ,   lc   =   : black ,   l\u03b1   =   0.1 ) \n     plot! ( p_decreasing_constraint ,   resample ( u ,   TruncateQuantiles ( 0.33 ,   0.67 ),   StrictlyDecreasing ()),   lw   =   0.2 ,   lc   =   : black ,   l\u03b1   =   0.1 )  end   plot ( p_noconstraint ,   p_decreasing ,   p_decreasing_constraint ,   link   =   : x , \n     layout   =   ( 3 ,   1 ),   size   =   ( 300 ,   600 ),   titlefont   =   font ( 8 ))", 
            "title": "Example: Strictly decreasing sequences + regular constraints"
        }, 
        {
            "location": "/resampling/sequential/resampling_indexvalue_sequential/", 
            "text": "Resampling syntax\n\n\n\n\nManually resampling\n\n\nBecause both the indices and the values of \nUncertainIndexValueDataset\ns are  datasets themselves, you could manually resample them by accessing the \nindices\n and  \nvalues\n fields. This gives you full control of the resampling. \n\n\nThere are some built-in sampling routines you could use instead if you use cases are simple.\n\n\n\n\nBuilt-in resampling methods\n\n\nSequential constraints are always interpreted as belonging to the indices of an  \nuncertain index-value dataset\n.  Therefore, when using the built-in function to resample an index-value dataset, you can use  the same syntax as for any other  \nuncertain value dataset\n, but provide an additional sequential constraint after the regular constraints. The  order of arguments is always 1) regular constraints, then 2) the sequential constraint.\n\n\nThe following examples illustrates the syntax. Assume \nudata\n is an  \nUncertainIndexValueDataset\n instance. Then\n\n\n\n\nresample\n(\nudata\n,\n \nStrictlyIncreasing\n())\n enforces the sequential constraint only to the    indices, applying no constraint(s) on the furnishing distributions of either the    indices nor the values of the dataset.\n\n\nresample\n(\nudata\n,\n \nTruncateQuantile\n(\n0\n.\n1\n,\n \n0\n.\n9\n),\n \nStrictlyIncreasing\n())\n applies the truncating    constraint both the indices and the values, then enforces the sequential constraint    on the indices.\n\n\nresample\n(\nudata\n,\n \nTruncateStd\n(\n2\n),\n \nTruncateQuantile\n(\n0\n.\n1\n,\n \n0\n.\n9\n),\n \nStrictlyIncreasing\n())\n    applies separate truncating constraints to the indices and to the values, then    enforces the sequential constraint on the indices.\n\n\nresample\n(\nudata\n,\n \nNoConstraint\n(),\n \nTruncateQuantile\n(\n0\n.\n1\n,\n \n0\n.\n9\n),\n \nStrictlyIncreasing\n())\n does    the same as above, but \nNoConstraint\n()\n indicates that no constraints are applied to    the indices prior to drawing the sequential realization of the indices.\n\n\n\n\nOf course, like for uncertain value datasets, you can also apply individual constraints to  each index and each value in the dataset, by providing a vector of constraints instead  of a single constraint.\n\n\nCurrently implemented sequential constraints: \n\n\n\n\nStrictlyIncreasing\n\n\nStrictlyDecreasing", 
            "title": "Index-value datasets"
        }, 
        {
            "location": "/resampling/sequential/resampling_indexvalue_sequential/#resampling_syntax", 
            "text": "", 
            "title": "Resampling syntax"
        }, 
        {
            "location": "/resampling/sequential/resampling_indexvalue_sequential/#manually_resampling", 
            "text": "Because both the indices and the values of  UncertainIndexValueDataset s are  datasets themselves, you could manually resample them by accessing the  indices  and   values  fields. This gives you full control of the resampling.   There are some built-in sampling routines you could use instead if you use cases are simple.", 
            "title": "Manually resampling"
        }, 
        {
            "location": "/resampling/sequential/resampling_indexvalue_sequential/#built-in_resampling_methods", 
            "text": "Sequential constraints are always interpreted as belonging to the indices of an   uncertain index-value dataset .  Therefore, when using the built-in function to resample an index-value dataset, you can use  the same syntax as for any other   uncertain value dataset , but provide an additional sequential constraint after the regular constraints. The  order of arguments is always 1) regular constraints, then 2) the sequential constraint.  The following examples illustrates the syntax. Assume  udata  is an   UncertainIndexValueDataset  instance. Then   resample ( udata ,   StrictlyIncreasing ())  enforces the sequential constraint only to the    indices, applying no constraint(s) on the furnishing distributions of either the    indices nor the values of the dataset.  resample ( udata ,   TruncateQuantile ( 0 . 1 ,   0 . 9 ),   StrictlyIncreasing ())  applies the truncating    constraint both the indices and the values, then enforces the sequential constraint    on the indices.  resample ( udata ,   TruncateStd ( 2 ),   TruncateQuantile ( 0 . 1 ,   0 . 9 ),   StrictlyIncreasing ())     applies separate truncating constraints to the indices and to the values, then    enforces the sequential constraint on the indices.  resample ( udata ,   NoConstraint (),   TruncateQuantile ( 0 . 1 ,   0 . 9 ),   StrictlyIncreasing ())  does    the same as above, but  NoConstraint ()  indicates that no constraints are applied to    the indices prior to drawing the sequential realization of the indices.   Of course, like for uncertain value datasets, you can also apply individual constraints to  each index and each value in the dataset, by providing a vector of constraints instead  of a single constraint.  Currently implemented sequential constraints:    StrictlyIncreasing  StrictlyDecreasing", 
            "title": "Built-in resampling methods"
        }, 
        {
            "location": "/resampling/interpolation/interpolation/", 
            "text": "Interpolations.jl\n is used for basic  interpolation. It supports many different types of interpolation when data are evenly  spaced, and gridded interpolation for unevenly spaced data. \n\n\n\n\nSupported interpolations\n\n\nFor now, \nUncertainData\n implements linear interpolation for uncertain  dataset realizations. \n\n\n\n\nUncertain index-value datasets\n\n\nDatasets with uncertain indices (hence, the indices are almost always unevenly spaced), can only be interpolated using \nlinear interpolation\n.", 
            "title": "Overview"
        }, 
        {
            "location": "/resampling/interpolation/interpolation/#supported_interpolations", 
            "text": "For now,  UncertainData  implements linear interpolation for uncertain  dataset realizations.", 
            "title": "Supported interpolations"
        }, 
        {
            "location": "/resampling/interpolation/interpolation/#uncertain_index-value_datasets", 
            "text": "Datasets with uncertain indices (hence, the indices are almost always unevenly spaced), can only be interpolated using  linear interpolation .", 
            "title": "Uncertain index-value datasets"
        }, 
        {
            "location": "/resampling/interpolation/gridded/", 
            "text": "Grids\n\n\n#\n\n\nUncertainData\n.\nInterpolationAndGrids\n.\nRegularGrid\n \n \nType\n.\n\n\n1\nRegularGrid\n\n\n\n\n\n\n\nFields\n\n\n\n\nmin\n: The minimum value of the grid.\n\n\nmax\n: The maximum value of the grid.\n\n\nstep\n: The interval size.\n\n\nextrapolation_bc\n: The extrapolation condition. Can also be NaN.\n\n\n\n\nsource\n\n\n\n\nSyntax\n\n\n\n\nUncertain index-value datasets\n\n\nThe following methods are available for the interpolating of a realization of an uncertain index-value dataset: \n\n\n\n\nNo constraints\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\n3\nresample\n(\nudata\n::\nUncertainIndexValueDataset\n,\n \n    \ngrid\n::\nInterpolationGrid\n;\n\n    \ntrunc\n::\nTruncateQuantiles\n \n=\n \nTruncateQuantiles\n(\n0.001\n,\n \n0.999\n))\n\n\n\n\n\n\n\nDraw a realization of \nudata\n, then interpolate the data values to \ngrid\n. \n\n\nTo avoid very large spans of interpolation, the uncertain indices are truncated to some  large quantile range. Values are not truncated. \n\n\nsource\n\n\n\n\nSequential constraints\n\n\n#\n\n\nUncertainData\n.\nResampling\n.\nresample\n \n \nMethod\n.\n\n\n1\n2\n3\n4\nresample\n(\nudata\n::\nUncertainIndexValueDataset\n,\n \n    \nsequential_constraint\n::\nSequentialSamplingConstraint\n,\n\n    \ngrid\n::\nInterpolationGrid\n;\n\n    \ntrunc\n::\nTruncateQuantiles\n \n=\n \nTruncateQuantiles\n(\n0.001\n,\n \n0.999\n))\n\n\n\n\n\n\n\nDraw a realization of \nudata\n, enforcing a \nsequential_constraint\n on the indices. Then, interpolate the values of the realization to the provided grid of indices (\ngrid\n). \n\n\nTo avoid very large spans of interpolation, the uncertain indices are truncated to some  large quantile range. Values are not truncated.  \n\n\nsource", 
            "title": "Gridded interpolation"
        }, 
        {
            "location": "/resampling/interpolation/gridded/#grids", 
            "text": "#  UncertainData . InterpolationAndGrids . RegularGrid     Type .  1 RegularGrid    Fields   min : The minimum value of the grid.  max : The maximum value of the grid.  step : The interval size.  extrapolation_bc : The extrapolation condition. Can also be NaN.   source", 
            "title": "Grids"
        }, 
        {
            "location": "/resampling/interpolation/gridded/#syntax", 
            "text": "", 
            "title": "Syntax"
        }, 
        {
            "location": "/resampling/interpolation/gridded/#uncertain_index-value_datasets", 
            "text": "The following methods are available for the interpolating of a realization of an uncertain index-value dataset:", 
            "title": "Uncertain index-value datasets"
        }, 
        {
            "location": "/resampling/interpolation/gridded/#no_constraints", 
            "text": "#  UncertainData . Resampling . resample     Method .  1\n2\n3 resample ( udata :: UncertainIndexValueDataset ,  \n     grid :: InterpolationGrid ; \n     trunc :: TruncateQuantiles   =   TruncateQuantiles ( 0.001 ,   0.999 ))    Draw a realization of  udata , then interpolate the data values to  grid .   To avoid very large spans of interpolation, the uncertain indices are truncated to some  large quantile range. Values are not truncated.   source", 
            "title": "No constraints"
        }, 
        {
            "location": "/resampling/interpolation/gridded/#sequential_constraints", 
            "text": "#  UncertainData . Resampling . resample     Method .  1\n2\n3\n4 resample ( udata :: UncertainIndexValueDataset ,  \n     sequential_constraint :: SequentialSamplingConstraint , \n     grid :: InterpolationGrid ; \n     trunc :: TruncateQuantiles   =   TruncateQuantiles ( 0.001 ,   0.999 ))    Draw a realization of  udata , enforcing a  sequential_constraint  on the indices. Then, interpolate the values of the realization to the provided grid of indices ( grid ).   To avoid very large spans of interpolation, the uncertain indices are truncated to some  large quantile range. Values are not truncated.    source", 
            "title": "Sequential constraints"
        }, 
        {
            "location": "/mathematics/elementary_operations/", 
            "text": "Elementary mathematical operations\n\n\nElementary mathematical operations (\n+\n, \n-\n, \n*\n, and \n/\n) between arbitrary  uncertain values of different types and scalars are supported. \n\n\n\n\nSyntax\n\n\nResampling is used to perform the mathematical operations. All mathematical  operations return a vector containing the results of repeated element-wise operations  (where each element is a resampled draw from the furnishing distribution(s) of the  uncertain value(s)).\n\n\nThe default number of realizations is set to \n10000\n. This allows calling \nuval1\n \n+\n \nuval2\n  for two uncertain values \nuval1\n and \nuval2\n. If you need to tune the number of resample  draws to \nn\n, use the \n+\n(\nuval1\n,\n \nuval2\n,\n \nn\n)\n syntax. \n\n\n\n\nFuture improvements\n\n\nIn the future, elementary operations might be improved for certain combinations of uncertain  values where exact expressions for error propagation are now, for example using the  machinery in \nMeasurements\n.\njl\n for normally distributed values.\n\n\n\n\nSupported operations\n\n\n\n\nAddition\n\n\n#\n\n\nBase\n.:\n+\n \n \nMethod\n.\n\n\n1\nBase\n.:+\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nAbstractUncertainValue\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nAddition operator for pairs of uncertain values. \n\n\nComputes the element-wise sum between for a default of \nn\n \n=\n \n10000\n realizations of \na\n and  \nb\n, then returns an uncertain value based on a kernel density estimate to the distribution  of the element-wise sums.\n\n\nUse the \n+\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n+\n \n \nMethod\n.\n\n\n1\nBase\n.:+\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nAddition operator for pairs of uncertain values. \n\n\nComputes the element-wise sum between \na\n and \nb\n for \nn\n realizations of \na\n and \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.\n\n\nCall this function using the \n+\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n+\n \n \nMethod\n.\n\n\n1\nBase\n.:+\n(\na\n::\nReal\n,\n \nb\n::\nAbstractUncertainValue\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nAddition operator for between scalars and uncertain values. \n\n\nComputes the element-wise sum between \na\n and \nb\n for a default of \nn\n \n=\n \n10000\n realizations of \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.\n\n\nUse the \n+\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n+\n \n \nMethod\n.\n\n\n1\nBase\n.:+\n(\na\n::\nReal\n,\n \nb\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nAddition operator for scalar-uncertain value pairs. \n\n\nComputes the element-wise sum between \na\n and \nb\n for \nn\n realizations of \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.\n\n\nCall this function using the \n+\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n+\n \n \nMethod\n.\n\n\n1\nBase\n.:+\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nReal\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nAddition operator for between uncertain values and scalars. \n\n\nComputes the element-wise sum between \na\n and \nb\n for a default of \nn\n \n=\n \n10000\n realizations of \na\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.\n\n\nUse the \n+\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n+\n \n \nMethod\n.\n\n\n1\nBase\n.:+\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nReal\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nAddition operator for scalar-uncertain value pairs. \n\n\nComputes the element-wise sum between \na\n and \nb\n for \nn\n realizations of \na\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.\n\n\nCall this function using the \n+\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n\n\nSubtraction\n\n\n#\n\n\nBase\n.:-\n \n \nMethod\n.\n\n\n1\nBase\n.:-\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nAbstractUncertainValue\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nSubtraction operator for pairs of uncertain values. \n\n\nComputes the element-wise differences between for a default of \nn\n \n=\n \n30000\n realizations of \na\n and  \nb\n, then returns an uncertain value based on a kernel density estimate to the distribution  of the element-wise differences.\n\n\nUse the \n-\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:-\n \n \nMethod\n.\n\n\n1\nBase\n.:-\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nSubtraction operator for pairs of uncertain values. \n\n\nComputes the element-wise differences between \na\n and \nb\n for \nn\n realizations of \na\n and \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.\n\n\nCall this function using the \n-\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n#\n\n\nBase\n.:-\n \n \nMethod\n.\n\n\n1\nBase\n.:-\n(\na\n::\nReal\n,\n \nb\n::\nAbstractUncertainValue\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nSubtraction operator for between scalars and uncertain values. \n\n\nComputes the element-wise differences between \na\n and \nb\n for a default of \nn\n \n=\n \n30000\n realizations of \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.\n\n\nUse the \n-\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:-\n \n \nMethod\n.\n\n\n1\nBase\n.:-\n(\na\n::\nReal\n,\n \nb\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nSubtraction operator for scalar-uncertain value pairs. \n\n\nComputes the element-wise differences between \na\n and \nb\n for \nn\n realizations of \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.\n\n\nCall this function using the \n-\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n#\n\n\nBase\n.:-\n \n \nMethod\n.\n\n\n1\nBase\n.:-\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nReal\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nSubtraction operator for between uncertain values and scalars. \n\n\nComputes the element-wise differences between \na\n and \nb\n for a default of \nn\n \n=\n \n30000\n realizations of \na\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.\n\n\nUse the \n-\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:-\n \n \nMethod\n.\n\n\n1\nBase\n.:-\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nReal\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nSubtraction operator for scalar-uncertain value pairs. \n\n\nComputes the element-wise differences between \na\n and \nb\n for \nn\n realizations of \na\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.\n\n\nCall this function using the \n-\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n\n\nMultiplication\n\n\n#\n\n\nBase\n.:\n*\n \n \nMethod\n.\n\n\n1\nBase\n.:*\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nAbstractUncertainValue\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nMultiplication operator for pairs of uncertain values. \n\n\nComputes the element-wise products between for a default of \nn\n \n=\n \n10000\n realizations of \na\n and  \nb\n, then returns an uncertain value based on a kernel density estimate to the distribution  of the element-wise products.\n\n\nUse the \n*\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n*\n \n \nMethod\n.\n\n\n1\nBase\n.:*\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nMultiplication operator for pairs of uncertain values. \n\n\nComputes the element-wise products between \na\n and \nb\n for \nn\n realizations of \na\n and \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.\n\n\nCall this function using the \n*\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n*\n \n \nMethod\n.\n\n\n1\nBase\n.:*\n(\na\n::\nReal\n,\n \nb\n::\nAbstractUncertainValue\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nMultiplication operator for between scalars and uncertain values. \n\n\nComputes the element-wise products between \na\n and \nb\n for a default of \nn\n \n=\n \n10000\n realizations of \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.\n\n\nUse the \n*\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n*\n \n \nMethod\n.\n\n\n1\nBase\n.:*\n(\na\n::\nReal\n,\n \nb\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nMultiplication operator for scalar-uncertain value pairs. \n\n\nComputes the element-wise products between \na\n and \nb\n for \nn\n realizations of \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.\n\n\nCall this function using the \n*\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n*\n \n \nMethod\n.\n\n\n1\nBase\n.:*\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nReal\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nMultiplication operator for between uncertain values and scalars. \n\n\nComputes the element-wise products between \na\n and \nb\n for a default of \nn\n \n=\n \n10000\n realizations of \na\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.\n\n\nUse the \n*\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n*\n \n \nMethod\n.\n\n\n1\nBase\n.:*\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nReal\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nMultiplication operator for scalar-uncertain value pairs. \n\n\nComputes the element-wise products between \na\n and \nb\n for \nn\n realizations of \na\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.\n\n\nCall this function using the \n*\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n\n\nDivision\n\n\n#\n\n\nBase\n.:\n/\n \n \nMethod\n.\n\n\n1\nBase\n.:/\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nAbstractUncertainValue\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nDivision operator for pairs of uncertain values. \n\n\nComputes the element-wise quotients between for a default of \nn\n \n=\n \n10000\n realizations of \na\n and  \nb\n, then returns an uncertain value based on a kernel density estimate to the distribution  of the element-wise quotients.\n\n\nUse the \n/\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n/\n \n \nMethod\n.\n\n\n1\nBase\n.:/\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nDivision operator for pairs of uncertain values. \n\n\nComputes the element-wise quotients between \na\n and \nb\n for \nn\n realizations of \na\n and \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.\n\n\nCall this function using the \n/\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n/\n \n \nMethod\n.\n\n\n1\nBase\n.:/\n(\na\n::\nReal\n,\n \nb\n::\nAbstractUncertainValue\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nDivision operator for between scalars and uncertain values. \n\n\nComputes the element-wise quotients between \na\n and \nb\n for a default of \nn\n \n=\n \n10000\n realizations of \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.\n\n\nUse the \n/\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n/\n \n \nMethod\n.\n\n\n1\nBase\n.:/\n(\na\n::\nReal\n,\n \nb\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nDivision operator for scalar-uncertain value pairs. \n\n\nComputes the element-wise quotients between \na\n and \nb\n for \nn\n realizations of \nb\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.\n\n\nCall this function using the \n/\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n/\n \n \nMethod\n.\n\n\n1\nBase\n.:/\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nReal\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nDivision operator for between uncertain values and scalars. \n\n\nComputes the element-wise quotients between \na\n and \nb\n for a default of \nn\n \n=\n \n10000\n realizations of \na\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.\n\n\nUse the \n/\n(\na\n,\n \nb\n,\n \nn\n)\n syntax to tune the number (\nn\n) of draws.\n\n\nsource\n\n\n#\n\n\nBase\n.:\n/\n \n \nMethod\n.\n\n\n1\nBase\n.:/\n(\na\n::\nAbstractUncertainValue\n,\n \nb\n::\nReal\n,\n \nn\n::\nInt\n)\n \n-\n \nUncertainValue\n\n\n\n\n\n\n\nDivision operator for scalar-uncertain value pairs. \n\n\nComputes the element-wise quotients between \na\n and \nb\n for \nn\n realizations of \na\n, then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.\n\n\nCall this function using the \n/\n(\na\n,\n \nb\n,\n \nn\n)\n syntax.\n\n\nsource\n\n\n\n\nSpecial cases\n\n\n\n\nCertainValue\ns\n\n\nPerforming elementary operations with \nCertainValue\ns behaves as for scalars.", 
            "title": "Elementary operations"
        }, 
        {
            "location": "/mathematics/elementary_operations/#elementary_mathematical_operations", 
            "text": "Elementary mathematical operations ( + ,  - ,  * , and  / ) between arbitrary  uncertain values of different types and scalars are supported.", 
            "title": "Elementary mathematical operations"
        }, 
        {
            "location": "/mathematics/elementary_operations/#syntax", 
            "text": "Resampling is used to perform the mathematical operations. All mathematical  operations return a vector containing the results of repeated element-wise operations  (where each element is a resampled draw from the furnishing distribution(s) of the  uncertain value(s)).  The default number of realizations is set to  10000 . This allows calling  uval1   +   uval2   for two uncertain values  uval1  and  uval2 . If you need to tune the number of resample  draws to  n , use the  + ( uval1 ,   uval2 ,   n )  syntax.", 
            "title": "Syntax"
        }, 
        {
            "location": "/mathematics/elementary_operations/#future_improvements", 
            "text": "In the future, elementary operations might be improved for certain combinations of uncertain  values where exact expressions for error propagation are now, for example using the  machinery in  Measurements . jl  for normally distributed values.", 
            "title": "Future improvements"
        }, 
        {
            "location": "/mathematics/elementary_operations/#supported_operations", 
            "text": "", 
            "title": "Supported operations"
        }, 
        {
            "location": "/mathematics/elementary_operations/#addition", 
            "text": "#  Base .: +     Method .  1 Base .:+ ( a :: AbstractUncertainValue ,   b :: AbstractUncertainValue )   -   UncertainValue    Addition operator for pairs of uncertain values.   Computes the element-wise sum between for a default of  n   =   10000  realizations of  a  and   b , then returns an uncertain value based on a kernel density estimate to the distribution  of the element-wise sums.  Use the  + ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .: +     Method .  1 Base .:+ ( a :: AbstractUncertainValue ,   b :: AbstractUncertainValue ,   n :: Int )   -   UncertainValue    Addition operator for pairs of uncertain values.   Computes the element-wise sum between  a  and  b  for  n  realizations of  a  and  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.  Call this function using the  + ( a ,   b ,   n )  syntax.  source  #  Base .: +     Method .  1 Base .:+ ( a :: Real ,   b :: AbstractUncertainValue )   -   UncertainValue    Addition operator for between scalars and uncertain values.   Computes the element-wise sum between  a  and  b  for a default of  n   =   10000  realizations of  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.  Use the  + ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .: +     Method .  1 Base .:+ ( a :: Real ,   b :: AbstractUncertainValue ,   n :: Int )   -   UncertainValue    Addition operator for scalar-uncertain value pairs.   Computes the element-wise sum between  a  and  b  for  n  realizations of  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.  Call this function using the  + ( a ,   b ,   n )  syntax.  source  #  Base .: +     Method .  1 Base .:+ ( a :: AbstractUncertainValue ,   b :: Real )   -   UncertainValue    Addition operator for between uncertain values and scalars.   Computes the element-wise sum between  a  and  b  for a default of  n   =   10000  realizations of  a , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.  Use the  + ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .: +     Method .  1 Base .:+ ( a :: AbstractUncertainValue ,   b :: Real ,   n :: Int )   -   UncertainValue    Addition operator for scalar-uncertain value pairs.   Computes the element-wise sum between  a  and  b  for  n  realizations of  a , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise sums.  Call this function using the  + ( a ,   b ,   n )  syntax.  source", 
            "title": "Addition"
        }, 
        {
            "location": "/mathematics/elementary_operations/#subtraction", 
            "text": "#  Base .:-     Method .  1 Base .:- ( a :: AbstractUncertainValue ,   b :: AbstractUncertainValue )   -   UncertainValue    Subtraction operator for pairs of uncertain values.   Computes the element-wise differences between for a default of  n   =   30000  realizations of  a  and   b , then returns an uncertain value based on a kernel density estimate to the distribution  of the element-wise differences.  Use the  - ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .:-     Method .  1 Base .:- ( a :: AbstractUncertainValue ,   b :: AbstractUncertainValue ,   n :: Int )   -   UncertainValue    Subtraction operator for pairs of uncertain values.   Computes the element-wise differences between  a  and  b  for  n  realizations of  a  and  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.  Call this function using the  - ( a ,   b ,   n )  syntax.  source  #  Base .:-     Method .  1 Base .:- ( a :: Real ,   b :: AbstractUncertainValue )   -   UncertainValue    Subtraction operator for between scalars and uncertain values.   Computes the element-wise differences between  a  and  b  for a default of  n   =   30000  realizations of  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.  Use the  - ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .:-     Method .  1 Base .:- ( a :: Real ,   b :: AbstractUncertainValue ,   n :: Int )   -   UncertainValue    Subtraction operator for scalar-uncertain value pairs.   Computes the element-wise differences between  a  and  b  for  n  realizations of  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.  Call this function using the  - ( a ,   b ,   n )  syntax.  source  #  Base .:-     Method .  1 Base .:- ( a :: AbstractUncertainValue ,   b :: Real )   -   UncertainValue    Subtraction operator for between uncertain values and scalars.   Computes the element-wise differences between  a  and  b  for a default of  n   =   30000  realizations of  a , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.  Use the  - ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .:-     Method .  1 Base .:- ( a :: AbstractUncertainValue ,   b :: Real ,   n :: Int )   -   UncertainValue    Subtraction operator for scalar-uncertain value pairs.   Computes the element-wise differences between  a  and  b  for  n  realizations of  a , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise differences.  Call this function using the  - ( a ,   b ,   n )  syntax.  source", 
            "title": "Subtraction"
        }, 
        {
            "location": "/mathematics/elementary_operations/#multiplication", 
            "text": "#  Base .: *     Method .  1 Base .:* ( a :: AbstractUncertainValue ,   b :: AbstractUncertainValue )   -   UncertainValue    Multiplication operator for pairs of uncertain values.   Computes the element-wise products between for a default of  n   =   10000  realizations of  a  and   b , then returns an uncertain value based on a kernel density estimate to the distribution  of the element-wise products.  Use the  * ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .: *     Method .  1 Base .:* ( a :: AbstractUncertainValue ,   b :: AbstractUncertainValue ,   n :: Int )   -   UncertainValue    Multiplication operator for pairs of uncertain values.   Computes the element-wise products between  a  and  b  for  n  realizations of  a  and  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.  Call this function using the  * ( a ,   b ,   n )  syntax.  source  #  Base .: *     Method .  1 Base .:* ( a :: Real ,   b :: AbstractUncertainValue )   -   UncertainValue    Multiplication operator for between scalars and uncertain values.   Computes the element-wise products between  a  and  b  for a default of  n   =   10000  realizations of  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.  Use the  * ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .: *     Method .  1 Base .:* ( a :: Real ,   b :: AbstractUncertainValue ,   n :: Int )   -   UncertainValue    Multiplication operator for scalar-uncertain value pairs.   Computes the element-wise products between  a  and  b  for  n  realizations of  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.  Call this function using the  * ( a ,   b ,   n )  syntax.  source  #  Base .: *     Method .  1 Base .:* ( a :: AbstractUncertainValue ,   b :: Real )   -   UncertainValue    Multiplication operator for between uncertain values and scalars.   Computes the element-wise products between  a  and  b  for a default of  n   =   10000  realizations of  a , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.  Use the  * ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .: *     Method .  1 Base .:* ( a :: AbstractUncertainValue ,   b :: Real ,   n :: Int )   -   UncertainValue    Multiplication operator for scalar-uncertain value pairs.   Computes the element-wise products between  a  and  b  for  n  realizations of  a , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise products.  Call this function using the  * ( a ,   b ,   n )  syntax.  source", 
            "title": "Multiplication"
        }, 
        {
            "location": "/mathematics/elementary_operations/#division", 
            "text": "#  Base .: /     Method .  1 Base .:/ ( a :: AbstractUncertainValue ,   b :: AbstractUncertainValue )   -   UncertainValue    Division operator for pairs of uncertain values.   Computes the element-wise quotients between for a default of  n   =   10000  realizations of  a  and   b , then returns an uncertain value based on a kernel density estimate to the distribution  of the element-wise quotients.  Use the  / ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .: /     Method .  1 Base .:/ ( a :: AbstractUncertainValue ,   b :: AbstractUncertainValue ,   n :: Int )   -   UncertainValue    Division operator for pairs of uncertain values.   Computes the element-wise quotients between  a  and  b  for  n  realizations of  a  and  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.  Call this function using the  / ( a ,   b ,   n )  syntax.  source  #  Base .: /     Method .  1 Base .:/ ( a :: Real ,   b :: AbstractUncertainValue )   -   UncertainValue    Division operator for between scalars and uncertain values.   Computes the element-wise quotients between  a  and  b  for a default of  n   =   10000  realizations of  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.  Use the  / ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .: /     Method .  1 Base .:/ ( a :: Real ,   b :: AbstractUncertainValue ,   n :: Int )   -   UncertainValue    Division operator for scalar-uncertain value pairs.   Computes the element-wise quotients between  a  and  b  for  n  realizations of  b , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.  Call this function using the  / ( a ,   b ,   n )  syntax.  source  #  Base .: /     Method .  1 Base .:/ ( a :: AbstractUncertainValue ,   b :: Real )   -   UncertainValue    Division operator for between uncertain values and scalars.   Computes the element-wise quotients between  a  and  b  for a default of  n   =   10000  realizations of  a , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.  Use the  / ( a ,   b ,   n )  syntax to tune the number ( n ) of draws.  source  #  Base .: /     Method .  1 Base .:/ ( a :: AbstractUncertainValue ,   b :: Real ,   n :: Int )   -   UncertainValue    Division operator for scalar-uncertain value pairs.   Computes the element-wise quotients between  a  and  b  for  n  realizations of  a , then returns an uncertain value based on a kernel density estimate to the  distribution of the element-wise quotients.  Call this function using the  / ( a ,   b ,   n )  syntax.  source", 
            "title": "Division"
        }, 
        {
            "location": "/mathematics/elementary_operations/#special_cases", 
            "text": "", 
            "title": "Special cases"
        }, 
        {
            "location": "/mathematics/elementary_operations/#certainvalues", 
            "text": "Performing elementary operations with  CertainValue s behaves as for scalars.", 
            "title": "CertainValues"
        }, 
        {
            "location": "/mathematics/trig_functions/", 
            "text": "Trigonometric functions\n\n\nTrigonometric functions are supported for arbitrary uncertain values of different types. Like for \nelementary operations\n, a resampling approach is  used for the computations.\n\n\n\n\nSyntax\n\n\nBecause elementary operations should work on arbitrary uncertain values, a resampling  approach is used to perform the mathematical operations. All mathematical  operations thus return a vector containing the results of repeated element-wise operations  (where each element is a resampled draw from the furnishing distribution(s) of the  uncertain value(s)). \n\n\nEach trigonometric function comes in two versions. \n\n\n\n\nThe first syntax allows skipping providing the number of draws, which is set to 10000 by default    (e.g. \ncos\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n.\n\n\nUsing the second syntax, you have to explicitly provide the number of draws (e.g. \ncos\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n).\n\n\n\n\n\n\nPossible errors\n\n\nBeware: if the support of the funishing distribution for an uncertain value lies partly  outside the domain of the function, you risk encountering errors.\n\n\n\n\nSupported trigonometric functions\n\n\n\n\nSine\n\n\n#\n\n\nBase\n.\nsin\n \n \nMethod\n.\n\n\n1\nBase\n.\nsin\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the sine of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise sine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nsin\n \n \nMethod\n.\n\n\n1\nBase\n.\nsin\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the sine of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise sine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsind\n \n \nMethod\n.\n\n\n1\nBase\n.\nsind\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the sine of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise sine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsind\n \n \nMethod\n.\n\n\n1\nBase\n.\nsind\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the sine of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise sine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nsinh\n \n \nMethod\n.\n\n\n1\nBase\n.\nsinh\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic sine of the uncertain value \nx\n. Computes the element-wise hyperbolic sine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nsinh\n \n \nMethod\n.\n\n\n1\nBase\n.\nsinh\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic sine of the uncertain value \nx\n. Computes the element-wise hyperbolic sine for \nn\n realizations.\n\n\nsource\n\n\n\n\nCosine\n\n\n#\n\n\nBase\n.\ncos\n \n \nMethod\n.\n\n\n1\nBase\n.\ncos\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cosine of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\ncos\n \n \nMethod\n.\n\n\n1\nBase\n.\ncos\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cosine of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncosd\n \n \nMethod\n.\n\n\n1\nBase\n.\ncos\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cosine of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncosd\n \n \nMethod\n.\n\n\n1\nBase\n.\ncos\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cosine of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\ncosh\n \n \nMethod\n.\n\n\n1\nBase\n.\ncos\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic cosine of the uncertain value \nx\n. Computes the element-wise hyperbolic cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\ncosh\n \n \nMethod\n.\n\n\n1\nBase\n.\ncos\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic cosine of the uncertain value \nx\n. Computes the element-wise hyperbolic cosine for \nn\n realizations.\n\n\nsource\n\n\n\n\nTangent\n\n\n#\n\n\nBase\n.\natan\n \n \nMethod\n.\n\n\n1\nBase\n.\natan\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse tangent of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise inverse tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\natan\n \n \nMethod\n.\n\n\n1\nBase\n.\natan\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse tangent of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise inverse tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\natand\n \n \nMethod\n.\n\n\n1\nBase\n.\natand\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse tangent of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise inverse tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\natand\n \n \nMethod\n.\n\n\n1\nBase\n.\natand\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse tangent of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise inverse tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\natanh\n \n \nMethod\n.\n\n\n1\nBase\n.\natanh\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hypoerbolic tangent of the uncertain value \nx\n. Computes the element-wise inverse hypoerbolic tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\natanh\n \n \nMethod\n.\n\n\n1\nBase\n.\natanh\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hypoerbolic tangent of the uncertain value \nx\n. Computes the element-wise inverse hypoerbolic tangent for \nn\n realizations.\n\n\nsource\n\n\n\n\nReciprocal trig functions\n\n\n\n\nCosecant\n\n\n#\n\n\nBase\n.\nMath\n.\ncsc\n \n \nMethod\n.\n\n\n1\nBase\n.\ncsc\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cosecant of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncsc\n \n \nMethod\n.\n\n\n1\nBase\n.\ncsc\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cosecant of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncscd\n \n \nMethod\n.\n\n\n1\nBase\n.\ncscd\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cosecant of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncscd\n \n \nMethod\n.\n\n\n1\nBase\n.\ncscd\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cosecant of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncsch\n \n \nMethod\n.\n\n\n1\nBase\n.\ncscd\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic cosecant of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise hyperbolic cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncsch\n \n \nMethod\n.\n\n\n1\nBase\n.\ncscd\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic cosecant of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise hyperbolic cosecant for \nn\n realizations.\n\n\nsource\n\n\n\n\nSecant\n\n\n#\n\n\nBase\n.\nMath\n.\nsec\n \n \nMethod\n.\n\n\n1\nBase\n.\nsec\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the secant of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsec\n \n \nMethod\n.\n\n\n1\nBase\n.\nsec\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the secant of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsecd\n \n \nMethod\n.\n\n\n1\nBase\n.\nsecd\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the secant of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsecd\n \n \nMethod\n.\n\n\n1\nBase\n.\nsecd\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the secant of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsech\n \n \nMethod\n.\n\n\n1\nBase\n.\nsech\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic secant of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise hyperbolic secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsech\n \n \nMethod\n.\n\n\n1\nBase\n.\nsech\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic secant of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise hyperbolic secant for \nn\n realizations.\n\n\nsource\n\n\n\n\nCotangent\n\n\n#\n\n\nBase\n.\nMath\n.\ncot\n \n \nMethod\n.\n\n\n1\nBase\n.\ncot\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cotangent of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise cotangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncot\n \n \nMethod\n.\n\n\n1\nBase\n.\ncot\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cotangent of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise cotangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncotd\n \n \nMethod\n.\n\n\n1\nBase\n.\ncotd\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cotangent of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise cotangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncotd\n \n \nMethod\n.\n\n\n1\nBase\n.\ncotd\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the cotangent of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise cotangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncoth\n \n \nMethod\n.\n\n\n1\nBase\n.\ncoth\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic cotangent of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise hyperbolic cotangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncoth\n \n \nMethod\n.\n\n\n1\nBase\n.\ncoth\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic cotangent of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise hyperbolic cotangent for \nn\n realizations.\n\n\nsource\n\n\n\n\nInverse trig functions\n\n\n\n\nSine\n\n\n#\n\n\nBase\n.\nasin\n \n \nMethod\n.\n\n\n1\nBase\n.\nasin\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse sine of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise inverse sine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nasin\n \n \nMethod\n.\n\n\n1\nBase\n.\nasin\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse sine of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise inverse sine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nasind\n \n \nMethod\n.\n\n\n1\nBase\n.\nasind\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse sine of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise inverse sine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nasind\n \n \nMethod\n.\n\n\n1\nBase\n.\nasind\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse sine of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise inverse sine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nasinh\n \n \nMethod\n.\n\n\n1\nBase\n.\nasinh\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic sine of the uncertain value \nx\n. Computes the element-wise inverse hyperbolic csine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nasinh\n \n \nMethod\n.\n\n\n1\nBase\n.\nasinh\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic sine of the uncertain value \nx\n. Computes the element-wise inverse hyperbolic csine for \nn\n realizations.\n\n\nsource\n\n\n\n\nCosine\n\n\n#\n\n\nBase\n.\nacos\n \n \nMethod\n.\n\n\n1\nBase\n.\nacos\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cosine of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise inverse cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nacos\n \n \nMethod\n.\n\n\n1\nBase\n.\nacos\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cosine of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise inverse cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacosd\n \n \nMethod\n.\n\n\n1\nBase\n.\nacosd\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cosine of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise inverse cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacosd\n \n \nMethod\n.\n\n\n1\nBase\n.\nacosd\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cosine of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise inverse cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nacosh\n \n \nMethod\n.\n\n\n1\nBase\n.\nacosh\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic cosine of the uncertain value \nx\n. Computes the element-wise inverse hyperbolic cosine for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nacosh\n \n \nMethod\n.\n\n\n1\nBase\n.\nacosh\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic cosine of the uncertain value \nx\n. Computes the element-wise inverse hyperbolic cosine for \nn\n realizations.\n\n\nsource\n\n\n\n\nTangent\n\n\n#\n\n\nBase\n.\ntan\n \n \nMethod\n.\n\n\n1\nBase\n.\ntan\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the tangent of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\ntan\n \n \nMethod\n.\n\n\n1\nBase\n.\ntan\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the tangent of the uncertain value \nx\n, where \nx\n is in radians. Computes the  element-wise tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ntand\n \n \nMethod\n.\n\n\n1\nBase\n.\ntand\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the tangent of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ntand\n \n \nMethod\n.\n\n\n1\nBase\n.\ntand\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the tangent of the uncertain value \nx\n, where \nx\n is in degrees. Computes the  element-wise tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\ntanh\n \n \nMethod\n.\n\n\n1\nBase\n.\ntanh\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic tangent of the uncertain value \nx\n. Computes the element-wise hyperbolic tangent for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\ntanh\n \n \nMethod\n.\n\n\n1\nBase\n.\ntanh\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the hyperbolic tangent of the uncertain value \nx\n.  Computes the element-wise hyperbolic tangent for \nn\n realizations.\n\n\nsource\n\n\n\n\nInverse cosecant\n\n\n#\n\n\nBase\n.\nMath\n.\nacsc\n \n \nMethod\n.\n\n\n1\nBase\n.\nacsc\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cosecant of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise inverse cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacsc\n \n \nMethod\n.\n\n\n1\nBase\n.\nacsc\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cosecant of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise inverse cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacscd\n \n \nMethod\n.\n\n\n1\nBase\n.\nacscd\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cosecant of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise inverse cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacscd\n \n \nMethod\n.\n\n\n1\nBase\n.\nacscd\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cosecant of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise inverse cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacsch\n \n \nMethod\n.\n\n\n1\nBase\n.\nacscd\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic cosecant of the uncertain value \nx\n. Computes the element-wise inverse hypoerbolic cosecant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacsch\n \n \nMethod\n.\n\n\n1\nBase\n.\nacscd\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic cosecant of the uncertain value \nx\n. Computes the element-wise inverse hypoerbolic cosecant for \nn\n realizations.\n\n\nsource\n\n\n\n\nInverse secant\n\n\n#\n\n\nBase\n.\nMath\n.\nasec\n \n \nMethod\n.\n\n\n1\nBase\n.\nasec\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse secant of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise inverse secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nasec\n \n \nMethod\n.\n\n\n1\nBase\n.\nasec\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse secant of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise inverse secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nasecd\n \n \nMethod\n.\n\n\n1\nBase\n.\nasecd\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse secant of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise inverse secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nasecd\n \n \nMethod\n.\n\n\n1\nBase\n.\nasecd\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse secant of the uncertain value \nx\n, where \nx\n is in degrees.  Computes the element-wise inverse secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nasech\n \n \nMethod\n.\n\n\n1\nBase\n.\nasech\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic secant of the uncertain value \nx\n. Computes the element-wise inverse hyperbolic secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nasech\n \n \nMethod\n.\n\n\n1\nBase\n.\nasech\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic secant of the uncertain value \nx\n. Computes the element-wise inverse hyperbolic secant for \nn\n realizations.\n\n\nsource\n\n\n\n\nInverse cotangent\n\n\n#\n\n\nBase\n.\nMath\n.\nacot\n \n \nMethod\n.\n\n\n1\nBase\n.\nacot\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cotangent of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise inverse secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacot\n \n \nMethod\n.\n\n\n1\nBase\n.\nacot\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cotangent of the uncertain value \nx\n, where \nx\n is in radians.  Computes the element-wise inverse secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacotd\n \n \nMethod\n.\n\n\n1\nBase\n.\nacotd\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cotangent of the uncertain value \nx\n, where \nx\n is in degrees. Computes the element-wise inverse secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacotd\n \n \nMethod\n.\n\n\n1\nBase\n.\nacotd\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse cotangent of the uncertain value \nx\n, where \nx\n is in degrees. Computes the element-wise inverse secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacoth\n \n \nMethod\n.\n\n\n1\nBase\n.\nacoth\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic cotangent of the uncertain value \nx\n. Computes the element-wise inverse hyperbolic secant for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nacoth\n \n \nMethod\n.\n\n\n1\nBase\n.\nacoth\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n \n-\n \nVector\n{\nFloat64\n}\n\n\n\n\n\n\n\nCompute the inverse hyperbolic cotangent of the uncertain value \nx\n. Computes the element-wise inverse hyperbolic secant for \nn\n realizations.\n\n\nsource\n\n\n\n\nOther trig functions\n\n\n#\n\n\nBase\n.\nMath\n.\nsincos\n \n \nMethod\n.\n\n\n1\nBase\n.\nsincos\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nSimultaneously compute the sine and cosine of the uncertain value \nx\n, where \nx\n is in  radians. Computes the element-wise \nsincos\n for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsincos\n \n \nMethod\n.\n\n\n1\nBase\n.\nsincos\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nSimultaneously compute the sine and cosine of the uncertain value \nx\n, where \nx\n is in  radians. Computes the element-wise \nsincos\n for \nn\n realizations.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsinc\n \n \nMethod\n.\n\n\n1\nBase\n.\nsinc\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nIn an element-wise manner for \nn\n realizations of the uncertain value \nx\n, compute  \n\\sin(\\pi x) / (\\pi x)\n\\sin(\\pi x) / (\\pi x)\n if \nx \\neq 0\nx \\neq 0\n, and \n1\n1\n if \nx = 0\nx = 0\n.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsinc\n \n \nMethod\n.\n\n\n1\nBase\n.\nsinc\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nCompute \n\\sin(\\pi x) / (\\pi x)\n\\sin(\\pi x) / (\\pi x)\n if \nx \\neq 0\nx \\neq 0\n, and \n1\n1\n if \nx = 0\nx = 0\n element-wise  over \nn\n realizations of the uncertain value \nx\n. \n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsinpi\n \n \nMethod\n.\n\n\n1\nBase\n.\nsinpi\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nCompute \n\\sin(\\pi x)\n\\sin(\\pi x)\n more accurately than \nsin\n(\npi\n*\nx\n)\n, especially for large \nx\n,  in an element-wise over \nn\n realizations of the uncertain value \nx\n. \n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\nsinpi\n \n \nMethod\n.\n\n\n1\nBase\n.\nsinpi\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nCompute \n\\sin(\\pi x)\n\\sin(\\pi x)\n more accurately than \nsin\n(\npi\n*\nx\n)\n, especially for large \nx\n,  in an element-wise over \nn\n realizations of the uncertain value \nx\n. \n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncosc\n \n \nMethod\n.\n\n\n1\nBase\n.\ncosc\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nCompute \n\\cos(\\pi x) / x - \\sin(\\pi x) / (\\pi x^2)\n\\cos(\\pi x) / x - \\sin(\\pi x) / (\\pi x^2)\n if \nx \\neq 0\nx \\neq 0\n, and \n0\n0\n if \nx = 0\nx = 0\n, in an element-wise manner over \nn\n realizations of the uncertain value \nx\n. \n\n\nThis is the derivative of \nsinc\n(\nx\n)\n.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncosc\n \n \nMethod\n.\n\n\n1\nBase\n.\ncosc\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nCompute \n\\cos(\\pi x) / x - \\sin(\\pi x) / (\\pi x^2)\n\\cos(\\pi x) / x - \\sin(\\pi x) / (\\pi x^2)\n if \nx \\neq 0\nx \\neq 0\n, and \n0\n0\n if \nx = 0\nx = 0\n, in an element-wise manner over \nn\n realizations of the uncertain value \nx\n. \n\n\nThis is the derivative of \nsinc\n(\nx\n)\n.\n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncospi\n \n \nMethod\n.\n\n\n1\nBase\n.\ncospi\n(\nx\n::\nAbstractUncertainValue\n;\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nCompute \n\\cos(\\pi x)\n\\cos(\\pi x)\n more accurately than \ncos\n(\npi\n*\nx\n)\n, especially for large \nx\n,  in an element-wise over \nn\n realizations of the uncertain value \nx\n. \n\n\nsource\n\n\n#\n\n\nBase\n.\nMath\n.\ncospi\n \n \nMethod\n.\n\n\n1\nBase\n.\ncospi\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n10000\n)\n\n\n\n\n\n\n\nCompute \n\\cos(\\pi x)\n\\cos(\\pi x)\n more accurately than \ncos\n(\npi\n*\nx\n)\n, especially for large \nx\n,  in an element-wise over \nn\n realizations of the uncertain value \nx\n. \n\n\nsource", 
            "title": "Trigonometric functions"
        }, 
        {
            "location": "/mathematics/trig_functions/#trigonometric_functions", 
            "text": "Trigonometric functions are supported for arbitrary uncertain values of different types. Like for  elementary operations , a resampling approach is  used for the computations.", 
            "title": "Trigonometric functions"
        }, 
        {
            "location": "/mathematics/trig_functions/#syntax", 
            "text": "Because elementary operations should work on arbitrary uncertain values, a resampling  approach is used to perform the mathematical operations. All mathematical  operations thus return a vector containing the results of repeated element-wise operations  (where each element is a resampled draw from the furnishing distribution(s) of the  uncertain value(s)).   Each trigonometric function comes in two versions.    The first syntax allows skipping providing the number of draws, which is set to 10000 by default    (e.g.  cos ( x :: AbstractUncertainValue ;   n :: Int   =   10000 ) .  Using the second syntax, you have to explicitly provide the number of draws (e.g.  cos ( x :: AbstractUncertainValue ,   n :: Int ) ).", 
            "title": "Syntax"
        }, 
        {
            "location": "/mathematics/trig_functions/#possible_errors", 
            "text": "Beware: if the support of the funishing distribution for an uncertain value lies partly  outside the domain of the function, you risk encountering errors.", 
            "title": "Possible errors"
        }, 
        {
            "location": "/mathematics/trig_functions/#supported_trigonometric_functions", 
            "text": "", 
            "title": "Supported trigonometric functions"
        }, 
        {
            "location": "/mathematics/trig_functions/#sine", 
            "text": "#  Base . sin     Method .  1 Base . sin ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the sine of the uncertain value  x , where  x  is in radians. Computes the  element-wise sine for  n  realizations.  source  #  Base . sin     Method .  1 Base . sin ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the sine of the uncertain value  x , where  x  is in radians. Computes the  element-wise sine for  n  realizations.  source  #  Base . Math . sind     Method .  1 Base . sind ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the sine of the uncertain value  x , where  x  is in degrees. Computes the  element-wise sine for  n  realizations.  source  #  Base . Math . sind     Method .  1 Base . sind ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the sine of the uncertain value  x , where  x  is in degrees. Computes the  element-wise sine for  n  realizations.  source  #  Base . sinh     Method .  1 Base . sinh ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic sine of the uncertain value  x . Computes the element-wise hyperbolic sine for  n  realizations.  source  #  Base . sinh     Method .  1 Base . sinh ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic sine of the uncertain value  x . Computes the element-wise hyperbolic sine for  n  realizations.  source", 
            "title": "Sine"
        }, 
        {
            "location": "/mathematics/trig_functions/#cosine", 
            "text": "#  Base . cos     Method .  1 Base . cos ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cosine of the uncertain value  x , where  x  is in radians. Computes the  element-wise cosine for  n  realizations.  source  #  Base . cos     Method .  1 Base . cos ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cosine of the uncertain value  x , where  x  is in radians. Computes the  element-wise cosine for  n  realizations.  source  #  Base . Math . cosd     Method .  1 Base . cos ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cosine of the uncertain value  x , where  x  is in degrees. Computes the  element-wise cosine for  n  realizations.  source  #  Base . Math . cosd     Method .  1 Base . cos ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cosine of the uncertain value  x , where  x  is in degrees. Computes the  element-wise cosine for  n  realizations.  source  #  Base . cosh     Method .  1 Base . cos ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic cosine of the uncertain value  x . Computes the element-wise hyperbolic cosine for  n  realizations.  source  #  Base . cosh     Method .  1 Base . cos ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic cosine of the uncertain value  x . Computes the element-wise hyperbolic cosine for  n  realizations.  source", 
            "title": "Cosine"
        }, 
        {
            "location": "/mathematics/trig_functions/#tangent", 
            "text": "#  Base . atan     Method .  1 Base . atan ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse tangent of the uncertain value  x , where  x  is in radians.  Computes the element-wise inverse tangent for  n  realizations.  source  #  Base . atan     Method .  1 Base . atan ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse tangent of the uncertain value  x , where  x  is in radians.  Computes the element-wise inverse tangent for  n  realizations.  source  #  Base . Math . atand     Method .  1 Base . atand ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse tangent of the uncertain value  x , where  x  is in degrees.  Computes the element-wise inverse tangent for  n  realizations.  source  #  Base . Math . atand     Method .  1 Base . atand ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse tangent of the uncertain value  x , where  x  is in degrees.  Computes the element-wise inverse tangent for  n  realizations.  source  #  Base . atanh     Method .  1 Base . atanh ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hypoerbolic tangent of the uncertain value  x . Computes the element-wise inverse hypoerbolic tangent for  n  realizations.  source  #  Base . atanh     Method .  1 Base . atanh ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hypoerbolic tangent of the uncertain value  x . Computes the element-wise inverse hypoerbolic tangent for  n  realizations.  source", 
            "title": "Tangent"
        }, 
        {
            "location": "/mathematics/trig_functions/#reciprocal_trig_functions", 
            "text": "", 
            "title": "Reciprocal trig functions"
        }, 
        {
            "location": "/mathematics/trig_functions/#cosecant", 
            "text": "#  Base . Math . csc     Method .  1 Base . csc ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cosecant of the uncertain value  x , where  x  is in radians. Computes the  element-wise cosecant for  n  realizations.  source  #  Base . Math . csc     Method .  1 Base . csc ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cosecant of the uncertain value  x , where  x  is in radians. Computes the  element-wise cosecant for  n  realizations.  source  #  Base . Math . cscd     Method .  1 Base . cscd ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cosecant of the uncertain value  x , where  x  is in degrees. Computes the  element-wise cosecant for  n  realizations.  source  #  Base . Math . cscd     Method .  1 Base . cscd ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cosecant of the uncertain value  x , where  x  is in degrees. Computes the  element-wise cosecant for  n  realizations.  source  #  Base . Math . csch     Method .  1 Base . cscd ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic cosecant of the uncertain value  x , where  x  is in degrees.  Computes the element-wise hyperbolic cosecant for  n  realizations.  source  #  Base . Math . csch     Method .  1 Base . cscd ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic cosecant of the uncertain value  x , where  x  is in degrees.  Computes the element-wise hyperbolic cosecant for  n  realizations.  source", 
            "title": "Cosecant"
        }, 
        {
            "location": "/mathematics/trig_functions/#secant", 
            "text": "#  Base . Math . sec     Method .  1 Base . sec ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the secant of the uncertain value  x , where  x  is in radians. Computes the  element-wise secant for  n  realizations.  source  #  Base . Math . sec     Method .  1 Base . sec ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the secant of the uncertain value  x , where  x  is in radians. Computes the  element-wise secant for  n  realizations.  source  #  Base . Math . secd     Method .  1 Base . secd ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the secant of the uncertain value  x , where  x  is in degrees. Computes the  element-wise cosecant for  n  realizations.  source  #  Base . Math . secd     Method .  1 Base . secd ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the secant of the uncertain value  x , where  x  is in degrees. Computes the  element-wise cosecant for  n  realizations.  source  #  Base . Math . sech     Method .  1 Base . sech ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic secant of the uncertain value  x , where  x  is in degrees.  Computes the element-wise hyperbolic secant for  n  realizations.  source  #  Base . Math . sech     Method .  1 Base . sech ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic secant of the uncertain value  x , where  x  is in degrees.  Computes the element-wise hyperbolic secant for  n  realizations.  source", 
            "title": "Secant"
        }, 
        {
            "location": "/mathematics/trig_functions/#cotangent", 
            "text": "#  Base . Math . cot     Method .  1 Base . cot ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cotangent of the uncertain value  x , where  x  is in radians. Computes the  element-wise cotangent for  n  realizations.  source  #  Base . Math . cot     Method .  1 Base . cot ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cotangent of the uncertain value  x , where  x  is in radians. Computes the  element-wise cotangent for  n  realizations.  source  #  Base . Math . cotd     Method .  1 Base . cotd ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cotangent of the uncertain value  x , where  x  is in degrees. Computes the  element-wise cotangent for  n  realizations.  source  #  Base . Math . cotd     Method .  1 Base . cotd ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the cotangent of the uncertain value  x , where  x  is in degrees. Computes the  element-wise cotangent for  n  realizations.  source  #  Base . Math . coth     Method .  1 Base . coth ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic cotangent of the uncertain value  x , where  x  is in radians.  Computes the element-wise hyperbolic cotangent for  n  realizations.  source  #  Base . Math . coth     Method .  1 Base . coth ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic cotangent of the uncertain value  x , where  x  is in radians.  Computes the element-wise hyperbolic cotangent for  n  realizations.  source", 
            "title": "Cotangent"
        }, 
        {
            "location": "/mathematics/trig_functions/#inverse_trig_functions", 
            "text": "", 
            "title": "Inverse trig functions"
        }, 
        {
            "location": "/mathematics/trig_functions/#sine_1", 
            "text": "#  Base . asin     Method .  1 Base . asin ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse sine of the uncertain value  x , where  x  is in radians. Computes the  element-wise inverse sine for  n  realizations.  source  #  Base . asin     Method .  1 Base . asin ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse sine of the uncertain value  x , where  x  is in radians. Computes the  element-wise inverse sine for  n  realizations.  source  #  Base . Math . asind     Method .  1 Base . asind ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse sine of the uncertain value  x , where  x  is in degrees. Computes the  element-wise inverse sine for  n  realizations.  source  #  Base . Math . asind     Method .  1 Base . asind ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse sine of the uncertain value  x , where  x  is in degrees. Computes the  element-wise inverse sine for  n  realizations.  source  #  Base . asinh     Method .  1 Base . asinh ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic sine of the uncertain value  x . Computes the element-wise inverse hyperbolic csine for  n  realizations.  source  #  Base . asinh     Method .  1 Base . asinh ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic sine of the uncertain value  x . Computes the element-wise inverse hyperbolic csine for  n  realizations.  source", 
            "title": "Sine"
        }, 
        {
            "location": "/mathematics/trig_functions/#cosine_1", 
            "text": "#  Base . acos     Method .  1 Base . acos ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cosine of the uncertain value  x , where  x  is in radians. Computes the  element-wise inverse cosine for  n  realizations.  source  #  Base . acos     Method .  1 Base . acos ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cosine of the uncertain value  x , where  x  is in radians. Computes the  element-wise inverse cosine for  n  realizations.  source  #  Base . Math . acosd     Method .  1 Base . acosd ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cosine of the uncertain value  x , where  x  is in degrees. Computes the  element-wise inverse cosine for  n  realizations.  source  #  Base . Math . acosd     Method .  1 Base . acosd ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cosine of the uncertain value  x , where  x  is in degrees. Computes the  element-wise inverse cosine for  n  realizations.  source  #  Base . acosh     Method .  1 Base . acosh ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic cosine of the uncertain value  x . Computes the element-wise inverse hyperbolic cosine for  n  realizations.  source  #  Base . acosh     Method .  1 Base . acosh ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic cosine of the uncertain value  x . Computes the element-wise inverse hyperbolic cosine for  n  realizations.  source", 
            "title": "Cosine"
        }, 
        {
            "location": "/mathematics/trig_functions/#tangent_1", 
            "text": "#  Base . tan     Method .  1 Base . tan ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the tangent of the uncertain value  x , where  x  is in radians. Computes the  element-wise tangent for  n  realizations.  source  #  Base . tan     Method .  1 Base . tan ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the tangent of the uncertain value  x , where  x  is in radians. Computes the  element-wise tangent for  n  realizations.  source  #  Base . Math . tand     Method .  1 Base . tand ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the tangent of the uncertain value  x , where  x  is in degrees. Computes the  element-wise tangent for  n  realizations.  source  #  Base . Math . tand     Method .  1 Base . tand ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the tangent of the uncertain value  x , where  x  is in degrees. Computes the  element-wise tangent for  n  realizations.  source  #  Base . tanh     Method .  1 Base . tanh ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic tangent of the uncertain value  x . Computes the element-wise hyperbolic tangent for  n  realizations.  source  #  Base . tanh     Method .  1 Base . tanh ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the hyperbolic tangent of the uncertain value  x .  Computes the element-wise hyperbolic tangent for  n  realizations.  source", 
            "title": "Tangent"
        }, 
        {
            "location": "/mathematics/trig_functions/#inverse_cosecant", 
            "text": "#  Base . Math . acsc     Method .  1 Base . acsc ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cosecant of the uncertain value  x , where  x  is in radians.  Computes the element-wise inverse cosecant for  n  realizations.  source  #  Base . Math . acsc     Method .  1 Base . acsc ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cosecant of the uncertain value  x , where  x  is in radians.  Computes the element-wise inverse cosecant for  n  realizations.  source  #  Base . Math . acscd     Method .  1 Base . acscd ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cosecant of the uncertain value  x , where  x  is in degrees.  Computes the element-wise inverse cosecant for  n  realizations.  source  #  Base . Math . acscd     Method .  1 Base . acscd ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cosecant of the uncertain value  x , where  x  is in degrees.  Computes the element-wise inverse cosecant for  n  realizations.  source  #  Base . Math . acsch     Method .  1 Base . acscd ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic cosecant of the uncertain value  x . Computes the element-wise inverse hypoerbolic cosecant for  n  realizations.  source  #  Base . Math . acsch     Method .  1 Base . acscd ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic cosecant of the uncertain value  x . Computes the element-wise inverse hypoerbolic cosecant for  n  realizations.  source", 
            "title": "Inverse cosecant"
        }, 
        {
            "location": "/mathematics/trig_functions/#inverse_secant", 
            "text": "#  Base . Math . asec     Method .  1 Base . asec ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse secant of the uncertain value  x , where  x  is in radians.  Computes the element-wise inverse secant for  n  realizations.  source  #  Base . Math . asec     Method .  1 Base . asec ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse secant of the uncertain value  x , where  x  is in radians.  Computes the element-wise inverse secant for  n  realizations.  source  #  Base . Math . asecd     Method .  1 Base . asecd ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse secant of the uncertain value  x , where  x  is in degrees.  Computes the element-wise inverse secant for  n  realizations.  source  #  Base . Math . asecd     Method .  1 Base . asecd ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse secant of the uncertain value  x , where  x  is in degrees.  Computes the element-wise inverse secant for  n  realizations.  source  #  Base . Math . asech     Method .  1 Base . asech ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic secant of the uncertain value  x . Computes the element-wise inverse hyperbolic secant for  n  realizations.  source  #  Base . Math . asech     Method .  1 Base . asech ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic secant of the uncertain value  x . Computes the element-wise inverse hyperbolic secant for  n  realizations.  source", 
            "title": "Inverse secant"
        }, 
        {
            "location": "/mathematics/trig_functions/#inverse_cotangent", 
            "text": "#  Base . Math . acot     Method .  1 Base . acot ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cotangent of the uncertain value  x , where  x  is in radians.  Computes the element-wise inverse secant for  n  realizations.  source  #  Base . Math . acot     Method .  1 Base . acot ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cotangent of the uncertain value  x , where  x  is in radians.  Computes the element-wise inverse secant for  n  realizations.  source  #  Base . Math . acotd     Method .  1 Base . acotd ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cotangent of the uncertain value  x , where  x  is in degrees. Computes the element-wise inverse secant for  n  realizations.  source  #  Base . Math . acotd     Method .  1 Base . acotd ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse cotangent of the uncertain value  x , where  x  is in degrees. Computes the element-wise inverse secant for  n  realizations.  source  #  Base . Math . acoth     Method .  1 Base . acoth ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic cotangent of the uncertain value  x . Computes the element-wise inverse hyperbolic secant for  n  realizations.  source  #  Base . Math . acoth     Method .  1 Base . acoth ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )   -   Vector { Float64 }    Compute the inverse hyperbolic cotangent of the uncertain value  x . Computes the element-wise inverse hyperbolic secant for  n  realizations.  source", 
            "title": "Inverse cotangent"
        }, 
        {
            "location": "/mathematics/trig_functions/#other_trig_functions", 
            "text": "#  Base . Math . sincos     Method .  1 Base . sincos ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )    Simultaneously compute the sine and cosine of the uncertain value  x , where  x  is in  radians. Computes the element-wise  sincos  for  n  realizations.  source  #  Base . Math . sincos     Method .  1 Base . sincos ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )    Simultaneously compute the sine and cosine of the uncertain value  x , where  x  is in  radians. Computes the element-wise  sincos  for  n  realizations.  source  #  Base . Math . sinc     Method .  1 Base . sinc ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )    In an element-wise manner for  n  realizations of the uncertain value  x , compute   \\sin(\\pi x) / (\\pi x) \\sin(\\pi x) / (\\pi x)  if  x \\neq 0 x \\neq 0 , and  1 1  if  x = 0 x = 0 .  source  #  Base . Math . sinc     Method .  1 Base . sinc ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )    Compute  \\sin(\\pi x) / (\\pi x) \\sin(\\pi x) / (\\pi x)  if  x \\neq 0 x \\neq 0 , and  1 1  if  x = 0 x = 0  element-wise  over  n  realizations of the uncertain value  x .   source  #  Base . Math . sinpi     Method .  1 Base . sinpi ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )    Compute  \\sin(\\pi x) \\sin(\\pi x)  more accurately than  sin ( pi * x ) , especially for large  x ,  in an element-wise over  n  realizations of the uncertain value  x .   source  #  Base . Math . sinpi     Method .  1 Base . sinpi ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )    Compute  \\sin(\\pi x) \\sin(\\pi x)  more accurately than  sin ( pi * x ) , especially for large  x ,  in an element-wise over  n  realizations of the uncertain value  x .   source  #  Base . Math . cosc     Method .  1 Base . cosc ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )    Compute  \\cos(\\pi x) / x - \\sin(\\pi x) / (\\pi x^2) \\cos(\\pi x) / x - \\sin(\\pi x) / (\\pi x^2)  if  x \\neq 0 x \\neq 0 , and  0 0  if  x = 0 x = 0 , in an element-wise manner over  n  realizations of the uncertain value  x .   This is the derivative of  sinc ( x ) .  source  #  Base . Math . cosc     Method .  1 Base . cosc ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )    Compute  \\cos(\\pi x) / x - \\sin(\\pi x) / (\\pi x^2) \\cos(\\pi x) / x - \\sin(\\pi x) / (\\pi x^2)  if  x \\neq 0 x \\neq 0 , and  0 0  if  x = 0 x = 0 , in an element-wise manner over  n  realizations of the uncertain value  x .   This is the derivative of  sinc ( x ) .  source  #  Base . Math . cospi     Method .  1 Base . cospi ( x :: AbstractUncertainValue ;   n :: Int   =   10000 )    Compute  \\cos(\\pi x) \\cos(\\pi x)  more accurately than  cos ( pi * x ) , especially for large  x ,  in an element-wise over  n  realizations of the uncertain value  x .   source  #  Base . Math . cospi     Method .  1 Base . cospi ( x :: AbstractUncertainValue ,   n :: Int   =   10000 )    Compute  \\cos(\\pi x) \\cos(\\pi x)  more accurately than  cos ( pi * x ) , especially for large  x ,  in an element-wise over  n  realizations of the uncertain value  x .   source", 
            "title": "Other trig functions"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics/", 
            "text": "Statistics on uncertain values and collections\n\n\nThis package extends many of the statistical algorithms in \nStatsBase\n for uncertain values. The statistics are computed using a resampling approach.\n\n\nTo enable uncertain statistics, first run the following to bring the functions into scope.\n\n\n1\nusing\n \nStatsBase\n\n\n\n\n\n\n\n\n\nList\n\n\n\n\nPoint-estimates of statistics on single uncertain values\n\n\nStatistics on pairs of uncertain values\n\n\nStatistics on a single uncertain data collection\n\n\nStatistics on pairs of uncertain data collections\n\n\n\n\n\n\nCollections of uncertain values\n\n\nIn the documentation for the statistical methods, you'll notice that the inputs are supposed to be of type \nUVAL_COLLECTION_TYPES\n. This is a type union representing all types of collections for which the statistical methods are defined. Currently, this includes \nUncertainValueDataset\n, \nUncertainIndexDataset\n  and vectors of uncertain values (\nVector\n{\nAbstractUncertainValue\n}\n).\n\n\n1\n2\n3\nconst\n \nUVAL_COLLECTION_TYPES\n \n=\n \nUnion\n{\nUD\n,\n \nUV\n}\n \nwhere\n \n{\n\n    \nUD\n \n:\n \nAbstractUncertainValueDataset\n,\n\n    \nUV\n \n:\n \nAbstractVector\n{\nT\n}\n \nwhere\n \n{\nT\n \n:\n \nAbstractUncertainValue\n}}", 
            "title": "Overview"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics/#statistics_on_uncertain_values_and_collections", 
            "text": "This package extends many of the statistical algorithms in  StatsBase  for uncertain values. The statistics are computed using a resampling approach.  To enable uncertain statistics, first run the following to bring the functions into scope.  1 using   StatsBase", 
            "title": "Statistics on uncertain values and collections"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics/#list", 
            "text": "Point-estimates of statistics on single uncertain values  Statistics on pairs of uncertain values  Statistics on a single uncertain data collection  Statistics on pairs of uncertain data collections", 
            "title": "List"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics/#collections_of_uncertain_values", 
            "text": "In the documentation for the statistical methods, you'll notice that the inputs are supposed to be of type  UVAL_COLLECTION_TYPES . This is a type union representing all types of collections for which the statistical methods are defined. Currently, this includes  UncertainValueDataset ,  UncertainIndexDataset   and vectors of uncertain values ( Vector { AbstractUncertainValue } ).  1\n2\n3 const   UVAL_COLLECTION_TYPES   =   Union { UD ,   UV }   where   { \n     UD   :   AbstractUncertainValueDataset , \n     UV   :   AbstractVector { T }   where   { T   :   AbstractUncertainValue }}", 
            "title": "Collections of uncertain values"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/", 
            "text": "Point-estimate statistics\n\n\nThese estimators operate on single uncertain values. They compute the statistic in question by drawing a length-\nn\n draw of the uncertain value, then computing the statistic on that draw.\n\n\n\n\nSyntax\n\n\nThe syntax for computing the statistic \nf\n for single instances of an uncertain value \nx\n is\n\n\n\n\nf\n(\nx\n::\nAbstractUncertainValue\n)\n, which returns the exact value of the statistic if \nx\n is some sort of formal distribution.\n\n\nf\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n,\n \nargs\n...;\n \nkwargs\n...)\n, which estimates the statistic \nf\n for a length-\nn\n draw of \nx\n.\n\n\n\n\n\n\nMean\n\n\n#\n\n\nStatistics\n.\nmean\n \n \nMethod\n.\n\n\n1\nmean\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the mean of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nMode\n\n\n#\n\n\nStatsBase\n.\nmode\n \n \nMethod\n.\n\n\n1\nmode\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the mode of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nQuantile\n\n\n#\n\n\nStatistics\n.\nquantile\n \n \nMethod\n.\n\n\n1\nquantile\n(\nuv\n::\nAbstractUncertainValue\n,\n \nq\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the quantile(s) \nq\n of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nIQR\n\n\n#\n\n\nStatsBase\n.\niqr\n \n \nMethod\n.\n\n\n1\niqr\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the interquartile range (IQR), i.e. the 75\nth\n percentile minus the 25\nth\n percentile, over an \nn\n-draw sample of an uncertain value.\n\n\nsource\n\n\n\n\nMedian\n\n\n#\n\n\nStatistics\n.\nmedian\n \n \nMethod\n.\n\n\n1\nmedian\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the median of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nMiddle\n\n\n#\n\n\nStatistics\n.\nmiddle\n \n \nMethod\n.\n\n\n1\nmiddle\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the middle of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nStandard deviation\n\n\n#\n\n\nStatistics\n.\nstd\n \n \nMethod\n.\n\n\n1\nstd\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the standard deviation of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nVariance\n\n\n#\n\n\nStatistics\n.\nvar\n \n \nMethod\n.\n\n\n1\nvariance\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the variance of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nGeneralized/power mean\n\n\n#\n\n\nStatsBase\n.\ngenmean\n \n \nMethod\n.\n\n\n1\ngenmean\n(\nuv\n::\nAbstractUncertainValue\n,\n \np\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the generalized/power mean with exponent \np\n of an uncertain value over an  \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nGeneralized variance\n\n\n#\n\n\nStatsBase\n.\ngenvar\n \n \nMethod\n.\n\n\n1\ngenvar\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the generalized sample variance of an uncertain value over an  \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nHarmonic mean\n\n\n#\n\n\nStatsBase\n.\nharmmean\n \n \nMethod\n.\n\n\n1\nharmmean\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the harmonic mean of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nGeometric mean\n\n\n#\n\n\nStatsBase\n.\ngeomean\n \n \nMethod\n.\n\n\n1\ngeomean\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the geometric mean of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nKurtosis\n\n\n#\n\n\nStatsBase\n.\nkurtosis\n \n \nMethod\n.\n\n\n1\nkurtosis\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n,\n \nm\n \n=\n \nmean\n(\nuv\n,\n \nn\n))\n\n\n\n\n\n\n\nCompute the excess kurtosis of an uncertain value over an \nn\n-draw sample of it, optionally specifying a center \nm\n).\n\n\nsource\n\n\n\n\nk-th order moment\n\n\n#\n\n\nStatsBase\n.\nmoment\n \n \nFunction\n.\n\n\n1\nmoment\n(\nx\n::\nAbstractUncertainValue\n,\n \nk\n,\n \nn\n::\nInt\n,\n \nm\n \n=\n \nmean\n(\nx\n,\n \nn\n))\n\n\n\n\n\n\n\nCompute the \nk\n-th order central moment of an uncertain value over an  \nn\n-draw sample of it, optionally specifying a center \nm\n.\n\n\nsource\n\n\n\n\nPercentile\n\n\n#\n\n\nStatsBase\n.\npercentile\n \n \nMethod\n.\n\n\n1\npercentile\n(\nx\n::\nAbstractUncertainValue\n,\n \np\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the percentile(s) \np\n of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nRenyi entropy\n\n\n#\n\n\nStatsBase\n.\nrenyientropy\n \n \nMethod\n.\n\n\n1\nrenyientropy\n(\nuv\n::\nAbstractUncertainValue\n,\n \n\u03b1\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the R\u00e9nyi (generalized) entropy of order \n\u03b1\n of an uncertain value over an  \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nRun-length encoding\n\n\n#\n\n\nStatsBase\n.\nrle\n \n \nMethod\n.\n\n\n1\nrle\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the run-length encoding of an uncertain value over a \nn\n-draw  sample of it as a tuple. The first element of the tuple is a vector of  values of the input and the second is the number of consecutive occurrences of each element.\n\n\nsource\n\n\n\n\nStandard error of the mean\n\n\n#\n\n\nStatsBase\n.\nsem\n \n \nMethod\n.\n\n\n1\nsem\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the standard error of the mean of an uncertain value over a \nn\n-draw  sample of it, optionally specifying a center \nm\n, i.e.  \nsqrt\n(\nvar\n(\nx_draw\n,\n \ncorrected\n \n=\n \ntrue\n)\n \n/\n \nlength\n(\nx_draw\n))\n.\n\n\nsource\n\n\n\n\nSkewness\n\n\n#\n\n\nStatsBase\n.\nskewness\n \n \nMethod\n.\n\n\n1\nskewness\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n,\n \nm\n \n=\n \nmean\n(\nx\n,\n \nn\n))\n\n\n\n\n\n\n\nCompute the standardized skewness of an uncertain value over an \nn\n-draw sample of  it, optionally specifying a center \nm\n.\n\n\nsource\n\n\n\n\nSpan\n\n\n#\n\n\nStatsBase\n.\nspan\n \n \nMethod\n.\n\n\n1\nspan\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the span of a collection, i.e. the range \nminimum\n(\nx\n):\nmaximum\n(\nx\n)\n, of an  uncertain value over an \nn\n-draw sample of it.  The minimum and  maximum of the draws of \nx\n are computed in one pass using extrema.\n\n\nsource\n\n\n\n\nSummary statistics\n\n\n#\n\n\nStatsBase\n.\nsummarystats\n \n \nMethod\n.\n\n\n1\nsummarystats\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute summary statistics of an uncertain value over an \nn\n-draw sample of it. Returns  a \nSummaryStats\n object containing the mean, minimum, 25\nth\n percentile, median,  75\nth\n percentile, and maximum.\n\n\nsource\n\n\n\n\nTotal variance\n\n\n#\n\n\nStatsBase\n.\ntotalvar\n \n \nMethod\n.\n\n\n1\ntotalvar\n(\nuv\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the total sample variance of an uncertain value over an  \nn\n-draw sample of it. For a single uncertain value, this is  equivalent to the sample variance.\n\n\nsource\n\n\n\n\nTheoretical and fitted distributions\n\n\nFor theoretical distributions, both with known and fitted parameters, some of  the stats functions may be called without the \nn\n argument, because the underlying distributions are represented as actual distributons. For these, we can compute several of the statistics from the distributions directly.", 
            "title": "Point estimates on values"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#point-estimate_statistics", 
            "text": "These estimators operate on single uncertain values. They compute the statistic in question by drawing a length- n  draw of the uncertain value, then computing the statistic on that draw.", 
            "title": "Point-estimate statistics"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#syntax", 
            "text": "The syntax for computing the statistic  f  for single instances of an uncertain value  x  is   f ( x :: AbstractUncertainValue ) , which returns the exact value of the statistic if  x  is some sort of formal distribution.  f ( x :: AbstractUncertainValue ,   n :: Int ,   args ...;   kwargs ...) , which estimates the statistic  f  for a length- n  draw of  x .", 
            "title": "Syntax"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#mean", 
            "text": "#  Statistics . mean     Method .  1 mean ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the mean of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#mode", 
            "text": "#  StatsBase . mode     Method .  1 mode ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the mode of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Mode"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#quantile", 
            "text": "#  Statistics . quantile     Method .  1 quantile ( uv :: AbstractUncertainValue ,   q ,   n :: Int )    Compute the quantile(s)  q  of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Quantile"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#iqr", 
            "text": "#  StatsBase . iqr     Method .  1 iqr ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the interquartile range (IQR), i.e. the 75 th  percentile minus the 25 th  percentile, over an  n -draw sample of an uncertain value.  source", 
            "title": "IQR"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#median", 
            "text": "#  Statistics . median     Method .  1 median ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the median of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Median"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#middle", 
            "text": "#  Statistics . middle     Method .  1 middle ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the middle of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Middle"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#standard_deviation", 
            "text": "#  Statistics . std     Method .  1 std ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the standard deviation of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Standard deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#variance", 
            "text": "#  Statistics . var     Method .  1 variance ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the variance of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Variance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#generalizedpower_mean", 
            "text": "#  StatsBase . genmean     Method .  1 genmean ( uv :: AbstractUncertainValue ,   p ,   n :: Int )    Compute the generalized/power mean with exponent  p  of an uncertain value over an   n -draw sample of it.  source", 
            "title": "Generalized/power mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#generalized_variance", 
            "text": "#  StatsBase . genvar     Method .  1 genvar ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the generalized sample variance of an uncertain value over an   n -draw sample of it.  source", 
            "title": "Generalized variance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#harmonic_mean", 
            "text": "#  StatsBase . harmmean     Method .  1 harmmean ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the harmonic mean of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Harmonic mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#geometric_mean", 
            "text": "#  StatsBase . geomean     Method .  1 geomean ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the geometric mean of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Geometric mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#kurtosis", 
            "text": "#  StatsBase . kurtosis     Method .  1 kurtosis ( uv :: AbstractUncertainValue ,   n :: Int ,   m   =   mean ( uv ,   n ))    Compute the excess kurtosis of an uncertain value over an  n -draw sample of it, optionally specifying a center  m ).  source", 
            "title": "Kurtosis"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#k-th_order_moment", 
            "text": "#  StatsBase . moment     Function .  1 moment ( x :: AbstractUncertainValue ,   k ,   n :: Int ,   m   =   mean ( x ,   n ))    Compute the  k -th order central moment of an uncertain value over an   n -draw sample of it, optionally specifying a center  m .  source", 
            "title": "k-th order moment"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#percentile", 
            "text": "#  StatsBase . percentile     Method .  1 percentile ( x :: AbstractUncertainValue ,   p ,   n :: Int )    Compute the percentile(s)  p  of an uncertain value over an  n -draw sample of it.  source", 
            "title": "Percentile"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#renyi_entropy", 
            "text": "#  StatsBase . renyientropy     Method .  1 renyientropy ( uv :: AbstractUncertainValue ,   \u03b1 ,   n :: Int )    Compute the R\u00e9nyi (generalized) entropy of order  \u03b1  of an uncertain value over an   n -draw sample of it.  source", 
            "title": "Renyi entropy"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#run-length_encoding", 
            "text": "#  StatsBase . rle     Method .  1 rle ( x :: AbstractUncertainValue ,   n :: Int )    Compute the run-length encoding of an uncertain value over a  n -draw  sample of it as a tuple. The first element of the tuple is a vector of  values of the input and the second is the number of consecutive occurrences of each element.  source", 
            "title": "Run-length encoding"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#standard_error_of_the_mean", 
            "text": "#  StatsBase . sem     Method .  1 sem ( x :: AbstractUncertainValue ,   n :: Int )    Compute the standard error of the mean of an uncertain value over a  n -draw  sample of it, optionally specifying a center  m , i.e.   sqrt ( var ( x_draw ,   corrected   =   true )   /   length ( x_draw )) .  source", 
            "title": "Standard error of the mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#skewness", 
            "text": "#  StatsBase . skewness     Method .  1 skewness ( x :: AbstractUncertainValue ,   n :: Int ,   m   =   mean ( x ,   n ))    Compute the standardized skewness of an uncertain value over an  n -draw sample of  it, optionally specifying a center  m .  source", 
            "title": "Skewness"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#span", 
            "text": "#  StatsBase . span     Method .  1 span ( x :: AbstractUncertainValue ,   n :: Int )    Compute the span of a collection, i.e. the range  minimum ( x ): maximum ( x ) , of an  uncertain value over an  n -draw sample of it.  The minimum and  maximum of the draws of  x  are computed in one pass using extrema.  source", 
            "title": "Span"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#summary_statistics", 
            "text": "#  StatsBase . summarystats     Method .  1 summarystats ( uv :: AbstractUncertainValue ,   n :: Int )    Compute summary statistics of an uncertain value over an  n -draw sample of it. Returns  a  SummaryStats  object containing the mean, minimum, 25 th  percentile, median,  75 th  percentile, and maximum.  source", 
            "title": "Summary statistics"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#total_variance", 
            "text": "#  StatsBase . totalvar     Method .  1 totalvar ( uv :: AbstractUncertainValue ,   n :: Int )    Compute the total sample variance of an uncertain value over an   n -draw sample of it. For a single uncertain value, this is  equivalent to the sample variance.  source", 
            "title": "Total variance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_point_estimates/#theoretical_and_fitted_distributions", 
            "text": "For theoretical distributions, both with known and fitted parameters, some of  the stats functions may be called without the  n  argument, because the underlying distributions are represented as actual distributons. For these, we can compute several of the statistics from the distributions directly.", 
            "title": "Theoretical and fitted distributions"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/", 
            "text": "Pairwise estimates of statistics\n\n\nThese estimators operate on pairs of uncertain values. They compute the  statistic in question by drawing independent length-\nn\n draws of the  uncertain values, then computing the statistic on those draws.\n\n\n\n\nSyntax\n\n\nThe syntax for computing the statistic \nf\n for uncertain values \nx\n and \ny\n is:\n\n\n\n\nf\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nargs\n...,\n \nn\n::\nInt\n;\n \nkwargs\n...)\n, which draws independent length-\nn\n draws of \nx\n and \ny\n, then estimates the statistic \nf\n for those draws.\n\n\n\n\n\n\nCovariance\n\n\n#\n\n\nStatistics\n.\ncov\n \n \nMethod\n.\n\n\n1\n2\ncov\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n;\n \n    \ncorrected\n::\nBool\n \n=\n \ntrue\n)\n\n\n\n\n\n\n\nCompute the covariance between two uncertain values by independently  drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n , then computing  the covariance between those length-\nn\n draws.\n\n\nsource\n\n\n\n\nCorrelation (Pearson)\n\n\n#\n\n\nStatistics\n.\ncor\n \n \nMethod\n.\n\n\n1\ncor\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the Pearson correlation between two uncertain values by independently  drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n, then computing  the Pearson correlation between those length-\nn\n draws.\n\n\nsource\n\n\n\n\nCorrelation (Kendall)\n\n\n#\n\n\nStatsBase\n.\ncorkendall\n \n \nMethod\n.\n\n\n1\ncorkendall\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute Kendalls's rank correlation coefficient between two uncertain values by  independently drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n, then computing  Kendalls's rank correlation coefficient between those length-\nn\n draws.\n\n\nsource\n\n\n\n\nCorrelation (Spearman)\n\n\n#\n\n\nStatsBase\n.\ncorspearman\n \n \nMethod\n.\n\n\n1\ncorspearman\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute Spearman's rank correlation coefficient between two uncertain values by  independently drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n, then computing  the Spearman's rank correlation coefficient between those length-\nn\n draws.\n\n\nsource\n\n\n\n\nCount non-equal\n\n\n#\n\n\nStatsBase\n.\ncountne\n \n \nMethod\n.\n\n\n1\ncountne\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCount the number of indices at which the elements of two independent length-\nn\n draws of \nx\n and for \ny\n are not equal. \n\n\nsource\n\n\n\n\nCount equal\n\n\n#\n\n\nStatsBase\n.\ncounteq\n \n \nMethod\n.\n\n\n1\ncounteq\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCount the number of indices at which the elements of two independent length-\nn\n draws of \nx\n and for \ny\n are equal. \n\n\nsource\n\n\n\n\nMaximum absolute deviation\n\n\n#\n\n\nStatsBase\n.\nmaxad\n \n \nMethod\n.\n\n\n1\nmaxad\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the maximum absolute deviation between two uncertain values by independently  drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n, then computing the  maximum absolute deviation between those length-\nn\n draws.\n\n\nsource\n\n\n\n\nMean absolute deviation\n\n\n#\n\n\nStatsBase\n.\nmeanad\n \n \nMethod\n.\n\n\n1\nmeanad\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the mean absolute deviation between two uncertain values by independently  drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n, then computing the  mean absolute deviation between those length-\nn\n draws.\n\n\nsource\n\n\n\n\nMean squared deviation\n\n\n#\n\n\nStatsBase\n.\nmsd\n \n \nMethod\n.\n\n\n1\nmsd\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the mean squared deviation between two uncertain values by independently  drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n, then computing the  mean squared deviation between those length-\nn\n draws.\n\n\nsource\n\n\n\n\nPeak signal-to-noise ratio\n\n\n#\n\n\nStatsBase\n.\npsnr\n \n \nMethod\n.\n\n\n1\npsnr\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nmaxv\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the peak signal-to-noise ratio between two uncertain values by independently  drawing \nn\n samples from \nx\n and from \ny\n, yielding \nx_draw\n and \ny_draw\n, then  computing the peak signal-to-noise ratio between those length-\nn\n draws. \n\n\nThe PSNR is computed as \n10\n \n*\n \nlog10\n(\nmaxv\n^\n2\n \n/\n \nmsd\n(\nx_draw\n,\n \ny_draw\n))\n, where \nmaxv\n is  the maximum possible value \nx\n or \ny\n can take\n\n\nsource\n\n\n\n\nRoot mean squared deviation\n\n\n#\n\n\nStatsBase\n.\nrmsd\n \n \nMethod\n.\n\n\n1\n2\nrmsd\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n,\n \n    \nnormalize\n \n=\n \nfalse\n)\n\n\n\n\n\n\n\nCompute the root mean squared deviation between two uncertain values by independently  drawing \nn\n samples from \nx\n and from \ny\n, yielding \nx_draw\n and \ny_draw\n, then  computing the the root mean squared deviation between those length-\nn\n draws.  The root mean squared deviation is computed as \nsqrt\n(\nmsd\n(\nx_draw\n,\n \ny_draw\n))\n. Optionally, \nx_draw\n and \ny_draw\n may be normalised.\n\n\nsource\n\n\n\n\nSquared L2 distance\n\n\n#\n\n\nStatsBase\n.\nsqL2dist\n \n \nMethod\n.\n\n\n1\nsqL2dist\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the squared L2 distance between two uncertain values by independently  drawing \nn\n samples from \nx\n and from \ny\n, then computing the   squared L2 distance between those length-\nn\n draws: \n\\sum_{i=1}^n |x_i - y_i|^2\n\\sum_{i=1}^n |x_i - y_i|^2\n.\n\n\nsource\n\n\n\n\nCross correlation\n\n\n#\n\n\nStatsBase\n.\ncrosscor\n \n \nMethod\n.\n\n\n1\n2\ncrosscor\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \n[\nlags\n],\n \n    \nn\n::\nInt\n;\n \ndemean\n \n=\n \ntrue\n)\n\n\n\n\n\n\n\nCompute the cross correlation between two uncertain values by independently  drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n, \nx_draw\n and \ny_draw\n, then computing  the cross correlation between those length-\nn\n draws. \ndemean\n specifies whether the respective  means of the \nx_draw\n and \ny_draw\n should be subtracted from them before computing  their cross correlation.\n\n\nWhen left unspecified, the \nlags\n used are \n-\nmin\n(\nn\n-\n1\n,\n \n10\n*\nlog10\n(\nn\n))\n to \nmin\n(\nn\n,\n \n10\n*\nlog10\n(\nn\n))\n.\n\n\nThe output is normalized by \nsqrt\n(\nvar\n(\nx_draw\n)\n*\nvar\n(\ny_draw\n))\n. See \ncrosscov\n for the unnormalized form.\n\n\nsource\n\n\n\n\nCross covariance\n\n\n#\n\n\nStatsBase\n.\ncrosscov\n \n \nMethod\n.\n\n\n1\n2\ncrosscov\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \n[\nlags\n],\n \n    \nn\n::\nInt\n;\n \ndemean\n \n=\n \ntrue\n)\n\n\n\n\n\n\n\nCompute the cross covariance function (CCF) between two uncertain values by independently  drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n, \nx_draw\n and \ny_draw\n, then computing  the cross correlation between those length-\nn\n draws. \ndemean\n specifies whether the respective  means of the \nx_draw\n and \ny_draw\n should be subtracted from them before computing  their CCF.\n\n\nWhen left unspecified, the \nlags\n used are \n-\nmin\n(\nn\n-\n1\n,\n \n10\n*\nlog10\n(\nn\n))\n to \nmin\n(\nn\n,\n \n10\n*\nlog10\n(\nn\n))\n.\n\n\nThe output is not normalized. See \ncrosscor\n for a function with normalization.\n\n\nsource\n\n\n\n\nGeneralized Kullback-Leibler divergence\n\n\n#\n\n\nStatsBase\n.\ngkldiv\n \n \nMethod\n.\n\n\n1\ngkldiv\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the generalized Kullback-Leibler divergence between two uncertain  values by independently drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n,  then computing the generalized Kullback-Leibler divergence between those  length-\nn\n draws. \n\n\nsource\n\n\n\n\nKullback-Leibler divergence\n\n\n#\n\n\nStatsBase\n.\nkldivergence\n \n \nMethod\n.\n\n\n1\n2\nkldivergence\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \n[\nb\n],\n \n    \nn\n::\nInt\n)\n\n\n\n\n\n\n\nCompute the Kullback-Leibler divergence between two uncertain values by independently  drawing \nn\n samples from \nx\n and \nn\n samples from \ny\n, then computing the  Kullback-Leibler divergence between those length-\nn\n draws. Optionally a real number  \nb\n can be specified such that the divergence is scaled by \n1\n/\nlog\n(\nb\n)\n.\n\n\nsource", 
            "title": "Pairwise estimates on values"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#pairwise_estimates_of_statistics", 
            "text": "These estimators operate on pairs of uncertain values. They compute the  statistic in question by drawing independent length- n  draws of the  uncertain values, then computing the statistic on those draws.", 
            "title": "Pairwise estimates of statistics"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#syntax", 
            "text": "The syntax for computing the statistic  f  for uncertain values  x  and  y  is:   f ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   args ...,   n :: Int ;   kwargs ...) , which draws independent length- n  draws of  x  and  y , then estimates the statistic  f  for those draws.", 
            "title": "Syntax"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#covariance", 
            "text": "#  Statistics . cov     Method .  1\n2 cov ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int ;  \n     corrected :: Bool   =   true )    Compute the covariance between two uncertain values by independently  drawing  n  samples from  x  and  n  samples from  y  , then computing  the covariance between those length- n  draws.  source", 
            "title": "Covariance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#correlation_pearson", 
            "text": "#  Statistics . cor     Method .  1 cor ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Compute the Pearson correlation between two uncertain values by independently  drawing  n  samples from  x  and  n  samples from  y , then computing  the Pearson correlation between those length- n  draws.  source", 
            "title": "Correlation (Pearson)"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#correlation_kendall", 
            "text": "#  StatsBase . corkendall     Method .  1 corkendall ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Compute Kendalls's rank correlation coefficient between two uncertain values by  independently drawing  n  samples from  x  and  n  samples from  y , then computing  Kendalls's rank correlation coefficient between those length- n  draws.  source", 
            "title": "Correlation (Kendall)"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#correlation_spearman", 
            "text": "#  StatsBase . corspearman     Method .  1 corspearman ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Compute Spearman's rank correlation coefficient between two uncertain values by  independently drawing  n  samples from  x  and  n  samples from  y , then computing  the Spearman's rank correlation coefficient between those length- n  draws.  source", 
            "title": "Correlation (Spearman)"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#count_non-equal", 
            "text": "#  StatsBase . countne     Method .  1 countne ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Count the number of indices at which the elements of two independent length- n  draws of  x  and for  y  are not equal.   source", 
            "title": "Count non-equal"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#count_equal", 
            "text": "#  StatsBase . counteq     Method .  1 counteq ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Count the number of indices at which the elements of two independent length- n  draws of  x  and for  y  are equal.   source", 
            "title": "Count equal"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#maximum_absolute_deviation", 
            "text": "#  StatsBase . maxad     Method .  1 maxad ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Compute the maximum absolute deviation between two uncertain values by independently  drawing  n  samples from  x  and  n  samples from  y , then computing the  maximum absolute deviation between those length- n  draws.  source", 
            "title": "Maximum absolute deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#mean_absolute_deviation", 
            "text": "#  StatsBase . meanad     Method .  1 meanad ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Compute the mean absolute deviation between two uncertain values by independently  drawing  n  samples from  x  and  n  samples from  y , then computing the  mean absolute deviation between those length- n  draws.  source", 
            "title": "Mean absolute deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#mean_squared_deviation", 
            "text": "#  StatsBase . msd     Method .  1 msd ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Compute the mean squared deviation between two uncertain values by independently  drawing  n  samples from  x  and  n  samples from  y , then computing the  mean squared deviation between those length- n  draws.  source", 
            "title": "Mean squared deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#peak_signal-to-noise_ratio", 
            "text": "#  StatsBase . psnr     Method .  1 psnr ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   maxv ,   n :: Int )    Compute the peak signal-to-noise ratio between two uncertain values by independently  drawing  n  samples from  x  and from  y , yielding  x_draw  and  y_draw , then  computing the peak signal-to-noise ratio between those length- n  draws.   The PSNR is computed as  10   *   log10 ( maxv ^ 2   /   msd ( x_draw ,   y_draw )) , where  maxv  is  the maximum possible value  x  or  y  can take  source", 
            "title": "Peak signal-to-noise ratio"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#root_mean_squared_deviation", 
            "text": "#  StatsBase . rmsd     Method .  1\n2 rmsd ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int ,  \n     normalize   =   false )    Compute the root mean squared deviation between two uncertain values by independently  drawing  n  samples from  x  and from  y , yielding  x_draw  and  y_draw , then  computing the the root mean squared deviation between those length- n  draws.  The root mean squared deviation is computed as  sqrt ( msd ( x_draw ,   y_draw )) . Optionally,  x_draw  and  y_draw  may be normalised.  source", 
            "title": "Root mean squared deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#squared_l2_distance", 
            "text": "#  StatsBase . sqL2dist     Method .  1 sqL2dist ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Compute the squared L2 distance between two uncertain values by independently  drawing  n  samples from  x  and from  y , then computing the   squared L2 distance between those length- n  draws:  \\sum_{i=1}^n |x_i - y_i|^2 \\sum_{i=1}^n |x_i - y_i|^2 .  source", 
            "title": "Squared L2 distance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#cross_correlation", 
            "text": "#  StatsBase . crosscor     Method .  1\n2 crosscor ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   [ lags ],  \n     n :: Int ;   demean   =   true )    Compute the cross correlation between two uncertain values by independently  drawing  n  samples from  x  and  n  samples from  y ,  x_draw  and  y_draw , then computing  the cross correlation between those length- n  draws.  demean  specifies whether the respective  means of the  x_draw  and  y_draw  should be subtracted from them before computing  their cross correlation.  When left unspecified, the  lags  used are  - min ( n - 1 ,   10 * log10 ( n ))  to  min ( n ,   10 * log10 ( n )) .  The output is normalized by  sqrt ( var ( x_draw ) * var ( y_draw )) . See  crosscov  for the unnormalized form.  source", 
            "title": "Cross correlation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#cross_covariance", 
            "text": "#  StatsBase . crosscov     Method .  1\n2 crosscov ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   [ lags ],  \n     n :: Int ;   demean   =   true )    Compute the cross covariance function (CCF) between two uncertain values by independently  drawing  n  samples from  x  and  n  samples from  y ,  x_draw  and  y_draw , then computing  the cross correlation between those length- n  draws.  demean  specifies whether the respective  means of the  x_draw  and  y_draw  should be subtracted from them before computing  their CCF.  When left unspecified, the  lags  used are  - min ( n - 1 ,   10 * log10 ( n ))  to  min ( n ,   10 * log10 ( n )) .  The output is not normalized. See  crosscor  for a function with normalization.  source", 
            "title": "Cross covariance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#generalized_kullback-leibler_divergence", 
            "text": "#  StatsBase . gkldiv     Method .  1 gkldiv ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )    Compute the generalized Kullback-Leibler divergence between two uncertain  values by independently drawing  n  samples from  x  and  n  samples from  y ,  then computing the generalized Kullback-Leibler divergence between those  length- n  draws.   source", 
            "title": "Generalized Kullback-Leibler divergence"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_pairwise_estimates/#kullback-leibler_divergence", 
            "text": "#  StatsBase . kldivergence     Method .  1\n2 kldivergence ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   [ b ],  \n     n :: Int )    Compute the Kullback-Leibler divergence between two uncertain values by independently  drawing  n  samples from  x  and  n  samples from  y , then computing the  Kullback-Leibler divergence between those length- n  draws. Optionally a real number   b  can be specified such that the divergence is scaled by  1 / log ( b ) .  source", 
            "title": "Kullback-Leibler divergence"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/", 
            "text": "Statistics on single collections of uncertain data\n\n\nThese estimators operate on collections of uncertain values. They compute the  statistic in question by drawing a length-\nn\n draw of the uncertain value,  sampling each point in the collection independently, then computing the statistic  on those \nn\n draws.\n\n\n\n\nSyntax\n\n\nThe syntax for computing a statistic \nf\n for single instances of an uncertain value collections is\n\n\n\n\nf\n(\nx\n::\nUVAL_COLLECTION_TYPES\n)\n, which resamples \nx\n once, assuming no element-wise dependence between the elements of \nx\n.\n\n\nf\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n,\n \nargs\n...;\n \nkwargs\n...)\n, which resamples \nx\n \nn\n times, assuming no    element-wise dependence between the elements of \nx\n, then computes the statistic on each of those \nn\n independent draws. Returns a distributions of estimates of the statistic.\n\n\n\n\n\n\nMean\n\n\n#\n\n\nStatistics\n.\nmean\n \n \nMethod\n.\n\n\n1\nmean\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the mean of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the mean is computed for each of those length-\nL\n realisations, yielding a distribution of mean estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the mean for the realisation.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the mean of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nMode\n\n\n#\n\n\nStatsBase\n.\nmode\n \n \nMethod\n.\n\n\n1\nmode\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the mode of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the mode is computed for each of those length-\nL\n realisations, yielding a distribution of mode estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the mode for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the mode of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nQuantile\n\n\n#\n\n\nStatistics\n.\nquantile\n \n \nMethod\n.\n\n\n1\nquantile\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nq\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the quantile(s) \nq\n of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the quantile is computed for each of those length-\nL\n realisations, yielding a distribution of quantile estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the quantile for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the quantile of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nIQR\n\n\n#\n\n\nStatsBase\n.\niqr\n \n \nMethod\n.\n\n\n1\niqr\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the interquartile range (IQR), i.e. the 75\nth\n  percentile minus the 25\nth\n percentile, of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the IQR is computed for each of those length-\nL\n realisations, yielding a distribution of IQR estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the IQR for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the IQR of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nMedian\n\n\n#\n\n\nStatistics\n.\nmedian\n \n \nMethod\n.\n\n\n1\nmedian\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the median of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the median is computed for each of those length-\nL\n realisations, yielding a distribution of median estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the median for the realisation.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the median of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nMiddle\n\n\n#\n\n\nStatistics\n.\nmiddle\n \n \nMethod\n.\n\n\n1\nmiddle\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the middle of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the middle is computed for each of those length-\nL\n realisations, yielding a distribution of middle estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the middle for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the middle of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nStandard deviation\n\n\n#\n\n\nStatistics\n.\nstd\n \n \nMethod\n.\n\n\n1\nstd\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the standard deviation of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the standard deviation is computed for each of those length-\nL\n realisations, yielding a distribution of standard deviation estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the std for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the standard deviation of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nVariance\n\n\n#\n\n\nStatistics\n.\nvar\n \n \nMethod\n.\n\n\n1\nvar\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the variance of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the variance is computed for each of those length-\nL\n realisations, yielding a distribution of variance estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the variance for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the variance of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nGeneralized/power mean\n\n\n#\n\n\nStatsBase\n.\ngenmean\n \n \nMethod\n.\n\n\n1\ngenmean\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \np\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the generalized/power mean with exponent \np\n of a  collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the generalized mean is computed for each of those length-\nL\n realisations, yielding a distribution of generalized mean estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the generalized mean for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the generalized mean of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nGeneralized variance\n\n\n#\n\n\nStatsBase\n.\ngenvar\n \n \nMethod\n.\n\n\n1\ngenvar\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the generalized sample variance of a collection of  uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the generalized sample variance is computed for each of  those length-\nL\n realisations, yielding a distribution of generalized sample variance estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the generalized sample variance for the realisation, which is a   vector of length \nL\n.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the generalized sample variance of \nx\n,   which is returned as a vector.\n\n\n\n\nsource\n\n\n\n\nHarmonic mean\n\n\n#\n\n\nStatsBase\n.\nharmmean\n \n \nMethod\n.\n\n\n1\nharmmean\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the harmonic mean of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the harmonic mean is computed for each of those length-\nL\n realisations, yielding a distribution of harmonic mean estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the harmonic mean for the realisation.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the harmonic mean of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nGeometric mean\n\n\n#\n\n\nStatsBase\n.\ngeomean\n \n \nMethod\n.\n\n\n1\ngeomean\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the geometric mean of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the geometric mean is computed for each of those length-\nL\n realisations, yielding a distribution of geometric mean estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the geometric mean for the realisation.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the geometric mean of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nKurtosis\n\n\n#\n\n\nStatsBase\n.\nkurtosis\n \n \nMethod\n.\n\n\n1\nkurtosis\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n,\n \nf\n \n=\n \nStatsBase\n.\nmean\n)\n\n\n\n\n\n\n\nObtain a distribution for the kurtosis of a collection of uncertain values.\n\n\nThis is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the kurtosis is computed for each of those length-\nL\n realisations, yielding a distribution of kurtosis estimates. \n\n\nOptionally, a center function \nf\n can be specified. This function is used  to compute the center of each draw, i.e. for the i-th draw, call \nStatsBase\n.\nkurtosis\n(\ndraw_i\n,\n \nf\n(\ndraw_i\n))\n.\n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the kurtosis for the realisation.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the kurtosis of \nx\n, which is returned as a vector.\n\n\n\n\nsource\n\n\n\n\nk-th order moment\n\n\n#\n\n\nStatsBase\n.\nmoment\n \n \nMethod\n.\n\n\n1\nmoment\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nk\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the \nk\n-th order central moment of a collection  of uncertain values.\n\n\nThis is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the \nk\n-th order central moment is computed for each  of those length-\nL\nrealisations, yielding a distribution of \nk\n-th  order central moment estimates. \n\n\nThe procedure is as follows. \n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the \nk\n-th order central moment for the realisation.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the \nk\n-th order central moment of \nx\n,   which is returned as a vector.\n\n\n\n\nsource\n\n\n\n\nPercentile\n\n\n#\n\n\nStatsBase\n.\npercentile\n \n \nMethod\n.\n\n\n1\npercentile\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \np\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the percentile(s) \np\n of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the percentile is computed for each of those length-\nL\n realisations, yielding a distribution of percentile estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the percentile for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the percentile of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nRenyi entropy\n\n\n#\n\n\nStatsBase\n.\nrenyientropy\n \n \nMethod\n.\n\n\n1\nrenyientropy\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \n\u03b1\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the R\u00e9nyi (generalized) entropy of  order \n\u03b1\n of a collection of uncertain values.\n\n\nThis is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the generalized entropy is computed for each  of those length-\nL\nrealisations, yielding a distribution of  generalized entropy estimates. \n\n\nThe procedure is as follows. \n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the R\u00e9nyi (generalized) entropy of order \n\u03b1\n for the realisation.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the R\u00e9nyi (generalized) entropy of   order \n\u03b1\n of \nx\n, which is returned as a vector.\n\n\n\n\nsource\n\n\n\n\nRun-length encoding\n\n\n#\n\n\nStatsBase\n.\nrle\n \n \nMethod\n.\n\n\n1\nrle\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \n\u03b1\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the run-length encoding of a  collection of uncertain values.\n\n\nThis is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the run-length encoding is computed for each  of those length-\nL\nrealisations, yielding a distribution of  run-length encoding estimates. \n\n\nReturns a vector of tuples of run-length encodings.\n\n\nThe procedure is as follows. \n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the run-length encoding for the realisation. This gives a   tuple, where the first element of the tuple is a vector of   values of the input and the second is the number of consecutive occurrences of  each element.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the run-length encoding of \nx\n,   which is returned as a vector of the run-length encoding tuples.\n\n\n\n\nsource\n\n\n\n\nStandard error of the mean\n\n\n#\n\n\nStatsBase\n.\nsem\n \n \nMethod\n.\n\n\n1\nsem\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the standard error of the mean of a  collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the standard error of the mean is computed for  each of those length-\nL\n realisations, yielding a distribution of standard error of the  mean estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the standard error of the mean for the realisation, which is   a vector of length \nL\n.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the standard error of the mean of \nx\n,   which is returned as a vector.\n\n\n\n\nsource\n\n\n\n\nSkewness\n\n\n#\n\n\nStatsBase\n.\nskewness\n \n \nMethod\n.\n\n\n1\nskewness\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n,\n \nf\n \n=\n \nStatsBase\n.\nmean\n)\n\n\n\n\n\n\n\nObtain a distribution for the skewness of a collection of uncertain values.\n\n\nThis is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the skewness is computed for each of those length-\nL\n realisations, yielding a distribution of skewness estimates. \n\n\nOptionally, a center function \nf\n can be specified. This function is used  to compute the center of each draw, i.e. for the i-th draw, call \nStatsBase\n.\nskewness\n(\ndraw_i\n,\n \nf\n(\ndraw_i\n))\n.\n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the skewness for the realisation.\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the skewness of \nx\n,   which is returned as a vector.\n\n\n\n\nsource\n\n\n\n\nSpan\n\n\n#\n\n\nStatsBase\n.\nspan\n \n \nMethod\n.\n\n\n1\nspan\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the span of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the span is computed for each of those length-\nL\n realisations, yielding a distribution of span estimates. \n\n\nReturns a length-\nL\n vector of \nspan\ns, where the i-th span is the range \nminimum\n(\ndraw_x_i\n):\nmaximum\n(\ndraw_x_i\n)\n.\n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the span for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the span of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nSummary statistics\n\n\n#\n\n\nStatsBase\n.\nsummarystats\n \n \nMethod\n.\n\n\n1\nsummarystats\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the summary statistics of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the summary statistics is computed for each of those length-\nL\n realisations, yielding a distribution of summary statistics estimates. \n\n\nReturns a length-\nL\n vector of \nSummaryStats\n objects containing the mean, minimum,  25\nth\n percentile, median, 75\nth\n percentile, and maximum for each draw of \nx\n.\n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the summary statistics for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the summary statistics of \nx\n, which is returned as   a vector.\n\n\n\n\nsource\n\n\n\n\nTotal variance\n\n\n#\n\n\nStatsBase\n.\ntotalvar\n \n \nMethod\n.\n\n\n1\ntotalvar\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution for the total variance of a collection of uncertain values. This is done by first drawing \nn\n length-\nL\n realisations of \nx\n, where  \nL\n \n=\n \nlength\n(\nx\n)\n. Then, the total variance is computed for each of those length-\nL\n realisations, yielding a distribution of total variance estimates. \n\n\nDetailed steps:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nCompute the total variance for the realisation, which is a vector of length \nL\n\n\nRepeat the procedure \nn\n times, drawing \nn\n independent realisations of \nx\n.  This yields \nn\n estimates of the total variance of \nx\n, which is returned as   a vector.\n\n\n\n\nsource", 
            "title": "Estimates on single uncertain value collections"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#statistics_on_single_collections_of_uncertain_data", 
            "text": "These estimators operate on collections of uncertain values. They compute the  statistic in question by drawing a length- n  draw of the uncertain value,  sampling each point in the collection independently, then computing the statistic  on those  n  draws.", 
            "title": "Statistics on single collections of uncertain data"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#syntax", 
            "text": "The syntax for computing a statistic  f  for single instances of an uncertain value collections is   f ( x :: UVAL_COLLECTION_TYPES ) , which resamples  x  once, assuming no element-wise dependence between the elements of  x .  f ( x :: UVAL_COLLECTION_TYPES ,   n :: Int ,   args ...;   kwargs ...) , which resamples  x   n  times, assuming no    element-wise dependence between the elements of  x , then computes the statistic on each of those  n  independent draws. Returns a distributions of estimates of the statistic.", 
            "title": "Syntax"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#mean", 
            "text": "#  Statistics . mean     Method .  1 mean ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the mean of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the mean is computed for each of those length- L  realisations, yielding a distribution of mean estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the mean for the realisation.  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the mean of  x , which is returned as   a vector.   source", 
            "title": "Mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#mode", 
            "text": "#  StatsBase . mode     Method .  1 mode ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the mode of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the mode is computed for each of those length- L  realisations, yielding a distribution of mode estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the mode for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the mode of  x , which is returned as   a vector.   source", 
            "title": "Mode"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#quantile", 
            "text": "#  Statistics . quantile     Method .  1 quantile ( x :: UVAL_COLLECTION_TYPES ,   q ,   n :: Int )    Obtain a distribution for the quantile(s)  q  of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the quantile is computed for each of those length- L  realisations, yielding a distribution of quantile estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the quantile for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the quantile of  x , which is returned as   a vector.   source", 
            "title": "Quantile"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#iqr", 
            "text": "#  StatsBase . iqr     Method .  1 iqr ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the interquartile range (IQR), i.e. the 75 th   percentile minus the 25 th  percentile, of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the IQR is computed for each of those length- L  realisations, yielding a distribution of IQR estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the IQR for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the IQR of  x , which is returned as   a vector.   source", 
            "title": "IQR"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#median", 
            "text": "#  Statistics . median     Method .  1 median ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the median of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the median is computed for each of those length- L  realisations, yielding a distribution of median estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the median for the realisation.  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the median of  x , which is returned as   a vector.   source", 
            "title": "Median"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#middle", 
            "text": "#  Statistics . middle     Method .  1 middle ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the middle of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the middle is computed for each of those length- L  realisations, yielding a distribution of middle estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the middle for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the middle of  x , which is returned as   a vector.   source", 
            "title": "Middle"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#standard_deviation", 
            "text": "#  Statistics . std     Method .  1 std ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the standard deviation of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the standard deviation is computed for each of those length- L  realisations, yielding a distribution of standard deviation estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the std for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the standard deviation of  x , which is returned as   a vector.   source", 
            "title": "Standard deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#variance", 
            "text": "#  Statistics . var     Method .  1 var ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the variance of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the variance is computed for each of those length- L  realisations, yielding a distribution of variance estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the variance for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the variance of  x , which is returned as   a vector.   source", 
            "title": "Variance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#generalizedpower_mean", 
            "text": "#  StatsBase . genmean     Method .  1 genmean ( x :: UVAL_COLLECTION_TYPES ,   p ,   n :: Int )    Obtain a distribution for the generalized/power mean with exponent  p  of a  collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the generalized mean is computed for each of those length- L  realisations, yielding a distribution of generalized mean estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the generalized mean for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the generalized mean of  x , which is returned as   a vector.   source", 
            "title": "Generalized/power mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#generalized_variance", 
            "text": "#  StatsBase . genvar     Method .  1 genvar ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the generalized sample variance of a collection of  uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the generalized sample variance is computed for each of  those length- L  realisations, yielding a distribution of generalized sample variance estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the generalized sample variance for the realisation, which is a   vector of length  L .  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the generalized sample variance of  x ,   which is returned as a vector.   source", 
            "title": "Generalized variance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#harmonic_mean", 
            "text": "#  StatsBase . harmmean     Method .  1 harmmean ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the harmonic mean of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the harmonic mean is computed for each of those length- L  realisations, yielding a distribution of harmonic mean estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the harmonic mean for the realisation.  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the harmonic mean of  x , which is returned as   a vector.   source", 
            "title": "Harmonic mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#geometric_mean", 
            "text": "#  StatsBase . geomean     Method .  1 geomean ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the geometric mean of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the geometric mean is computed for each of those length- L  realisations, yielding a distribution of geometric mean estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the geometric mean for the realisation.  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the geometric mean of  x , which is returned as   a vector.   source", 
            "title": "Geometric mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#kurtosis", 
            "text": "#  StatsBase . kurtosis     Method .  1 kurtosis ( x :: UVAL_COLLECTION_TYPES ,   n :: Int ,   f   =   StatsBase . mean )    Obtain a distribution for the kurtosis of a collection of uncertain values.  This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the kurtosis is computed for each of those length- L  realisations, yielding a distribution of kurtosis estimates.   Optionally, a center function  f  can be specified. This function is used  to compute the center of each draw, i.e. for the i-th draw, call  StatsBase . kurtosis ( draw_i ,   f ( draw_i )) .  Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the kurtosis for the realisation.  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the kurtosis of  x , which is returned as a vector.   source", 
            "title": "Kurtosis"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#k-th_order_moment", 
            "text": "#  StatsBase . moment     Method .  1 moment ( x :: UVAL_COLLECTION_TYPES ,   k ,   n :: Int )    Obtain a distribution for the  k -th order central moment of a collection  of uncertain values.  This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the  k -th order central moment is computed for each  of those length- L realisations, yielding a distribution of  k -th  order central moment estimates.   The procedure is as follows.    First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the  k -th order central moment for the realisation.  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the  k -th order central moment of  x ,   which is returned as a vector.   source", 
            "title": "k-th order moment"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#percentile", 
            "text": "#  StatsBase . percentile     Method .  1 percentile ( x :: UVAL_COLLECTION_TYPES ,   p ,   n :: Int )    Obtain a distribution for the percentile(s)  p  of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the percentile is computed for each of those length- L  realisations, yielding a distribution of percentile estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the percentile for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the percentile of  x , which is returned as   a vector.   source", 
            "title": "Percentile"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#renyi_entropy", 
            "text": "#  StatsBase . renyientropy     Method .  1 renyientropy ( x :: UVAL_COLLECTION_TYPES ,   \u03b1 ,   n :: Int )    Obtain a distribution for the R\u00e9nyi (generalized) entropy of  order  \u03b1  of a collection of uncertain values.  This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the generalized entropy is computed for each  of those length- L realisations, yielding a distribution of  generalized entropy estimates.   The procedure is as follows.    First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the R\u00e9nyi (generalized) entropy of order  \u03b1  for the realisation.  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the R\u00e9nyi (generalized) entropy of   order  \u03b1  of  x , which is returned as a vector.   source", 
            "title": "Renyi entropy"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#run-length_encoding", 
            "text": "#  StatsBase . rle     Method .  1 rle ( x :: UVAL_COLLECTION_TYPES ,   \u03b1 ,   n :: Int )    Obtain a distribution for the run-length encoding of a  collection of uncertain values.  This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the run-length encoding is computed for each  of those length- L realisations, yielding a distribution of  run-length encoding estimates.   Returns a vector of tuples of run-length encodings.  The procedure is as follows.    First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the run-length encoding for the realisation. This gives a   tuple, where the first element of the tuple is a vector of   values of the input and the second is the number of consecutive occurrences of  each element.  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the run-length encoding of  x ,   which is returned as a vector of the run-length encoding tuples.   source", 
            "title": "Run-length encoding"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#standard_error_of_the_mean", 
            "text": "#  StatsBase . sem     Method .  1 sem ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the standard error of the mean of a  collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the standard error of the mean is computed for  each of those length- L  realisations, yielding a distribution of standard error of the  mean estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the standard error of the mean for the realisation, which is   a vector of length  L .  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the standard error of the mean of  x ,   which is returned as a vector.   source", 
            "title": "Standard error of the mean"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#skewness", 
            "text": "#  StatsBase . skewness     Method .  1 skewness ( x :: UVAL_COLLECTION_TYPES ,   n :: Int ,   f   =   StatsBase . mean )    Obtain a distribution for the skewness of a collection of uncertain values.  This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the skewness is computed for each of those length- L  realisations, yielding a distribution of skewness estimates.   Optionally, a center function  f  can be specified. This function is used  to compute the center of each draw, i.e. for the i-th draw, call  StatsBase . skewness ( draw_i ,   f ( draw_i )) .  Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the skewness for the realisation.  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the skewness of  x ,   which is returned as a vector.   source", 
            "title": "Skewness"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#span", 
            "text": "#  StatsBase . span     Method .  1 span ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the span of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the span is computed for each of those length- L  realisations, yielding a distribution of span estimates.   Returns a length- L  vector of  span s, where the i-th span is the range  minimum ( draw_x_i ): maximum ( draw_x_i ) .  Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the span for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the span of  x , which is returned as   a vector.   source", 
            "title": "Span"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#summary_statistics", 
            "text": "#  StatsBase . summarystats     Method .  1 summarystats ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the summary statistics of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the summary statistics is computed for each of those length- L  realisations, yielding a distribution of summary statistics estimates.   Returns a length- L  vector of  SummaryStats  objects containing the mean, minimum,  25 th  percentile, median, 75 th  percentile, and maximum for each draw of  x .  Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the summary statistics for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the summary statistics of  x , which is returned as   a vector.   source", 
            "title": "Summary statistics"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/#total_variance", 
            "text": "#  StatsBase . totalvar     Method .  1 totalvar ( x :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution for the total variance of a collection of uncertain values. This is done by first drawing  n  length- L  realisations of  x , where   L   =   length ( x ) . Then, the total variance is computed for each of those length- L  realisations, yielding a distribution of total variance estimates.   Detailed steps:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Compute the total variance for the realisation, which is a vector of length  L  Repeat the procedure  n  times, drawing  n  independent realisations of  x .  This yields  n  estimates of the total variance of  x , which is returned as   a vector.   source", 
            "title": "Total variance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/", 
            "text": "Pairwise statistics on uncertain data collections\n\n\nThese estimators operate on pairs of uncertain value collections. They compute the  statistic in question by drawing length-\nn\n draws of both datasets independently, then computing the statistic \nn\n times for the \nn\n pairs of draws. \n\n\nWithin each collection, point are always sampled independently according to their  furnishing distributions.\n\n\n\n\nSyntax\n\n\nThe syntax for estimating of a statistic \nf\n on uncertain value collections \nx\n and \ny\n is\n\n\n\n\nf\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nargs\n...,\n \nn\n::\nInt\n;\n \nkwargs\n...)\n, which draws independent length-\nn\n draws of \nx\n and \ny\n, then estimates the statistic \nf\n for those draws.\n\n\n\n\n\n\nCovariance\n\n\n#\n\n\nStatistics\n.\ncov\n \n \nMethod\n.\n\n\n1\ncov\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n;\n \ncorrected\n::\nBool\n \n=\n \ntrue\n)\n\n\n\n\n\n\n\nObtain a distribution on the covariance between two collections of  uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the covariance between the two length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the covariance between \nn\n independent pairs  of realisations of \nx\n and \ny\n. The \nn\n-member distribution of covariance  estimates is returned as a vector.\n\n\nIf \ncorrected\n is \ntrue\n (the default) then the sum is scaled with \nn\n \n-\n \n1\n for  each pair of draws, whereas the sum is scaled with \nn\n if \ncorrected\n is \nfalse\n  where \nn\n \n=\n \nlength\n(\nx\n)\n.\n\n\nsource\n\n\n\n\nCorrelation (Pearson)\n\n\n#\n\n\nStatistics\n.\ncor\n \n \nMethod\n.\n\n\n1\ncor\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nEstimate a distribution on Pearson's rank correlation coefficient between  two collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute Pearson's rank correlation coefficient between the two length-\nL\n  draws.\n\n\n\n\nThis yields \nn\n estimates of Pearson's rank correlation coefficient  between \nn\n independent pairs of realisations of \nx\n and \ny\n. The  \nn\n-member distribution of correlation estimates is returned as a vector.\n\n\nsource\n\n\n\n\nCorrelation (Kendall)\n\n\n#\n\n\nStatsBase\n.\ncorkendall\n \n \nMethod\n.\n\n\n1\ncorkendall\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nEstimate a \nn\n-member distribution on Kendalls's rank correlation  coefficient between two collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute Kendall's rank correlation coefficient between the two length-\nL\n  draws.\n\n\n\n\nThis yields \nn\n computations of Kendall's rank correlation coefficient  between \nn\n independent pairs of realisations of \nx\n and \ny\n. The  \nn\n-member distribution of correlation estimates is returned as a vector.\n\n\nsource\n\n\n\n\nCorrelation (Spearman)\n\n\n#\n\n\nStatsBase\n.\ncorspearman\n \n \nMethod\n.\n\n\n1\ncorspearman\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nEstimate a \nn\n-member distribution on Spearman's rank correlation  coefficient between two collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute Spearman's rank correlation coefficient between the two length-\nL\n  draws.\n\n\n\n\nThis yields \nn\n estimates of Spearman's rank correlation coefficient  between \nn\n independent pairs of realisations of \nx\n and \ny\n. The  \nn\n-member distribution of correlation estimates is returned as a vector.\n\n\nsource\n\n\n\n\nCount non-equal\n\n\n#\n\n\nStatsBase\n.\ncountne\n \n \nMethod\n.\n\n\n1\ncountne\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nEstimate a \nn\n-member distribution on the number of indices at which the elements of  two collections of uncertain values are not equal. \n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nDraw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nDraw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCount the number of indices at which the elements of the two length-\nL\n  draws are not equal.\n\n\n\n\nThis yields \nn\n counts of non-equal values between \nn\n pairs of independent  realisations of \nx\n and \ny\n. The \nn\n-member distribution of nonequal-value counts  is returned as a vector.\n\n\nsource\n\n\n\n\nCount equal\n\n\n#\n\n\nStatsBase\n.\ncounteq\n \n \nMethod\n.\n\n\n1\ncounteq\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nEstimate a \nn\n-member distribution on the number of indices at which the elements of  two collections of uncertain values are equal.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCount the number of indices at which the elements of the two length-\nL\n  draws are equal.\n\n\n\n\nThis yields \nn\n counts of non-equal values between \nn\n pairs of independent  realisations of \nx\n and \ny\n. The \nn\n-member distribution of equal-value counts  is returned as a vector.\n\n\nsource\n\n\n\n\nMaximum absolute deviation\n\n\n#\n\n\nStatsBase\n.\nmaxad\n \n \nMethod\n.\n\n\n1\nmaxad\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution over the maximum absolute deviation between two  collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the maximum absolute deviation between the two   length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the maximum absolute deviation between \nn\n independent pairs of realisations of \nx\n and \ny\n. The \nn\n-member  distribution of maximum absolute deviation estimates is  returned as a vector.\n\n\nsource\n\n\n\n\nMean absolute deviation\n\n\n#\n\n\nStatsBase\n.\nmeanad\n \n \nMethod\n.\n\n\n1\nmeanad\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution over the mean absolute deviation between two  collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the mean absolute deviation between the two   length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the mean absolute deviation between \nn\n independent pairs of realisations of \nx\n and \ny\n. The \nn\n-member  distribution of mean absolute deviation estimates is  returned as a vector.\n\n\nsource\n\n\n\n\nMean squared deviation\n\n\n#\n\n\nStatsBase\n.\nmsd\n \n \nMethod\n.\n\n\n1\nmsd\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution over the mean squared deviation between two  collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the mean squared deviation between the two   length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the mean squared deviation between \nn\n independent pairs of realisations of \nx\n and \ny\n. The \nn\n-member  distribution of mean squared deviation estimates is  returned as a vector.\n\n\nsource\n\n\n\n\nPeak signal-to-noise ratio\n\n\n#\n\n\nStatsBase\n.\npsnr\n \n \nMethod\n.\n\n\n1\npsnr\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nmaxv\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution over the peak signal-to-noise ratio (PSNR) between two  collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the PSNR between the two length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the peak signal-to-noise ratio between \nn\n independent pairs of realisations of \nx\n and \ny\n. The \nn\n-member  distribution of PSNR estimates is returned as a vector.\n\n\nThe PSNR is computed as \n10\n \n*\n \nlog10\n(\nmaxv\n^\n2\n \n/\n \nmsd\n(\nx_draw\n,\n \ny_draw\n))\n, where \nmaxv\n is  the maximum possible value \nx\n or \ny\n can take\n\n\nsource\n\n\n\n\nRoot mean squared deviation\n\n\n#\n\n\nStatsBase\n.\nrmsd\n \n \nMethod\n.\n\n\n1\nrmsd\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n,\n \nnormalize\n \n=\n \nfalse\n)\n\n\n\n\n\n\n\nObtain a distribution over the root mean squared deviation between two  collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the root mean squared deviation between the two   length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the root mean squared deviation between \nn\n independent pairs of realisations of \nx\n and \ny\n. The \nn\n-member  distribution of root mean squared deviation estimates is  returned as a vector.\n\n\nThe root mean squared deviation is computed as \nsqrt\n(\nmsd\n(\nx_draw\n,\n \ny_draw\n))\n  at each iteration. Optionally, \nx_draw\n and \ny_draw\n may be normalised.\n\n\nsource\n\n\n\n\nSquared L2 distance\n\n\n#\n\n\nStatsBase\n.\nsqL2dist\n \n \nMethod\n.\n\n\n1\nsqL2dist\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution over the squared L2 distance between two  collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the squared L2 distance between the two   length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the squared L2 distance between \nn\n independent pairs of realisations of \nx\n and \ny\n. The \nn\n-member  distribution of squared L2 distance estimates is returned as a vector.\n\n\nThe squared L2 distance is computed as \n\\sum_{i=1}^n |x_i - y_i|^2\n\\sum_{i=1}^n |x_i - y_i|^2\n.\n\n\nsource\n\n\n\n\nCross correlation\n\n\n#\n\n\nStatsBase\n.\ncrosscor\n \n \nMethod\n.\n\n\n1\ncrosscor\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \n[\nlags\n],\n \nn\n::\nInt\n;\n \ndemean\n \n=\n \ntrue\n)\n\n\n\n\n\n\n\nObtain a distribution over the cross correlation between two collections of  uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the cross correlation between the two length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the cross correlation between \nn\n independent pairs  of realisations of \nx\n and \ny\n. The \nn\n-member distribution of cross correlation estimates is returned as a vector.\n\n\ndemean\n specifies whether, at each iteration, the respective means of the draws  should be subtracted from them before computing their cross correlation.\n\n\nWhen left unspecified, the \nlags\n used are \n-\nmin\n(\nn\n-\n1\n,\n \n10\n*\nlog10\n(\nn\n))\n to \nmin\n(\nn\n,\n \n10\n*\nlog10\n(\nn\n))\n.\n\n\nThe output is normalized by \nsqrt\n(\nvar\n(\nx_draw\n)\n*\nvar\n(\ny_draw\n))\n. See \ncrosscov\n for the unnormalized form.\n\n\nsource\n\n\n\n\nCross covariance\n\n\n#\n\n\nStatsBase\n.\ncrosscov\n \n \nMethod\n.\n\n\n1\ncrosscov\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \n[\nlags\n],\n \nn\n::\nInt\n;\n \ndemean\n \n=\n \ntrue\n)\n\n\n\n\n\n\n\nObtain a distribution over the cross covariance function (CCF) between two  collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the CCF between the two length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the CCF between \nn\n independent pairs  of realisations of \nx\n and \ny\n. The \nn\n-member distribution of CCF estimates  is returned as a vector.\n\n\ndemean\n specifies whether, at each iteration, the respective means of the draws  should be subtracted from them before computing their CCF.\n\n\nWhen left unspecified, the \nlags\n used are \n-\nmin\n(\nn\n-\n1\n,\n \n10\n*\nlog10\n(\nn\n))\n to \nmin\n(\nn\n,\n \n10\n*\nlog10\n(\nn\n))\n.\n\n\nThe output is not normalized. See \ncrosscor\n for a function with normalization.\n\n\nsource\n\n\n\n\nGeneralized Kullback-Leibler divergence\n\n\n#\n\n\nStatsBase\n.\ngkldiv\n \n \nMethod\n.\n\n\n1\ngkldiv\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution over the generalized Kullback-Leibler divergence between two  collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the  generalized Kullback-Leibler divergence between the two   length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the  generalized Kullback-Leibler divergence  between \nn\n independent pairs of realisations of \nx\n and \ny\n. The \nn\n-member  distribution of generalized Kullback-Leibler divergence estimates is  returned as a vector.\n\n\nsource\n\n\n\n\nKullback-Leibler divergence\n\n\n#\n\n\nStatsBase\n.\nkldivergence\n \n \nMethod\n.\n\n\n1\nkldivergence\n(\nx\n::\nUVAL_COLLECTION_TYPES\n,\n \ny\n::\nUVAL_COLLECTION_TYPES\n,\n \n[\nb\n],\n \nn\n::\nInt\n)\n\n\n\n\n\n\n\nObtain a distribution over the Kullback-Leibler divergence between two  collections of uncertain values.\n\n\nThis is done by repeating the following procedure \nn\n times:\n\n\n\n\nFirst, draw a length-\nL\n realisation of \nx\n by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.\n\n\nSecond, draw a length-\nL\n realisation of \ny\n in the same manner.\n\n\nCompute the Kullback-Leibler divergence between the two   length-\nL\n draws.\n\n\n\n\nThis yields \nn\n estimates of the Kullback-Leibler divergence  between \nn\n independent pairs of realisations of \nx\n and \ny\n. The \nn\n-member  distribution of Kullback-Leibler divergence estimates is  returned as a vector.\n\n\nOptionally a real number \nb\n can be specified such that the divergence is  scaled by \n1\n/\nlog\n(\nb\n)\n.\n\n\nsource", 
            "title": "Estimates on pairs of uncertain value collections"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#pairwise_statistics_on_uncertain_data_collections", 
            "text": "These estimators operate on pairs of uncertain value collections. They compute the  statistic in question by drawing length- n  draws of both datasets independently, then computing the statistic  n  times for the  n  pairs of draws.   Within each collection, point are always sampled independently according to their  furnishing distributions.", 
            "title": "Pairwise statistics on uncertain data collections"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#syntax", 
            "text": "The syntax for estimating of a statistic  f  on uncertain value collections  x  and  y  is   f ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   args ...,   n :: Int ;   kwargs ...) , which draws independent length- n  draws of  x  and  y , then estimates the statistic  f  for those draws.", 
            "title": "Syntax"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#covariance", 
            "text": "#  Statistics . cov     Method .  1 cov ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int ;   corrected :: Bool   =   true )    Obtain a distribution on the covariance between two collections of  uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the covariance between the two length- L  draws.   This yields  n  estimates of the covariance between  n  independent pairs  of realisations of  x  and  y . The  n -member distribution of covariance  estimates is returned as a vector.  If  corrected  is  true  (the default) then the sum is scaled with  n   -   1  for  each pair of draws, whereas the sum is scaled with  n  if  corrected  is  false   where  n   =   length ( x ) .  source", 
            "title": "Covariance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#correlation_pearson", 
            "text": "#  Statistics . cor     Method .  1 cor ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Estimate a distribution on Pearson's rank correlation coefficient between  two collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute Pearson's rank correlation coefficient between the two length- L   draws.   This yields  n  estimates of Pearson's rank correlation coefficient  between  n  independent pairs of realisations of  x  and  y . The   n -member distribution of correlation estimates is returned as a vector.  source", 
            "title": "Correlation (Pearson)"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#correlation_kendall", 
            "text": "#  StatsBase . corkendall     Method .  1 corkendall ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Estimate a  n -member distribution on Kendalls's rank correlation  coefficient between two collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute Kendall's rank correlation coefficient between the two length- L   draws.   This yields  n  computations of Kendall's rank correlation coefficient  between  n  independent pairs of realisations of  x  and  y . The   n -member distribution of correlation estimates is returned as a vector.  source", 
            "title": "Correlation (Kendall)"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#correlation_spearman", 
            "text": "#  StatsBase . corspearman     Method .  1 corspearman ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Estimate a  n -member distribution on Spearman's rank correlation  coefficient between two collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute Spearman's rank correlation coefficient between the two length- L   draws.   This yields  n  estimates of Spearman's rank correlation coefficient  between  n  independent pairs of realisations of  x  and  y . The   n -member distribution of correlation estimates is returned as a vector.  source", 
            "title": "Correlation (Spearman)"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#count_non-equal", 
            "text": "#  StatsBase . countne     Method .  1 countne ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Estimate a  n -member distribution on the number of indices at which the elements of  two collections of uncertain values are not equal.   This is done by repeating the following procedure  n  times:   Draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Draw a length- L  realisation of  y  in the same manner.  Count the number of indices at which the elements of the two length- L   draws are not equal.   This yields  n  counts of non-equal values between  n  pairs of independent  realisations of  x  and  y . The  n -member distribution of nonequal-value counts  is returned as a vector.  source", 
            "title": "Count non-equal"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#count_equal", 
            "text": "#  StatsBase . counteq     Method .  1 counteq ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Estimate a  n -member distribution on the number of indices at which the elements of  two collections of uncertain values are equal.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from  each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Count the number of indices at which the elements of the two length- L   draws are equal.   This yields  n  counts of non-equal values between  n  pairs of independent  realisations of  x  and  y . The  n -member distribution of equal-value counts  is returned as a vector.  source", 
            "title": "Count equal"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#maximum_absolute_deviation", 
            "text": "#  StatsBase . maxad     Method .  1 maxad ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution over the maximum absolute deviation between two  collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the maximum absolute deviation between the two   length- L  draws.   This yields  n  estimates of the maximum absolute deviation between  n  independent pairs of realisations of  x  and  y . The  n -member  distribution of maximum absolute deviation estimates is  returned as a vector.  source", 
            "title": "Maximum absolute deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#mean_absolute_deviation", 
            "text": "#  StatsBase . meanad     Method .  1 meanad ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution over the mean absolute deviation between two  collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the mean absolute deviation between the two   length- L  draws.   This yields  n  estimates of the mean absolute deviation between  n  independent pairs of realisations of  x  and  y . The  n -member  distribution of mean absolute deviation estimates is  returned as a vector.  source", 
            "title": "Mean absolute deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#mean_squared_deviation", 
            "text": "#  StatsBase . msd     Method .  1 msd ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution over the mean squared deviation between two  collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the mean squared deviation between the two   length- L  draws.   This yields  n  estimates of the mean squared deviation between  n  independent pairs of realisations of  x  and  y . The  n -member  distribution of mean squared deviation estimates is  returned as a vector.  source", 
            "title": "Mean squared deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#peak_signal-to-noise_ratio", 
            "text": "#  StatsBase . psnr     Method .  1 psnr ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   maxv ,   n :: Int )    Obtain a distribution over the peak signal-to-noise ratio (PSNR) between two  collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the PSNR between the two length- L  draws.   This yields  n  estimates of the peak signal-to-noise ratio between  n  independent pairs of realisations of  x  and  y . The  n -member  distribution of PSNR estimates is returned as a vector.  The PSNR is computed as  10   *   log10 ( maxv ^ 2   /   msd ( x_draw ,   y_draw )) , where  maxv  is  the maximum possible value  x  or  y  can take  source", 
            "title": "Peak signal-to-noise ratio"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#root_mean_squared_deviation", 
            "text": "#  StatsBase . rmsd     Method .  1 rmsd ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int ,   normalize   =   false )    Obtain a distribution over the root mean squared deviation between two  collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the root mean squared deviation between the two   length- L  draws.   This yields  n  estimates of the root mean squared deviation between  n  independent pairs of realisations of  x  and  y . The  n -member  distribution of root mean squared deviation estimates is  returned as a vector.  The root mean squared deviation is computed as  sqrt ( msd ( x_draw ,   y_draw ))   at each iteration. Optionally,  x_draw  and  y_draw  may be normalised.  source", 
            "title": "Root mean squared deviation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#squared_l2_distance", 
            "text": "#  StatsBase . sqL2dist     Method .  1 sqL2dist ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution over the squared L2 distance between two  collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the squared L2 distance between the two   length- L  draws.   This yields  n  estimates of the squared L2 distance between  n  independent pairs of realisations of  x  and  y . The  n -member  distribution of squared L2 distance estimates is returned as a vector.  The squared L2 distance is computed as  \\sum_{i=1}^n |x_i - y_i|^2 \\sum_{i=1}^n |x_i - y_i|^2 .  source", 
            "title": "Squared L2 distance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#cross_correlation", 
            "text": "#  StatsBase . crosscor     Method .  1 crosscor ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   [ lags ],   n :: Int ;   demean   =   true )    Obtain a distribution over the cross correlation between two collections of  uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the cross correlation between the two length- L  draws.   This yields  n  estimates of the cross correlation between  n  independent pairs  of realisations of  x  and  y . The  n -member distribution of cross correlation estimates is returned as a vector.  demean  specifies whether, at each iteration, the respective means of the draws  should be subtracted from them before computing their cross correlation.  When left unspecified, the  lags  used are  - min ( n - 1 ,   10 * log10 ( n ))  to  min ( n ,   10 * log10 ( n )) .  The output is normalized by  sqrt ( var ( x_draw ) * var ( y_draw )) . See  crosscov  for the unnormalized form.  source", 
            "title": "Cross correlation"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#cross_covariance", 
            "text": "#  StatsBase . crosscov     Method .  1 crosscov ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   [ lags ],   n :: Int ;   demean   =   true )    Obtain a distribution over the cross covariance function (CCF) between two  collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the CCF between the two length- L  draws.   This yields  n  estimates of the CCF between  n  independent pairs  of realisations of  x  and  y . The  n -member distribution of CCF estimates  is returned as a vector.  demean  specifies whether, at each iteration, the respective means of the draws  should be subtracted from them before computing their CCF.  When left unspecified, the  lags  used are  - min ( n - 1 ,   10 * log10 ( n ))  to  min ( n ,   10 * log10 ( n )) .  The output is not normalized. See  crosscor  for a function with normalization.  source", 
            "title": "Cross covariance"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#generalized_kullback-leibler_divergence", 
            "text": "#  StatsBase . gkldiv     Method .  1 gkldiv ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   n :: Int )    Obtain a distribution over the generalized Kullback-Leibler divergence between two  collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the  generalized Kullback-Leibler divergence between the two   length- L  draws.   This yields  n  estimates of the  generalized Kullback-Leibler divergence  between  n  independent pairs of realisations of  x  and  y . The  n -member  distribution of generalized Kullback-Leibler divergence estimates is  returned as a vector.  source", 
            "title": "Generalized Kullback-Leibler divergence"
        }, 
        {
            "location": "/uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/#kullback-leibler_divergence", 
            "text": "#  StatsBase . kldivergence     Method .  1 kldivergence ( x :: UVAL_COLLECTION_TYPES ,   y :: UVAL_COLLECTION_TYPES ,   [ b ],   n :: Int )    Obtain a distribution over the Kullback-Leibler divergence between two  collections of uncertain values.  This is done by repeating the following procedure  n  times:   First, draw a length- L  realisation of  x  by drawing one random   number from each uncertain value furnishing the dataset. The draws are   independent, so that no element-wise dependencies (e.g. sequential  correlations) that are not already present in the data are introduced in   the realisation.  Second, draw a length- L  realisation of  y  in the same manner.  Compute the Kullback-Leibler divergence between the two   length- L  draws.   This yields  n  estimates of the Kullback-Leibler divergence  between  n  independent pairs of realisations of  x  and  y . The  n -member  distribution of Kullback-Leibler divergence estimates is  returned as a vector.  Optionally a real number  b  can be specified such that the divergence is  scaled by  1 / log ( b ) .  source", 
            "title": "Kullback-Leibler divergence"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/hypothesis_tests_overview/", 
            "text": "Hypothesis tests for uncertain values and collections\n\n\nIn addition to providing ensemble computation of basic statistic measures, this package also wraps various hypothesis tests from \nHypothesisTests\n.\njl\n. This allows us to perform hypothesis testing on ensemble realisations of the data.\n\n\n\n\nTerminology\n\n\nPooled statistics\n are computed by sampling all uncertain values comprising the dataset n times, pooling the values together and treating them as one variable, then computing the statistic.\n\n\nElement-wise statistics\n are computed by sampling each uncertain value n times, keeping the data generated from each uncertain value separate. The statistics are the computed separately for each sample.\n\n\n\n\nImplemented hypothesis tests\n\n\nThe following hypothesis tests are implemented for uncertain data types.\n\n\n\n\nOne sample t-test\n.\n\n\nEqual variance t-test\n.\n\n\nUnequal variance t-test\n.\n\n\nExact Kolmogorov-Smirnov test\n.\n\n\nApproximate two-sample Kolmogorov-Smirnov test\n.\n\n\nOne-sample Anderson\u2013Darling test\n.\n\n\nJarque-Bera test\n.", 
            "title": "Overview"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/hypothesis_tests_overview/#hypothesis_tests_for_uncertain_values_and_collections", 
            "text": "In addition to providing ensemble computation of basic statistic measures, this package also wraps various hypothesis tests from  HypothesisTests . jl . This allows us to perform hypothesis testing on ensemble realisations of the data.", 
            "title": "Hypothesis tests for uncertain values and collections"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/hypothesis_tests_overview/#terminology", 
            "text": "Pooled statistics  are computed by sampling all uncertain values comprising the dataset n times, pooling the values together and treating them as one variable, then computing the statistic.  Element-wise statistics  are computed by sampling each uncertain value n times, keeping the data generated from each uncertain value separate. The statistics are the computed separately for each sample.", 
            "title": "Terminology"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/hypothesis_tests_overview/#implemented_hypothesis_tests", 
            "text": "The following hypothesis tests are implemented for uncertain data types.   One sample t-test .  Equal variance t-test .  Unequal variance t-test .  Exact Kolmogorov-Smirnov test .  Approximate two-sample Kolmogorov-Smirnov test .  One-sample Anderson\u2013Darling test .  Jarque-Bera test .", 
            "title": "Implemented hypothesis tests"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/one_sample_t_test/", 
            "text": "Regular test\n\n\n#\n\n\nHypothesisTests\n.\nOneSampleTTest\n \n \nType\n.\n\n\n1\n2\nOneSampleTTest\n(\nd\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n1000\n;\n\n    \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nOneSampleTTest\n\n\n\n\n\n\n\nPerform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \n\u03bc\n0\n against the alternative hypothesis that its distribution does not have mean \n\u03bc\n0\n. \nn\n indicates the number of draws during resampling.\n\n\nsource\n\n\nExample:\n\n\n1\n2\n3\n4\n5\n6\n# Normally distributed uncertain observation with mean = 2.1\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2.1\n,\n \n0.2\n)\n\n\n\n# Perform a one-sample t-test to test the null hypothesis that\n\n\n# the sample comes from a distribution with mean \u03bc0\n\n\nOneSampleTTest\n(\nuv\n,\n \n1000\n,\n \n\u03bc0\n \n=\n \n2.1\n)\n\n\n\n\n\n\n\nWhich gives the following output:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n# Which results in\n\n\nOne\n \nsample\n \nt\n-\ntest\n\n\n-----------------\n\n\nPopulation\n \ndetails\n:\n\n    \nparameter\n \nof\n \ninterest\n:\n   \nMean\n\n    \nvalue\n \nunder\n \nh_0\n:\n         \n2.1\n\n    \npoint\n \nestimate\n:\n          \n2.1031909275381566\n\n    \n95\n%\n \nconfidence\n \ninterval\n:\n \n(\n2.091\n,\n \n2.1154\n)\n\n\n\nTest\n \nsummary\n:\n\n    \noutcome\n \nwith\n \n95\n%\n \nconfidence\n:\n \nfail\n \nto\n \nreject\n \nh_0\n\n    \ntwo\n-\nsided\n \np\n-\nvalue\n:\n           \n0.6089\n\n\n\nDetails\n:\n\n    \nnumber\n \nof\n \nobservations\n:\n   \n1000\n\n    \nt\n-\nstatistic\n:\n              \n0.5117722099885472\n\n    \ndegrees\n \nof\n \nfreedom\n:\n       \n999\n\n    \nempirical\n \nstandard\n \nerror\n:\n \n0.00623505433839\n\n\n\n\n\n\n\nThus, we cannot reject the null-hypothesis that the sample comes from a distribution with mean = 2.1. Therefore, we accept the alternative hypothesis that our sample \ndoes\n in fact come from such a distribution. This is of course true, because we defined the uncertain value as a normal distribution with mean 2.1.\n\n\n\n\nPooled test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nOneSampleTTestPooled\n \n \nFunction\n.\n\n\n1\n2\n3\nOneSampleTTestPooled\n(\nd1\n::\nUncertainDataset\n,\n\n    \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nOneSampleTTest\n\n\n\n\n\n\n\nFirst, sample \nn\n draws of each uncertain value in each dataset, pooling the draws from the elements of \nd1\n and the draws from the elements of \nd2\n separately. Then, perform a paired sample t-test of the null hypothesis that the differences between pairs of uncertain values in \nd1\n and \nd2\n come from a distribution with mean \n\u03bc\n0\n against the alternative hypothesis that the distribution does not have mean \n\u03bc\n0\n.\n\n\nsource\n\n\n\n\nElement-wise test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nOneSampleTTestElementWise\n \n \nFunction\n.\n\n\n1\n2\n3\nOneSampleTTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n\n    \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nVector\n{\nOneSampleTTest\n}\n\n\n\n\n\n\n\nPerform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \n\u03bc\n0\n against the alternative hypothesis that its distribution does not have mean \n\u03bc\n0\n for uncertain value in \nd\n.\n\n\nn\n indicates the number of draws during resampling.\n\n\nsource", 
            "title": "One sample t-test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/one_sample_t_test/#regular_test", 
            "text": "#  HypothesisTests . OneSampleTTest     Type .  1\n2 OneSampleTTest ( d :: AbstractUncertainValue ,   n :: Int   =   1000 ; \n     \u03bc0 :: Real   =   0 )   -   OneSampleTTest    Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean  \u03bc 0  against the alternative hypothesis that its distribution does not have mean  \u03bc 0 .  n  indicates the number of draws during resampling.  source  Example:  1\n2\n3\n4\n5\n6 # Normally distributed uncertain observation with mean = 2.1  uv   =   UncertainValue ( Normal ,   2.1 ,   0.2 )  # Perform a one-sample t-test to test the null hypothesis that  # the sample comes from a distribution with mean \u03bc0  OneSampleTTest ( uv ,   1000 ,   \u03bc0   =   2.1 )    Which gives the following output:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 # Which results in  One   sample   t - test  -----------------  Population   details : \n     parameter   of   interest :     Mean \n     value   under   h_0 :           2.1 \n     point   estimate :            2.1031909275381566 \n     95 %   confidence   interval :   ( 2.091 ,   2.1154 )  Test   summary : \n     outcome   with   95 %   confidence :   fail   to   reject   h_0 \n     two - sided   p - value :             0.6089  Details : \n     number   of   observations :     1000 \n     t - statistic :                0.5117722099885472 \n     degrees   of   freedom :         999 \n     empirical   standard   error :   0.00623505433839    Thus, we cannot reject the null-hypothesis that the sample comes from a distribution with mean = 2.1. Therefore, we accept the alternative hypothesis that our sample  does  in fact come from such a distribution. This is of course true, because we defined the uncertain value as a normal distribution with mean 2.1.", 
            "title": "Regular test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/one_sample_t_test/#pooled_test", 
            "text": "#  UncertainData . UncertainStatistics . OneSampleTTestPooled     Function .  1\n2\n3 OneSampleTTestPooled ( d1 :: UncertainDataset , \n     d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   -   OneSampleTTest    First, sample  n  draws of each uncertain value in each dataset, pooling the draws from the elements of  d1  and the draws from the elements of  d2  separately. Then, perform a paired sample t-test of the null hypothesis that the differences between pairs of uncertain values in  d1  and  d2  come from a distribution with mean  \u03bc 0  against the alternative hypothesis that the distribution does not have mean  \u03bc 0 .  source", 
            "title": "Pooled test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/one_sample_t_test/#element-wise_test", 
            "text": "#  UncertainData . UncertainStatistics . OneSampleTTestElementWise     Function .  1\n2\n3 OneSampleTTestElementWise ( d1 :: UncertainDataset , \n     d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   -   Vector { OneSampleTTest }    Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean  \u03bc 0  against the alternative hypothesis that its distribution does not have mean  \u03bc 0  for uncertain value in  d .  n  indicates the number of draws during resampling.  source", 
            "title": "Element-wise test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/equal_variance_t_test/", 
            "text": "Regular test\n\n\n#\n\n\nHypothesisTests\n.\nEqualVarianceTTest\n \n \nType\n.\n\n\n1\n2\nEqualVarianceTTest\n(\nd1\n::\nAbstractUncertainValue\n,\n \nd2\n::\nAbstractUncertainValue\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nEqualVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1\n and \ns2\n, each consisting of \nn\n random draws from the distributions furnishing \nd1\n and \nd2\n, respectively.\n\n\nThis function performs a two-sample t-test of the null hypothesis that \ns1\n and \ns2\n come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.\n\n\nsource\n\n\n\n\nExample\n\n\nLet's create two uncertain values furnished by distributions of different types. We'll perform the equal variance t-test to check if there is support for the null-hypothesis that the distributions furnishing the uncertain values come from distributions with equal means and variances.\n\n\nWe expect the test to reject this null-hypothesis, because we've created two very different distributions.\n\n\n1\n2\n3\n4\n5\nuv1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1.2\n,\n \n0.3\n)\n\n\nuv2\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2\n,\n \n3\n)\n\n\n\n# EqualVarianceTTest on 1000 draws for each variable\n\n\nEqualVarianceTTest\n(\nuv1\n,\n \nuv2\n,\n \n1000\n)\n\n\n\n\n\n\n\nThe output is:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nTwo\n \nsample\n \nt\n-\ntest\n \n(\nequal\n \nvariance\n)\n\n\n----------------------------------\n\n\nPopulation\n \ndetails\n:\n\n    \nparameter\n \nof\n \ninterest\n:\n   \nMean\n \ndifference\n\n    \nvalue\n \nunder\n \nh_0\n:\n         \n0\n\n    \npoint\n \nestimate\n:\n          \n-\n4.782470406651697\n\n    \n95\n%\n \nconfidence\n \ninterval\n:\n \n(\n-\n5.0428\n,\n \n-\n4.5222\n)\n\n\n\nTest\n \nsummary\n:\n\n    \noutcome\n \nwith\n \n95\n%\n \nconfidence\n:\n \nreject\n \nh_0\n\n    \ntwo\n-\nsided\n \np\n-\nvalue\n:\n           \n1e-99\n\n\n\nDetails\n:\n\n    \nnumber\n \nof\n \nobservations\n:\n   \n[\n1000\n,\n1000\n]\n\n    \nt\n-\nstatistic\n:\n              \n-\n36.03293014520585\n\n    \ndegrees\n \nof\n \nfreedom\n:\n       \n1998\n\n    \nempirical\n \nstandard\n \nerror\n:\n \n0.1327249931487462\n\n\n\n\n\n\n\nThe test rejects the null-hypothesis, so we accept the alternative hypothesis that the samples come from distributions with different means and variances.\n\n\n\n\nPooled test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nEqualVarianceTTestPooled\n \n \nFunction\n.\n\n\n1\n2\nEqualVarianceTTestPooled\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nEqualVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1\n[\ni\n]\n and \ns2\n[\ni\n]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1\n[\ni\n]\n and \nd2\n[\ni\n]\n, respectively. Gather all \ns1\n[\ni\n]\n in a pooled sample \nS1\n, and all \ns2\n[\ni\n]\n in a pooled sample \nS2\n.\n\n\nPerform a two-sample t-test of the null hypothesis that \nS1\n and \nS2\n come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.\n\n\nsource\n\n\n\n\nElement-wise test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nEqualVarianceTTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nEqualVarianceTTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nVector\n{\nEqualVarianceTTest\n}\n\n\n\n\n\n\n\nConsider two samples \ns1\n[\ni\n]\n and \ns2\n[\ni\n]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1\n[\ni\n]\n and \nd2\n[\ni\n]\n, respectively. This function performs an elementwise \nEqualVarianceTTest\n on the pairs \n(\ns1\n[\ni\n]\n,\n \ns2\n[\ni\n]\n)\n. Specifically:\n\n\nPerforms an pairwise two-sample t-test of the null hypothesis that \ns1\n[\ni\n]\n and \ns2\n[\ni\n]\n come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.\n\n\nsource", 
            "title": "Equal variance t-test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/equal_variance_t_test/#regular_test", 
            "text": "#  HypothesisTests . EqualVarianceTTest     Type .  1\n2 EqualVarianceTTest ( d1 :: AbstractUncertainValue ,   d2 :: AbstractUncertainValue , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   -   EqualVarianceTTest    Consider two samples  s1  and  s2 , each consisting of  n  random draws from the distributions furnishing  d1  and  d2 , respectively.  This function performs a two-sample t-test of the null hypothesis that  s1  and  s2  come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.  source", 
            "title": "Regular test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/equal_variance_t_test/#example", 
            "text": "Let's create two uncertain values furnished by distributions of different types. We'll perform the equal variance t-test to check if there is support for the null-hypothesis that the distributions furnishing the uncertain values come from distributions with equal means and variances.  We expect the test to reject this null-hypothesis, because we've created two very different distributions.  1\n2\n3\n4\n5 uv1   =   UncertainValue ( Normal ,   1.2 ,   0.3 )  uv2   =   UncertainValue ( Gamma ,   2 ,   3 )  # EqualVarianceTTest on 1000 draws for each variable  EqualVarianceTTest ( uv1 ,   uv2 ,   1000 )    The output is:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 Two   sample   t - test   ( equal   variance )  ----------------------------------  Population   details : \n     parameter   of   interest :     Mean   difference \n     value   under   h_0 :           0 \n     point   estimate :            - 4.782470406651697 \n     95 %   confidence   interval :   ( - 5.0428 ,   - 4.5222 )  Test   summary : \n     outcome   with   95 %   confidence :   reject   h_0 \n     two - sided   p - value :             1e-99  Details : \n     number   of   observations :     [ 1000 , 1000 ] \n     t - statistic :                - 36.03293014520585 \n     degrees   of   freedom :         1998 \n     empirical   standard   error :   0.1327249931487462    The test rejects the null-hypothesis, so we accept the alternative hypothesis that the samples come from distributions with different means and variances.", 
            "title": "Example"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/equal_variance_t_test/#pooled_test", 
            "text": "#  UncertainData . UncertainStatistics . EqualVarianceTTestPooled     Function .  1\n2 EqualVarianceTTestPooled ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   -   EqualVarianceTTest    Consider two samples  s1 [ i ]  and  s2 [ i ] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1 [ i ]  and  d2 [ i ] , respectively. Gather all  s1 [ i ]  in a pooled sample  S1 , and all  s2 [ i ]  in a pooled sample  S2 .  Perform a two-sample t-test of the null hypothesis that  S1  and  S2  come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.  source", 
            "title": "Pooled test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/equal_variance_t_test/#element-wise_test", 
            "text": "#  UncertainData . UncertainStatistics . EqualVarianceTTestElementWise     Function .  1\n2 EqualVarianceTTestElementWise ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   -   Vector { EqualVarianceTTest }    Consider two samples  s1 [ i ]  and  s2 [ i ] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1 [ i ]  and  d2 [ i ] , respectively. This function performs an elementwise  EqualVarianceTTest  on the pairs  ( s1 [ i ] ,   s2 [ i ] ) . Specifically:  Performs an pairwise two-sample t-test of the null hypothesis that  s1 [ i ]  and  s2 [ i ]  come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.  source", 
            "title": "Element-wise test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/unequal_variance_t_test/", 
            "text": "Regular test\n\n\n#\n\n\nHypothesisTests\n.\nUnequalVarianceTTest\n \n \nType\n.\n\n\n1\n2\nUnequalVarianceTTest\n(\nd1\n::\nAbstractUncertainValue\n,\n \nd2\n::\nAbstractUncertainValue\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nUnequalVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1\n and \ns2\n, each consisting of \nn\n random draws from the distributions furnishing \nd1\n and \nd2\n, respectively.\n\n\nPerform an unequal variance two-sample t-test of the null hypothesis that \ns1\n and \ns2\n come from distributions with equal means against the alternative hypothesis that the distributions have different means.\n\n\nsource\n\n\n\n\nPooled test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nUnequalVarianceTTestPooled\n \n \nFunction\n.\n\n\n1\n2\nUnequalVarianceTTestPooled\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nUnequalVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1\n[\ni\n]\n and \ns2\n[\ni\n]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1\n[\ni\n]\n and \nd2\n[\ni\n]\n, respectively. Gather all \ns1\n[\ni\n]\n in a pooled sample \nS1\n, and all \ns2\n[\ni\n]\n in a pooled sample \nS2\n.\n\n\nThis function performs an unequal variance two-sample t-test of the null hypothesis that \nS1\n and \nS2\n come from distributions with equal means against the alternative hypothesis that the distributions have different means.\n\n\nsource\n\n\n\n\nElement-wise test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nUnequalVarianceTTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nUnequalVarianceTTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nVector\n{\nUnequalVarianceTTest\n}\n\n\n\n\n\n\n\nConsider two samples \ns1\n[\ni\n]\n and \ns2\n[\ni\n]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1\n[\ni\n]\n and \nd2\n[\ni\n]\n, respectively. This function performs an elementwise \nEqualVarianceTTest\n on the pairs \n(\ns1\n[\ni\n]\n,\n \ns2\n[\ni\n]\n)\n. Specifically:\n\n\nPerforms an pairwise unequal variance two-sample t-test of the null hypothesis that \ns1\n[\ni\n]\n and \ns2\n[\ni\n]\n come from distributions with equal means against the alternative hypothesis that the distributions have different means.\n\n\nThis test is sometimes known as Welch's t-test. It differs from the equal variance t-test in that it computes the number of degrees of freedom of the test using the Welch-Satterthwaite equation:\n\n\n\n\n\n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}\n\n\n\n\n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}\n\n\n\n\n\nsource", 
            "title": "Unequal variance t-test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/unequal_variance_t_test/#regular_test", 
            "text": "#  HypothesisTests . UnequalVarianceTTest     Type .  1\n2 UnequalVarianceTTest ( d1 :: AbstractUncertainValue ,   d2 :: AbstractUncertainValue , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   -   UnequalVarianceTTest    Consider two samples  s1  and  s2 , each consisting of  n  random draws from the distributions furnishing  d1  and  d2 , respectively.  Perform an unequal variance two-sample t-test of the null hypothesis that  s1  and  s2  come from distributions with equal means against the alternative hypothesis that the distributions have different means.  source", 
            "title": "Regular test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/unequal_variance_t_test/#pooled_test", 
            "text": "#  UncertainData . UncertainStatistics . UnequalVarianceTTestPooled     Function .  1\n2 UnequalVarianceTTestPooled ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   -   UnequalVarianceTTest    Consider two samples  s1 [ i ]  and  s2 [ i ] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1 [ i ]  and  d2 [ i ] , respectively. Gather all  s1 [ i ]  in a pooled sample  S1 , and all  s2 [ i ]  in a pooled sample  S2 .  This function performs an unequal variance two-sample t-test of the null hypothesis that  S1  and  S2  come from distributions with equal means against the alternative hypothesis that the distributions have different means.  source", 
            "title": "Pooled test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/unequal_variance_t_test/#element-wise_test", 
            "text": "#  UncertainData . UncertainStatistics . UnequalVarianceTTestElementWise     Function .  1\n2 UnequalVarianceTTestElementWise ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   -   Vector { UnequalVarianceTTest }    Consider two samples  s1 [ i ]  and  s2 [ i ] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1 [ i ]  and  d2 [ i ] , respectively. This function performs an elementwise  EqualVarianceTTest  on the pairs  ( s1 [ i ] ,   s2 [ i ] ) . Specifically:  Performs an pairwise unequal variance two-sample t-test of the null hypothesis that  s1 [ i ]  and  s2 [ i ]  come from distributions with equal means against the alternative hypothesis that the distributions have different means.  This test is sometimes known as Welch's t-test. It differs from the equal variance t-test in that it computes the number of degrees of freedom of the test using the Welch-Satterthwaite equation:   \n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}  \n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}   source", 
            "title": "Element-wise test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/", 
            "text": "Regular test\n\n\n#\n\n\nHypothesisTests\n.\nExactOneSampleKSTest\n \n \nType\n.\n\n\n1\n2\nExactOneSampleKSTest\n(\nuv\n::\nAbstractUncertainValue\n,\n\n    \nd\n::\nUnivariateDistribution\n,\n \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nExactOneSampleKSTest\n\n\n\n\n\n\n\nPerform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that a draw of \nn\n realisations of the uncertain value \nuv\n comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\n\n\nExample\n\n\nWe'll test whether the uncertain value \nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2\n,\n \n4\n)\n comes from the theoretical distribution \nGamma\n(\n2\n,\n \n4\n)\n. Of course, we expect the test to confirm this, because we're using the exact same distribution.\n\n\n1\n2\n3\n4\n5\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2\n,\n \n4\n)\n\n\n\n# Perform the Kolgomorov-Smirnov test by drawing 1000 samples from the\n\n\n# uncertain value.\n\n\nExactOneSampleKSTest\n(\nuv\n,\n \nGamma\n(\n2\n,\n \n4\n),\n \n1000\n)\n\n\n\n\n\n\n\nThat gives the following output:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nExact\n \none\n \nsample\n \nKolmogorov\n-\nSmirnov\n \ntest\n\n\n----------------------------------------\n\n\nPopulation\n \ndetails\n:\n\n    \nparameter\n \nof\n \ninterest\n:\n   \nSupremum\n \nof\n \nCDF\n \ndifferences\n\n    \nvalue\n \nunder\n \nh_0\n:\n         \n0.0\n\n    \npoint\n \nestimate\n:\n          \n0.0228345021301449\n\n\n\nTest\n \nsummary\n:\n\n    \noutcome\n \nwith\n \n95\n%\n \nconfidence\n:\n \nfail\n \nto\n \nreject\n \nh_0\n\n    \ntwo\n-\nsided\n \np\n-\nvalue\n:\n           \n0.6655\n\n\n\nDetails\n:\n\n    \nnumber\n \nof\n \nobservations\n:\n   \n1000\n\n\n\n\n\n\n\nAs expected, the test can't reject the hypothesis that the uncertain value \nuv\n comes from the theoretical distribution \nGamma\n(\n2\n,\n \n4\n)\n, precisely because it does.\n\n\n\n\nPooled test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nExactOneSampleKSTestPooled\n \n \nFunction\n.\n\n\n1\n2\nExactOneSampleKSTestPooled\n(\nud\n::\nUncertainDataset\n,\n\n    \nd\n::\nUnivariateDistribution\n,\n \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nExactOneSampleKSTest\n\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n and pool them together. Then perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that the pooled values comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\n\n\nElement-wise test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nExactOneSampleKSTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nExactOneSampleKSTestElementWise\n(\nud\n::\nUncertainDataset\n,\n\n    \nd\n::\nUnivariateDistribution\n,\n \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nVector\n{\nExactOneSampleKSTest\n}\n\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n, keeping one pool of values for each uncertain value.\n\n\nThen, perform an element-wise (pool-wise) one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that each value pool comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource", 
            "title": "Exact Kolmogorov-Smirnov test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/#regular_test", 
            "text": "#  HypothesisTests . ExactOneSampleKSTest     Type .  1\n2 ExactOneSampleKSTest ( uv :: AbstractUncertainValue , \n     d :: UnivariateDistribution ,   n :: Int   =   1000 )   -   ExactOneSampleKSTest    Perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that a draw of  n  realisations of the uncertain value  uv  comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source", 
            "title": "Regular test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/#example", 
            "text": "We'll test whether the uncertain value  uv   =   UncertainValue ( Gamma ,   2 ,   4 )  comes from the theoretical distribution  Gamma ( 2 ,   4 ) . Of course, we expect the test to confirm this, because we're using the exact same distribution.  1\n2\n3\n4\n5 uv   =   UncertainValue ( Gamma ,   2 ,   4 )  # Perform the Kolgomorov-Smirnov test by drawing 1000 samples from the  # uncertain value.  ExactOneSampleKSTest ( uv ,   Gamma ( 2 ,   4 ),   1000 )    That gives the following output:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 Exact   one   sample   Kolmogorov - Smirnov   test  ----------------------------------------  Population   details : \n     parameter   of   interest :     Supremum   of   CDF   differences \n     value   under   h_0 :           0.0 \n     point   estimate :            0.0228345021301449  Test   summary : \n     outcome   with   95 %   confidence :   fail   to   reject   h_0 \n     two - sided   p - value :             0.6655  Details : \n     number   of   observations :     1000    As expected, the test can't reject the hypothesis that the uncertain value  uv  comes from the theoretical distribution  Gamma ( 2 ,   4 ) , precisely because it does.", 
            "title": "Example"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/#pooled_test", 
            "text": "#  UncertainData . UncertainStatistics . ExactOneSampleKSTestPooled     Function .  1\n2 ExactOneSampleKSTestPooled ( ud :: UncertainDataset , \n     d :: UnivariateDistribution ,   n :: Int   =   1000 )   -   ExactOneSampleKSTest    First, draw  n  realisations of each uncertain value in  ud  and pool them together. Then perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that the pooled values comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source", 
            "title": "Pooled test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/#element-wise_test", 
            "text": "#  UncertainData . UncertainStatistics . ExactOneSampleKSTestElementWise     Function .  1\n2 ExactOneSampleKSTestElementWise ( ud :: UncertainDataset , \n     d :: UnivariateDistribution ,   n :: Int   =   1000 )   -   Vector { ExactOneSampleKSTest }    First, draw  n  realisations of each uncertain value in  ud , keeping one pool of values for each uncertain value.  Then, perform an element-wise (pool-wise) one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that each value pool comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source", 
            "title": "Element-wise test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/", 
            "text": "Pooled test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nApproximateTwoSampleKSTestPooled\n \n \nFunction\n.\n\n\n1\n2\nApproximateTwoSampleKSTestPooled\n(\nd1\n::\nUncertainDataset\n,\n\n    \nd2\n::\nUncertainDataset\n,\n \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nApproximateTwoSampleKSTest\n\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nd1\n, then separately draw \nn\n realisations of each uncertain value in \nd2\n. Then, pool all realisations for \nd1\n together and all realisations of \nd2\n together.\n\n\nOn the pooled realisations, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the distribution furnishing the \nd1\n value pool represents the same distribution as the distribution furnishing the \nd2\n value pool, against the alternative hypothesis that the furnishing distributions are different.\n\n\nsource\n\n\n\n\nElement-wise test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nApproximateTwoSampleKSTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nApproximateTwoSampleKSTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n\n    \nd2\n::\nUncertainDataset\n,\n \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nVector\n{\nApproximateTwoSampleKSTest\n}\n\n\n\n\n\n\n\nAssuming \nd1\n and \nd2\n contain the same number of uncertain observations, draw \nn\n realisations of each uncertain value in \nd1\n, then separately and separately draw \nn\n realisations of each uncertain value in \nd2\n.\n\n\nThen, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the uncertain values in \nd1\n and \nd2\n come from the same distribution against the alternative hypothesis that the (element-wise) values in  \nd1\n and \nd2\n come from different distributions.\n\n\nThe test is performed pairwise, i.e. ApproximateTwoSampleKSTest(d1[i], d2[i]) with \nn\n draws for the \ni\ni\n-ith pair of uncertain values.\n\n\nsource", 
            "title": "Approximate two-sample Kolmogorov-Smirnov test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/#pooled_test", 
            "text": "#  UncertainData . UncertainStatistics . ApproximateTwoSampleKSTestPooled     Function .  1\n2 ApproximateTwoSampleKSTestPooled ( d1 :: UncertainDataset , \n     d2 :: UncertainDataset ,   n :: Int   =   1000 )   -   ApproximateTwoSampleKSTest    First, draw  n  realisations of each uncertain value in  d1 , then separately draw  n  realisations of each uncertain value in  d2 . Then, pool all realisations for  d1  together and all realisations of  d2  together.  On the pooled realisations, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the distribution furnishing the  d1  value pool represents the same distribution as the distribution furnishing the  d2  value pool, against the alternative hypothesis that the furnishing distributions are different.  source", 
            "title": "Pooled test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/#element-wise_test", 
            "text": "#  UncertainData . UncertainStatistics . ApproximateTwoSampleKSTestElementWise     Function .  1\n2 ApproximateTwoSampleKSTestElementWise ( d1 :: UncertainDataset , \n     d2 :: UncertainDataset ,   n :: Int   =   1000 )   -   Vector { ApproximateTwoSampleKSTest }    Assuming  d1  and  d2  contain the same number of uncertain observations, draw  n  realisations of each uncertain value in  d1 , then separately and separately draw  n  realisations of each uncertain value in  d2 .  Then, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the uncertain values in  d1  and  d2  come from the same distribution against the alternative hypothesis that the (element-wise) values in   d1  and  d2  come from different distributions.  The test is performed pairwise, i.e. ApproximateTwoSampleKSTest(d1[i], d2[i]) with  n  draws for the  i i -ith pair of uncertain values.  source", 
            "title": "Element-wise test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/jarque_bera_test/", 
            "text": "Regular test\n\n\n#\n\n\nHypothesisTests\n.\nJarqueBeraTest\n \n \nType\n.\n\n\n1\nJarqueBeraTest\n(\nd\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nJarqueBeraTest\n\n\n\n\n\n\n\nCompute the Jarque-Bera statistic to test the null hypothesis that an uncertain value is normally distributed.\n\n\nsource\n\n\n\n\nPooled test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nJarqueBeraTestPooled\n \n \nFunction\n.\n\n\n1\nJarqueBeraTestPooled\n(\nud\n::\nUncertainDataset\n,\n \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nJarqueBeraTest\n\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n and pool them together. Then, compute the Jarque-Bera statistic to test the null hypothesis that the values of the pool are normally distributed.\n\n\nsource\n\n\n\n\nElement-wise test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nJarqueBeraTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nOneSampleADTestElementWise\n(\nud\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nVector\n{\nJarqueBeraTest\n}\n\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n, keeping one pool of values for each uncertain value.\n\n\nThen, compute the Jarque-Bera statistic to test the null hypothesis that each value pool is normally distributed.\n\n\nsource", 
            "title": "Jarque-Bera test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/jarque_bera_test/#regular_test", 
            "text": "#  HypothesisTests . JarqueBeraTest     Type .  1 JarqueBeraTest ( d :: AbstractUncertainValue ,   n :: Int   =   1000 )   -   JarqueBeraTest    Compute the Jarque-Bera statistic to test the null hypothesis that an uncertain value is normally distributed.  source", 
            "title": "Regular test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/jarque_bera_test/#pooled_test", 
            "text": "#  UncertainData . UncertainStatistics . JarqueBeraTestPooled     Function .  1 JarqueBeraTestPooled ( ud :: UncertainDataset ,   n :: Int   =   1000 )   -   JarqueBeraTest    First, draw  n  realisations of each uncertain value in  ud  and pool them together. Then, compute the Jarque-Bera statistic to test the null hypothesis that the values of the pool are normally distributed.  source", 
            "title": "Pooled test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/jarque_bera_test/#element-wise_test", 
            "text": "#  UncertainData . UncertainStatistics . JarqueBeraTestElementWise     Function .  1\n2 OneSampleADTestElementWise ( ud :: UncertainDataset , \n     n :: Int   =   1000 )   -   Vector { JarqueBeraTest }    First, draw  n  realisations of each uncertain value in  ud , keeping one pool of values for each uncertain value.  Then, compute the Jarque-Bera statistic to test the null hypothesis that each value pool is normally distributed.  source", 
            "title": "Element-wise test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/mann_whitney_u_test/", 
            "text": "Regular test\n\n\n#\n\n\nHypothesisTests\n.\nMannWhitneyUTest\n \n \nFunction\n.\n\n\n1\n2\nMannWhitneyUTest\n(\nd1\n::\nAbstractUncertainValue\n,\n \nd2\n::\nAbstractUncertainValue\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nMannWhitneyUTest\n\n\n\n\n\n\n\nLet \ns1\n and \ns2\n be samples of \nn\n realisations from the distributions furnishing the uncertain values \nd1\n and \nd2\n.\n\n\nPerform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as \ns1\n is greater than an observation drawn from the same population as \ns2\n is equal to the probability that an observation drawn from the same population as \ns2\n is greater than an observation drawn from the same population as \ns1\n against the alternative hypothesis that these probabilities are not equal.\n\n\nThe Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, \nMannWhitneyUTest\n performs an exact Mann-Whitney U test. In all other cases, \nMannWhitneyUTest\n performs an approximate Mann-Whitney U test.\n\n\nsource\n\n\n\n\nPooled test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nMannWhitneyUTestPooled\n \n \nFunction\n.\n\n\n1\n2\nMannWhitneyUTest\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nMannWhitneyUTest\n\n\n\n\n\n\n\nLet \ns_{1_{i}}\ns_{1_{i}}\n be a sample of \nn\n realisations of the distribution furnishing the uncertain value \nd1\n[\ni\n]\n, where \ni \\in [1, 2, \\ldots, N]\ni \\in [1, 2, \\ldots, N]\n and \nN\nN\n is the number of uncertain values in \nd1\n.  Next, gather the samples for all \ns_{1_{i}}\ns_{1_{i}}\n in a pooled sample \nS_1\nS_1\n.  Do the same for the second uncertain dataset \nd2\n, yielding the pooled sample  \nS_2\nS_2\n.\n\n\nPerform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as \nS_1\nS_1\n is greater than an observation drawn from the same population as \nS_2\nS_2\n is equal to the probability that an observation drawn from the same population as \nS_2\nS_2\n is greater than an observation drawn from the same population as \nS_1\nS_1\n against the alternative hypothesis that these probabilities are not equal.\n\n\nThe Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, \nMannWhitneyUTest\n performs an exact Mann-Whitney U test. In all other cases, \nMannWhitneyUTest\n performs an approximate Mann-Whitney U test.\n\n\nsource\n\n\n\n\nElement-wise test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nMannWhitneyUTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nMannWhitneyUTest\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nVector\n{\nMannWhitneyUTest\n}\n\n\n\n\n\n\n\nAssume \nd1\n and \nd2\n consist of the same number of uncertain values. Let \ns_{1_{i}}\ns_{1_{i}}\n be a sample of \nn\n realisations of the distribution furnishing the uncertain value \nd1\n[\ni\n]\n, where \ni \\in [1, 2, \\ldots, N]\ni \\in [1, 2, \\ldots, N]\n and \nN\nN\n is the number of uncertain values in \nd1\n. Let \ns_{2_{i}}\ns_{2_{i}}\n be the corresponding sample for \nd2\n[\ni\n]\n. This function\n\n\nPerform an element-wise Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as \ns_{1_{i}}\ns_{1_{i}}\n is greater than an observation drawn from the same population as \ns_{2_{i}}\ns_{2_{i}}\n is equal to the probability that an observation drawn from the same population as \ns_{2_{i}}\ns_{2_{i}}\n is greater than an observation drawn from the same population as \ns_{1_{i}}\ns_{1_{i}}\n against the alternative hypothesis that these probabilities are not equal.\n\n\nThe Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, \nMannWhitneyUTest\n performs an exact Mann-Whitney U test. In all other cases, \nMannWhitneyUTest\n performs an approximate Mann-Whitney U test.\n\n\nsource", 
            "title": "Mann-Whitney u-test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/mann_whitney_u_test/#regular_test", 
            "text": "#  HypothesisTests . MannWhitneyUTest     Function .  1\n2 MannWhitneyUTest ( d1 :: AbstractUncertainValue ,   d2 :: AbstractUncertainValue , \n     n :: Int   =   1000 )   -   MannWhitneyUTest    Let  s1  and  s2  be samples of  n  realisations from the distributions furnishing the uncertain values  d1  and  d2 .  Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as  s1  is greater than an observation drawn from the same population as  s2  is equal to the probability that an observation drawn from the same population as  s2  is greater than an observation drawn from the same population as  s1  against the alternative hypothesis that these probabilities are not equal.  The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples,  MannWhitneyUTest  performs an exact Mann-Whitney U test. In all other cases,  MannWhitneyUTest  performs an approximate Mann-Whitney U test.  source", 
            "title": "Regular test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/mann_whitney_u_test/#pooled_test", 
            "text": "#  UncertainData . UncertainStatistics . MannWhitneyUTestPooled     Function .  1\n2 MannWhitneyUTest ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 )   -   MannWhitneyUTest    Let  s_{1_{i}} s_{1_{i}}  be a sample of  n  realisations of the distribution furnishing the uncertain value  d1 [ i ] , where  i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N]  and  N N  is the number of uncertain values in  d1 .  Next, gather the samples for all  s_{1_{i}} s_{1_{i}}  in a pooled sample  S_1 S_1 .  Do the same for the second uncertain dataset  d2 , yielding the pooled sample   S_2 S_2 .  Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as  S_1 S_1  is greater than an observation drawn from the same population as  S_2 S_2  is equal to the probability that an observation drawn from the same population as  S_2 S_2  is greater than an observation drawn from the same population as  S_1 S_1  against the alternative hypothesis that these probabilities are not equal.  The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples,  MannWhitneyUTest  performs an exact Mann-Whitney U test. In all other cases,  MannWhitneyUTest  performs an approximate Mann-Whitney U test.  source", 
            "title": "Pooled test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/mann_whitney_u_test/#element-wise_test", 
            "text": "#  UncertainData . UncertainStatistics . MannWhitneyUTestElementWise     Function .  1\n2 MannWhitneyUTest ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 )   -   Vector { MannWhitneyUTest }    Assume  d1  and  d2  consist of the same number of uncertain values. Let  s_{1_{i}} s_{1_{i}}  be a sample of  n  realisations of the distribution furnishing the uncertain value  d1 [ i ] , where  i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N]  and  N N  is the number of uncertain values in  d1 . Let  s_{2_{i}} s_{2_{i}}  be the corresponding sample for  d2 [ i ] . This function  Perform an element-wise Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as  s_{1_{i}} s_{1_{i}}  is greater than an observation drawn from the same population as  s_{2_{i}} s_{2_{i}}  is equal to the probability that an observation drawn from the same population as  s_{2_{i}} s_{2_{i}}  is greater than an observation drawn from the same population as  s_{1_{i}} s_{1_{i}}  against the alternative hypothesis that these probabilities are not equal.  The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples,  MannWhitneyUTest  performs an exact Mann-Whitney U test. In all other cases,  MannWhitneyUTest  performs an approximate Mann-Whitney U test.  source", 
            "title": "Element-wise test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/anderson_darling_test/", 
            "text": "Regular test\n\n\n#\n\n\nHypothesisTests\n.\nOneSampleADTest\n \n \nType\n.\n\n\n1\n2\nOneSampleADTest\n(\nuv\n::\nUncertainValue\n,\n \nd\n::\nUnivariateDistribution\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n)\n \n-\n \nOneSampleADTest\n\n\n\n\n\n\n\nPerform a one-sample Anderson\u2013Darling test of the null hypothesis that a draw of \nn\n realisations of the uncertain value \nuv\n comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\n\n\nPooled test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nOneSampleADTestPooled\n \n \nFunction\n.\n\n\n1\n2\nOneSampleADTestPooled\n(\nud\n::\nUncertainDataset\n,\n \nd\n::\nUnivariateDistribution\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n))\n \n-\n \nOneSampleADTest\n\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n and pool them together. Then perform a one-sample Anderson\u2013Darling test of the null hypothesis that the pooled values comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\n\n\nElement-wise test\n\n\n#\n\n\nUncertainData\n.\nUncertainStatistics\n.\nOneSampleADTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nOneSampleADTestElementWise\n(\nud\n::\nUncertainDataset\n,\n \nd\n::\nUnivariateDistribution\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n))\n \n-\n \nVector\n{\nOneSampleADTest\n}\n\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n, keeping one pool of values for each uncertain value. Then, perform an element-wise (pool-wise) one-sample Anderson\u2013Darling test of the null hypothesis that each value pool comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource", 
            "title": "Anderson-Darling test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/anderson_darling_test/#regular_test", 
            "text": "#  HypothesisTests . OneSampleADTest     Type .  1\n2 OneSampleADTest ( uv :: UncertainValue ,   d :: UnivariateDistribution , \n     n :: Int   =   1000 )   -   OneSampleADTest    Perform a one-sample Anderson\u2013Darling test of the null hypothesis that a draw of  n  realisations of the uncertain value  uv  comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source", 
            "title": "Regular test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/anderson_darling_test/#pooled_test", 
            "text": "#  UncertainData . UncertainStatistics . OneSampleADTestPooled     Function .  1\n2 OneSampleADTestPooled ( ud :: UncertainDataset ,   d :: UnivariateDistribution , \n     n :: Int   =   1000 ))   -   OneSampleADTest    First, draw  n  realisations of each uncertain value in  ud  and pool them together. Then perform a one-sample Anderson\u2013Darling test of the null hypothesis that the pooled values comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source", 
            "title": "Pooled test"
        }, 
        {
            "location": "/uncertain_statistics/hypothesistests/anderson_darling_test/#element-wise_test", 
            "text": "#  UncertainData . UncertainStatistics . OneSampleADTestElementWise     Function .  1\n2 OneSampleADTestElementWise ( ud :: UncertainDataset ,   d :: UnivariateDistribution , \n     n :: Int   =   1000 ))   -   Vector { OneSampleADTest }    First, draw  n  realisations of each uncertain value in  ud , keeping one pool of values for each uncertain value. Then, perform an element-wise (pool-wise) one-sample Anderson\u2013Darling test of the null hypothesis that each value pool comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source", 
            "title": "Element-wise test"
        }, 
        {
            "location": "/implementing_algorithms_for_uncertaindata/", 
            "text": "Extending existing algorithms for uncertain data types\n\n\nDo you already have an algorithm computing some statistic that you want to obtain uncertainty estimates for? Simply use Julia's multiple dispatch and create a version of the algorithm function that accepts the \nAbstractUncertainValue\n and \nAbstractUncertainDataset\n types, along with a \nSamplingConstraints\n specifying how the uncertain values are should be resampled.\n\n\nA basic function skeleton could be\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n# Some algorithm computing a statistic for a scalar-valued vector\n\n\nfunction\n \nmyalgorithm\n(\ndataset\n::\nVector\n{\nT\n};\n \nkwargs\n...\n)\n \nwhere\n \nT\n\n    \n# some algorithm returning a single-valued statistic\n\n\nend\n\n\n\n# Applying the algorithm to an ensemble of realisations from\n\n\n# an uncertain dataset, given a sampling constraint.\n\n\nfunction\n \nmyalgorithm\n(\nd\n::\nUncertainDataset\n,\n \nconstraint\n::\nC\n;\n\n        \nn_ensemble_realisations\n \n=\n \n100\n,\n \nkwargs\n...\n)\n\n        \nwhere\n \n{\nC\n \n:\n \nSamplingConstraint\n}\n\n\n    \nensemble_stats\n \n=\n \nzeros\n(\nn_ensemble_realisations\n)\n\n\n    \nfor\n \ni\n \nin\n \n1\n:\nn_ensemble_realisations\n\n        \nensemble_stats\n[\ni\n]\n \n=\n \nmyalgorithm\n(\nresample\n(\nd\n,\n \nconstraint\n);\n \nkwargs\n...\n)\n\n    \nend\n\n\n    \nreturn\n \nensemble_stats\n\n\nend", 
            "title": "Implementing algorithms for uncertain data"
        }, 
        {
            "location": "/implementing_algorithms_for_uncertaindata/#extending_existing_algorithms_for_uncertain_data_types", 
            "text": "Do you already have an algorithm computing some statistic that you want to obtain uncertainty estimates for? Simply use Julia's multiple dispatch and create a version of the algorithm function that accepts the  AbstractUncertainValue  and  AbstractUncertainDataset  types, along with a  SamplingConstraints  specifying how the uncertain values are should be resampled.  A basic function skeleton could be   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19 # Some algorithm computing a statistic for a scalar-valued vector  function   myalgorithm ( dataset :: Vector { T };   kwargs ... )   where   T \n     # some algorithm returning a single-valued statistic  end  # Applying the algorithm to an ensemble of realisations from  # an uncertain dataset, given a sampling constraint.  function   myalgorithm ( d :: UncertainDataset ,   constraint :: C ; \n         n_ensemble_realisations   =   100 ,   kwargs ... ) \n         where   { C   :   SamplingConstraint } \n\n     ensemble_stats   =   zeros ( n_ensemble_realisations ) \n\n     for   i   in   1 : n_ensemble_realisations \n         ensemble_stats [ i ]   =   myalgorithm ( resample ( d ,   constraint );   kwargs ... ) \n     end \n\n     return   ensemble_stats  end", 
            "title": "Extending existing algorithms for uncertain data types"
        }, 
        {
            "location": "/changelog/", 
            "text": "Changelog\n\n\n\n\nUncertainData.jl v0.5.0\n\n\n\n\nBreaking changes\n\n\n\n\nTo allow easier multiple dispatch, the \nindices\n field of a \nUncertainIndexValueDataset\n is   now \nalways\n an instance of a subtype of \nAbstractUncertainIndexDataset\n. The \nvalues\n field    of a \nUncertainIndexValueDataset\n is now \nalways\n an instance of a subtype of    \nAbstractUncertainValueDataset\n.\n\n\n\n\n\n\nNew functionality\n\n\n\n\nExperimental support for nested populations.\n\n\n\n\nAdded point-estimators for single uncertain values:\n\n\n\n\nharmmean\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\ngeomean\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\nkurtosis\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n;\n \nm\n \n=\n \nmean\n(\nx\n))\n\n\nmoment\n(\nx\n::\nAbstractUncertainValue\n,\n \nk\n,\n \nn\n::\nInt\n,\n \nm\n \n=\n \nmean\n(\nx\n))\n\n\npercentile\n(\nx\n::\nAbstractUncertainValue\n,\n \np\n,\n \nn\n::\nInt\n)\n\n\nrenyientropy\n(\nx\n::\nAbstractUncertainValue\n,\n \n\u03b1\n,\n \nn\n::\nInt\n)\n\n\nrle\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\nsem\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\nskewness\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n;\n \nm\n \n=\n \nmean\n(\nx\n))\n\n\nspan\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\nsummarystats\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\ntotalvar\n(\nx\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\n\n\nAdded statistical estimators for pairs of uncertain values:\n\n\n\n\n\n\ncov\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n;\n \ncorrected\n::\nBool\n \n=\n \ntrue\n)\n\n\n\n\ncor\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\ncountne\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\ncounteq\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\ncorkendall\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\ncorspearman\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\nmaxad\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\nmeanad\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\nmsd\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\npsnr\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nmaxv\n,\n \nn\n::\nInt\n)\n\n\nrmsd\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n;\n \nnormalize\n \n=\n \nfalse\n)\n\n\nsqL2dist\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\ncrosscor\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n;\n \ndemean\n \n=\n \ntrue\n)\n\n\ncrosscov\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n;\n \ndemean\n \n=\n \ntrue\n)\n\n\ngkldiv\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\nkldivergence\n(\nx\n::\nAbstractUncertainValue\n,\n \ny\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n)\n\n\nAdded \nUncertainValue\n constructor for distribution instances.\n\n\nAdded \nUncertainValue\n constructor for (potentially nested) truncated distribution instances.\n\n\nImplemented \nresample\n methods for \nNTuple\ns of uncertain values.\n\n\nAdded \nresample\n(\nf\n::\nFunction\n,\n \nn\n::\nInt\n,\n \nx\n::\nAbstractUncertainValue\n,\n \nargs\n...;\n \nkwargs\n...)\nmethod for    easy evaluation of point-estimates for single uncertain values.\n\n\nAdded support for \nMeasurement\n instances from    \nMeasurements.jl\n.   These are treated as uncertain values represented by normal distibutions.    Hence, they are given no extra treatment and error propagation is done by    resampling, not by exact methods.\n\n\nThe uncertain value type \nUncertainScalarPopulation\n may now not only have real-valued scalars    as elements of the population. It can now have uncertain values as members of the population!\n\n\nResampling implemented for \nUncertainScalarPopulation\n so that we can also sample population    members that are uncertain values.\n\n\nImplemented iteration for \nUncertainScalarPopulation\n.\n\n\n\n\n\n\n\n\n\n\nImprovements\n\n\n\n\nImproved subtyping for theoretical distributions.\n\n\nRemoved redundant \nresample\n methods for the \nUncertainDataset\n type. \nUncertainDataset\n    is a subtype of \nAbstractUncertainValueDataset\n and has no special behaviour beyond    that implemented for the abstract type, so now we just rely on multiple dispatch here.\n\n\n\n\n\n\nDocumentation\n\n\n\n\nImproved documentation statistical methods.\n\n\nOther minor documentation improvements.\n\n\nImproved documentation for \nTruncateStd\n.\n\n\n\n\n\n\nBug fixes\n\n\n\n\nFixed error in \nshow\n method for \nAbstractUncertainValue\n. Not subtypes of \nAbstractUncertainValue\n has the \ndistributions\n field, so that is now removed from the \nshow\n method.\n\n\n\n\n\n\nUncertainData.jl v0.4.0\n\n\n\n\nNew functionality\n\n\n\n\nIntroduce an abstract resampling type \nAbstractUncertainDataResampling\n for this    package pending the implementation of \nAbstractResampling\n in StatsBase.jl.\n\n\nAdded \nConstrainedResampling\n resampling scheme.\n\n\n\n\nResample vectors of uncertain values without constraints. Syntax:\n\n\n\n\nresample\n(::\nVector\n{\n:\nAbstractUncertainValue\n}\n for single draws.\n\n\nresample\n(::\nVector\n{\n:\nAbstractUncertainValue\n}\n,\n \n::\nInt\n}\n for multiple draws.\n\n\n\n\nResample vectors of uncertain values with constraint(s) multiple times. Syntax:\n\n\n\n\n\n\nresample\n(::\nVector\n{\n:\nAbstractUncertainValue\n}\n,\n \n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\n:\nSamplingConstraint\n}}\n for single draws.\n\n\n\n\nresample\n(::\nVector\n{\n:\nAbstractUncertainValue\n}\n,\n \n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\n:\nSamplingConstraint\n}}\n,\n \n::\nInt\n for multiple draws.\n\n\n\n\n\n\n\n\n\n\nUncertainData.jl v0.3.0\n\n\n\n\nNew functionality\n\n\n\n\nAdded additional resampling methods for uncertain index and uncertain value datasets,    allowing passing vectors of constraints that are mapped to each value in the dataset. The    syntax is \nresample\n(::\nAbstractUncertainValueDataset\n,\n \n::\nVector\n{\n:\nSamplingConstraint\n}\n for a    single draw, and \nresample\n(::\nAbstractUncertainValueDataset\n,\n \n::\nVector\n{\n:\nSamplingConstraint\n}\n,\n \nn\n::\nInt\n   for \nn\n draws.\n\n\n\n\n\n\nUncertainData.jl v0.2.3\n\n\n\n\nImprovements\n\n\n\n\nAdded input validation when initialising \nTruncateQuantiles\n, \nTruncateRange\n and    \nTruncateStd\n.\n\n\nSeparate parameters types for \nTruncateQuantiles\n and \nTruncateRange\n, so one can do for    example \nTruncateRange\n(\n1\n,\n \n8\n.\n0\n)\n, instead of having to promote to \nFloat64\n.\n\n\nAdded validation for distribution truncation when resampling.\n\n\n\n\n\n\nUncertainData.jl v0.2.2\n\n\n\n\nNew functionality and syntax changes\n\n\n\n\nResampling vectors consisting of uncertain values (done in #61)\n\n\n\n\nresample\n(\nuvals\n::\nVector\n{\nAbstractUncertainValue\n}\n,\n \nn\n::\nInt\n)\n is now interpreted as \"treat    \nuvals\n as a dataset and sample it \nn\n times\". Thus, it now behaves as    \nresample\n(\nAbstractUncertainDataset\n,\n \nn\n::\nInt\n)\n, returning \nn\n vectors of length    \nlength\n(\nuvals\n)\n, where the i-th element is a unique draw of \nuvals\n[\ni\n]\n.\n\n\nresample_elwise\n(\nuvals\n::\nVector\n{\nAbstractUncertainValue\n}\n,\n \nn\n::\nInt\n)\n takes over the role as    \"sample \nuvals\n element-wise and \nn\n times for each element\". Returns a vector of    length \nlength\n(\nuvals\n)\n, where the i-th element is a \nn\n-element vector of unique draws    of \nuvals\n[\ni\n]\n.\n\n\n\n\n\n\nResampling with subtypes of \nAbstractUncertainValueDataset\n\n\nCurrently, this affects the generic \nUncertainDataset\ns, as well as the specialized  \nUncertainIndexDataset\ns and \nUncertainValueDataset\ns.\n\n\n\n\nresample_elwise\n(\nuvd\n::\nAbstractUncertainValueDataset\n,\n \nn\n::\nInt\n)\n is now interpreted as    \"draw \nn\n realisations of each value in \nuvd\n\". Returns a vector of length \nlength\n(\nuvals\n)\n    where the i-th element is a \nn\n-element vector of unique draws of \nuvals\n[\ni\n]\n. This works    for \nUncertainDataset\ns, \nUncertainIndexDataset\ns, and \nUncertainValueDataset\ns.\n\n\nresample_elwise\n(\nuvd\n::\nAbstractUncertainValueDataset\n,\n \nconstraint\n::\nUnion\n{\nSamplingConstraint\n,\n \nVector\n{\nSamplingConstraint\n}}\n,\n \nn\n::\nInt\n)\n    is now interpreted as \"draw \nn\n realisations of each value in \nuvd\n, subjecting each value    in \nuvd\n to some sampling \nconstraint\n(s) during resampling\". Returns a vector of    length \nlength\n(\nuvals\n)\n where the i-th element is a \nn\n-element vector of unique draws    of \nuvals\n[\ni\n]\n, where the support of \nuvals\n[\ni\n]\n has been truncated by the provided    \nconstraint\n(s).\n\n\n\n\n\n\nBug fixes\n\n\n\n\nRemoved extra blank line from print method for \nAbstractUncertainPopulation\n.\n\n\n\n\n\n\nUncertainData.jl v0.2.1\n\n\n\n\nNew functionality\n\n\n\n\nmerge\n(\nuvals\n::\nVector\n{\n:AbstractUncertainValue\n}\n;\n \nn\n \n=\n \n1000\n)\n now makes it possible to    combine many uncertain values of different into one uncertain value represented by a    kernel density estimate. This is achieved by resampling each of the values \nn\n times,    then pooling the draws and estimating a total distribution using KDE.\n\n\nmerge\n(\nuvals\n::\nVector\n{\n:AbstractUncertainValue\n}\n;\n \nweights\n::\nWeights\n \nn\n \n=\n \n1000\n)\n,    \nmerge\n(\nuvals\n::\nVector\n{\n:AbstractUncertainValue\n}\n;\n \nweights\n::\nAnalyticalWeights\n \nn\n \n=\n \n1000\n)\n    and    \nmerge\n(\nuvals\n::\nVector\n{\n:AbstractUncertainValue\n}\n;\n \nweights\n::\nProbabilityWeights\n \nn\n \n=\n \n1000\n)\n   merges uncertain values by resampling them proportionally to \nweights\n, then pooling    the draws and performing KDE. These are all functionally equivalent, but implementations   for different weights are provided for compatibility with StatsBase.\n\n\nmerge\n(\nuvals\n::\nVector\n{\n:AbstractUncertainValue\n}\n;\n \nweights\n::\nFrequencyWeights\n \nn\n \n=\n \n1000\n)\n    merges uncertain values by sampling them according to the number of samples provided    with \nweights\n.\n\n\n\n\n\n\nBug fixes\n\n\n\n\nresample\n didn't work for \nUncertainIndexDataset\ns due to the data being stored in the    \nindices\n field, not the \nvalues\n field as for other subtypes of    \nAbstractUncertainValueDataset\n. This is now fixed.\n\n\n\n\n\n\nUncertainData.jl v0.2.0\n\n\n\n\nNotes\n\n\n\n\nJulia 1.1 is required for version \n v.0.2.0.\n\n\n\n\n\n\nNew functionality\n\n\n\n\nSpline interpolation on a regular grid.\n\n\nLinear interpolation on an irregular grid.\n\n\n\n\n\n\nImprovements\n\n\n\n\nsupport_overlap\n now returns an interval (from \nIntervalArithmetic\n), in line with    what \nsupport\n returns.\n\n\n\n\n\n\nUncertainData.jl v0.1.8\n\n\n\n\nBug fixes\n\n\n\n\nAdded missing package dependencies which were not caught by CI.\n\n\n\n\n\n\nUncertainData.jl v0.1.7\n\n\n\n\nNew functionality\n\n\n\n\nUncertainIndexValueDataset\ns can now be constructed from vectors of uncertain values.    To do so, provide a vector of uncertain values for the indices, and the same for the    values, e.g. \nUncertainIndexValueDataset\n([\nidx1\n,\n \nidx2\n],\n \n[\nval1\n,\n \nval2\n])\n.\n\n\nIndex-value dataset realizations can now be    \ninterpolated on a regular grid\n.\n\n\n\n\n\n\nBug fixes\n\n\n\n\nminima\n and \nmaxima\n now returns the global minimum for a dataset instead of a vector    of elementwise minima and maxima.\n\n\nImplemented the option to linearly interpolate index-value dataset realizations.    To do so, provide \nresample\n with a \nRegularGrid\n instance.\n\n\nMerged redundant methods for assigning some distributions.\n\n\nFixed non-critical indexing bug for uncertain index-value datasets.\n\n\nRemoved redudant method definitions and multiple imports of the same files causing    definitions to be overwritten and printing warnings statements when loading the package.\n\n\n\n\n\n\nUncertainData.jl v0.1.6\n\n\n\n\nNew functionality\n\n\n\n\nImplemented sequential sampling constraints \nStrictlyIncreasing\n and \nStrictlyDecreasing\n   for \nUncertainIndexValueDataset\ns.\n\n\nAdded \nUncertainScalarPopulation\n type, representing    vectors of values that should be sampled according to a vector of probabilities.\n\n\n\n\n\n\nImprovements\n\n\n\n\nImproved documentation for \nCertainValue\ns.\n\n\nAdded documentation for \nUncertainScalarPopulation\n.\n\n\nAdded \nUncertainScalarPopulation\n to uncertain value overview list in the documentation.\n\n\nFixed duplicate docs for \ncot\n, \ncotd\n, \ncoth\n and added missing \nacot\n, \nacotd\n, \nacoth\n   docs.\n\n\nShortened and updated main documentation page with more links.\n\n\n\n\n\n\nBug fixes\n\n\n\n\nImport \nBase\n functions properly when defining \nCertainValue\n, so that no unexpected    behaviour is introduced.\n\n\nFixed links in documentation that pointed to the wrong locations.\n\n\nRemove model resampling docs which was not supposed to be published until the    functionality is properly implemented.\n\n\n\n\n\n\nUncertainData.jl v0.1.5\n\n\n\n\nNew functionality\n\n\n\n\nAdded \nCertainValue\n type to represent scalars without   any uncertainty. Even though a scalar is not uncertain, we'll define it as subtype of    \nAbstractUncertainValue\n to treat certain values alongside uncertain values in datasets.\n\n\nAdded plot recipe for \nCertainValue\ns. They are just plotted as regular points.\n\n\nAdded method \nresample\n(\nVector\n{\nAbstractUncertainValue\n}\n)\n for resampling vectors of    uncertain values. Operates element-wise, just as for an uncertain dataset.\n\n\nAdded an abstract type \nSequentialSamplingConstraint\n to separate sequential constraints    from general constraints that might be applied \nbefore\n resampling according to    the sequential constraints.\n\n\nAdded abstract type (\nOrderedSamplingAlgorithm\n) and composite types    (\nStartToEnd\n, \nEndToStart\n, \nMidpointOutwards\n, \nChunksForwards\n, \nChunksBackwards\n)    which indicates how to sample sequential realizations when resampling an uncertain    dataset. Only \nStartToEnd\n is used at the moment.\n\n\nAdded abstract type \nSequentialSamplingConstraint\n which is the supertype for all    sequential constraints.\n\n\nAdded function to check if strictly increasing sequences through an uncertain dataset    exist: \nstrictly_increasing_sequence_exists\n(\nudata\n::\nAbstractUncertainValueDataset\n.\n\n\nAdded function to check if strictly decreasing sequences through an uncertain dataset    exist: \nstrictly_increasing_sequence_exists\n(\nudata\n::\nAbstractUncertainValueDataset\n.\n\n\nAdded the \nStrictlyIncreasing\n{\nT\n}\n \nwhere\n \n{\nT\n:\nOrderedSamplingAlgorithm\n}\n sequential    constraint for resampling uncertain datasets.\n\n\nAdded the \nStrictlyDecreasing\n{\nT\n}\n \nwhere\n \n{\nT\n:\nOrderedSamplingAlgorithm\n}\n sequential    constraint for resampling uncertain datasets.\n\n\n\n\nAdded resampling methods\n\n\n\n\nresample\n(\nudata\n,\n \nsequential_constraint\n::\nStrictlyIncreasing\n{\nT\n}\n \nwhere\n \n{\nT\n \n:\n \nStartToEnd\n}\n\n\nresample\n(\nudata\n,\n \nsequential_constraint\n::\nStrictlyDecreasing\n{\nT\n}\n \nwhere\n \n{\nT\n \n:\n \nStartToEnd\n}\n\n\nresample\n(\nudata\n,\n \nconstraint\n::\nSamplingConstraint\n,\n \nsequential_constraint\n::\nStrictlyIncreasing\n{\nT\n}\n \nwhere\n \n{\nT\n \n:\n \nStartToEnd\n}\n\n\nresample\n(\nudata\n,\n \nconstraint\n::\nSamplingConstraint\n,\n \nsequential_constraint\n::\nStrictlyDecreasing\n{\nT\n}\n \nwhere\n \n{\nT\n \n:\n \nStartToEnd\n}\n\n\nresample\n(\nudata\n,\n \nconstraint\n::\nVector\n{\nSamplingConstraint\n}\n,\n \nsequential_constraint\n::\nStrictlyIncreasing\n{\nT\n}\n \nwhere\n \n{\nT\n \n:\n \nStartToEnd\n}\n\n\nresample\n(\nudata\n,\n \nconstraint\n::\nVector\n{\nSamplingConstraint\n}\n,\n \nsequential_constraint\n::\nStrictlyDecreasing\n{\nT\n}\n \nwhere\n \n{\nT\n \n:\n \nStartToEnd\n}\n\n\n\n\n\n\n\n\n\n\nImprovements\n\n\n\n\nAdded \ndocumentation on sequential constraints\n, clearly separating it from the general constraints.\n\n\n\n\n\n\nUncertainData.jl v0.1.4\n\n\n\n\nBreaking changes\n\n\n\n\nElementary operations for \n(\nscalar\n,\n \nuncertain_value\n)\n, \n(\nuncertain_value\n,\n \nscalar\n)\n and    \n(\nuncertain_value\n,\n \nuncertain_value\n)\n pairs now returns an uncertain value instead of    a vector of resampled realizations. The default behaviour is to perform a kernel    density estimate over the vector of results of the element-wise operations (which    was previously returned without representing it as an uncertain value).\n\n\n\n\n\n\nNew functionality\n\n\n\n\nImplemented constraints for datasets that have already been constrained.    \nconstrain\n(\nudata\n::\nConstrainedDataset\n,\n \ns\n::\nSamplingConstraint\n)\n will now return another    \nConstrainedDataset\n. The same applies for \nConstrainedIndexDataset\n and    \nConstrainedValueDataset\n.\n\n\nAdded \nmaximum\n(\nVector\n{\nAbstractUncertainValue\n}\n)\n and    \nminimum\n(\nVector\n{\nAbstractUncertainValue\n}\n)\n methods.\n\n\nAdded plot recipe for \nVector\n{\nAbstractUncertainValue\n}\ns. Behaves just as plotting an   uncertain dataset, assuming an implicit indices \n1\n:\nlength\n(\nv\n)\n. Error bars may be    tuned by providing a second argument of quantiles to \nplot\n, e.g. \nplot\n(\nv\n,\n \n[\n0\n.\n2\n,\n \n0\n.\n8\n]\n   gives error bars covering the 20\nth\n to 80\nth\n percentile range of the data.\n\n\n\n\n\n\nImprovements\n\n\n\n\nAdded documentation for \nStrictlyIncreasing\n and \nStrictlyDecreasing\n sampling    constraints.\n\n\nAdded \nshow\n function for \nAbstractUncertainIndexDataset\n. \nshow\n errored previously,    because it assumed the default behaviour of \nAbstractUncertainValueDataset\n, which    does not have the \nindices\n field.\n\n\n\n\n\n\nBug fixes\n\n\n\n\nFixed bug when resampling an uncertain dataset using the \nNoConstraint\n constraint,    which did not work to due to a reference to a non-existing variable.\n\n\nFixed test bug where when resampling an uncertain value with the \nTruncateStd\n sampling   constraint, the test compared the result to a fixed scalar, not the standar deviation    of the value. This sometimes made the travis build fail.\n\n\n\n\n\n\nUncertainData.jl v0.1.3\n\n\n\n\nNew functionality\n\n\n\n\nAllow both the \nindices\n and \nvalues\n fields of \nUncertainIndexValueDataset\n to be any    subtype of \nAbstractUncertainValueDataset\n. This way, you don't \nhave\n to use an    index dataset type for the indices if not necessary.\n\n\n\n\n\n\nImprovements\n\n\n\n\nImproved documentation for \nUncertainIndexDataset\n, \nUncertainValueDataset\n,    \nUncertainDataset\n and \nUncertainIndexValueDataset\n types and added an    \noverview page\n in the documentation    to explain the difference between these types.\n\n\nAdded an \noverview\n section for the resampling    documentation.\n\n\nCleaned and improved \ndocumentation for uncertain values\n.\n\n\nAdded separate \ndocumentation for the uncertain index dataset type\n.\n\n\nAdded separate \ndocumentation for the uncertain value dataset type\n.\n\n\nImproved \ndocumentation for the generic uncertain dataset type\n\n\nMerged documentation for sampling constraints and resampling.\n\n\nAdded missing documentation for the \nsinc\n, \nsincos\n, \nsinpi\n, \ncosc\n and \ncospi\n trig    functions.\n\n\n\n\n\n\nUncertainData.jl v0.1.2\n\n\n\n\nNew functionality\n\n\n\n\nSupport \nelementary mathematical operations\n    (\n+\n, \n-\n, \n*\n and \n/\n) between arbitrary    uncertain values of different types. Also works with the combination of scalars and    uncertain values. Because elementary operations should work on arbitrary uncertain    values, a resampling approach is used to perform the mathematical operations. This    means that all mathematical operations return a vector containing the results of    repeated element-wise operations (where each element is a resampled draw from the    furnishing distribution(s) of the uncertain value(s)). The default number of    realizations is set to \n10000\n. This allows calling \nuval1\n \n+\n \nuval2\n for two uncertain    values \nuval1\n and \nuval2\n. If you need to tune the number of resample draws to \nn\n,    you need to use the \n+\n(\nuval1\n,\n \nuval2\n,\n \nn\n)\n syntax (similar for the operators). In the    future, elementary operations might be improved for certain combinations of uncertain   values where exact expressions for error propagation are now, for example using the    machinery in \nMeasurements\n.\njl\n for normally distributed values.\n\n\nSupport for \ntrigonometric functions\n added (\nsin\n, \nsind\n, \nsinh\n, \ncos\n,   \ncosd\n, \ncosh\n, \ntan\n, \ntand\n, \ntanh\n, \ncsc\n, \ncscd\n, \ncsch\n, \ncsc\n, \ncscd\n, \ncsch\n,    \nsec\n, \nsecd\n, \nsech\n, \ncot\n, \ncotd\n, \ncoth\n, \nsincos\n, \nsinc\n, \nsinpi\n, \ncosc\n,    \ncospi\n). Inverses are also defined (\nasin\n, \nasind\n, \nasinh\n, \nacos\n,   \nacosd\n, \nacosh\n, \natan\n, \natand\n, \natanh\n, \nacsc\n, \nacscd\n, \nacsch\n, \nacsc\n, \nacscd\n,    \nacsch\n, \nasec\n, \nasecd\n, \nasech\n, \nacot\n, \nacotd\n, \nacoth\n).   Beware: if the support of the funishing distribution for an uncertain value lies partly    outside the domain of the function, you risk encountering errors.   These also use a resampling approach, using \n10000\n realizations by default.    Use either the \nsin\n(\nuval\n)\n syntax for the default, and \nsin\n(\nuval\n,\n \nn\n::\nInt\n)\n to tune the    number of samples.\n\n\nSupport non-integer multiples of the standard deviation in the \nTruncateStd\n sampling    constraint.\n\n\n\n\n\n\nFixes\n\n\n\n\nFixed bug in resampling of index-value datasets, where the \nn\n arguments wasn't used.\n\n\nBugfix: due to \nStatsBase\n.\nstd\n not being defined for \nFittedDistribution\n instances,    uncertain values represented by \nUncertainScalarTheoreticalFit\n instances were not    compatible with the \nTruncateStd\n sampling constraint. Now fixed!\n\n\nAdded missing \nresample\n(\nuv\n::\nAbstractUncertainValue\n,\n \nconstraint\n::\nTruncateRange\n,\n \nn\n::\nInt\n)\n    method.\n\n\n\n\n\n\nImprovements\n\n\n\n\nImproved resampling documentation for \nUncertainIndexValueDataset\ns. Now shows    the documentation for the main methods, as well as examples of how to use different    sampling constraints for each individual index and data value.\n\n\nImproved resampling documentation for \nUncertainDataset\ns. Now shows    the documentation for the main methods.\n\n\n\n\n\n\nUncertainData.jl v0.1.1\n\n\n\n\nNew functionality\n\n\n\n\nIndexing implemented for \nUncertainIndexValueDataset\n.\n\n\nResampling implemented for \nUncertainIndexValueDataset\n.\n\n\nUncertain values and uncertain datasets now support \nminimum\n and \nmaximum\n.\n\n\nsupport\n(\nuv\n::\nAbstractUncertainValue\n)\n now always returns an interval from    \nIntervalArithmetic.jl\n\n\nsupport_overlap\n now computes overlaps also for fitted theoretical distributions.\n\n\nAdded more plotting recipes.\n\n\nAll implemented uncertain data types now support resampling.\n\n\n\n\n\n\nImprovements\n\n\n\n\nImproved general documentation. Added a reference to \n   Measurements.jl\n and an explanation    for the differences between the packages.\n\n\nImproved resampling documentation with detailed explanation and plots.\n\n\n\n\n\n\nUncertainData.jl v0.1.0\n\n\n\n\nBasic functionality in place.", 
            "title": "Changelog"
        }, 
        {
            "location": "/changelog/#changelog", 
            "text": "", 
            "title": "Changelog"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v050", 
            "text": "", 
            "title": "UncertainData.jl v0.5.0"
        }, 
        {
            "location": "/changelog/#breaking_changes", 
            "text": "To allow easier multiple dispatch, the  indices  field of a  UncertainIndexValueDataset  is   now  always  an instance of a subtype of  AbstractUncertainIndexDataset . The  values  field    of a  UncertainIndexValueDataset  is now  always  an instance of a subtype of     AbstractUncertainValueDataset .", 
            "title": "Breaking changes"
        }, 
        {
            "location": "/changelog/#new_functionality", 
            "text": "Experimental support for nested populations.   Added point-estimators for single uncertain values:   harmmean ( x :: AbstractUncertainValue ,   n :: Int )  geomean ( x :: AbstractUncertainValue ,   n :: Int )  kurtosis ( x :: AbstractUncertainValue ,   n :: Int ;   m   =   mean ( x ))  moment ( x :: AbstractUncertainValue ,   k ,   n :: Int ,   m   =   mean ( x ))  percentile ( x :: AbstractUncertainValue ,   p ,   n :: Int )  renyientropy ( x :: AbstractUncertainValue ,   \u03b1 ,   n :: Int )  rle ( x :: AbstractUncertainValue ,   n :: Int )  sem ( x :: AbstractUncertainValue ,   n :: Int )  skewness ( x :: AbstractUncertainValue ,   n :: Int ;   m   =   mean ( x ))  span ( x :: AbstractUncertainValue ,   n :: Int )  summarystats ( x :: AbstractUncertainValue ,   n :: Int )  totalvar ( x :: AbstractUncertainValue ,   n :: Int )   Added statistical estimators for pairs of uncertain values:    cov ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int ;   corrected :: Bool   =   true )   cor ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  countne ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  counteq ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  corkendall ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  corspearman ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  maxad ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  meanad ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  msd ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  psnr ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   maxv ,   n :: Int )  rmsd ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int ;   normalize   =   false )  sqL2dist ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  crosscor ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int ;   demean   =   true )  crosscov ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int ;   demean   =   true )  gkldiv ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  kldivergence ( x :: AbstractUncertainValue ,   y :: AbstractUncertainValue ,   n :: Int )  Added  UncertainValue  constructor for distribution instances.  Added  UncertainValue  constructor for (potentially nested) truncated distribution instances.  Implemented  resample  methods for  NTuple s of uncertain values.  Added  resample ( f :: Function ,   n :: Int ,   x :: AbstractUncertainValue ,   args ...;   kwargs ...) method for    easy evaluation of point-estimates for single uncertain values.  Added support for  Measurement  instances from     Measurements.jl .   These are treated as uncertain values represented by normal distibutions.    Hence, they are given no extra treatment and error propagation is done by    resampling, not by exact methods.  The uncertain value type  UncertainScalarPopulation  may now not only have real-valued scalars    as elements of the population. It can now have uncertain values as members of the population!  Resampling implemented for  UncertainScalarPopulation  so that we can also sample population    members that are uncertain values.  Implemented iteration for  UncertainScalarPopulation .", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#improvements", 
            "text": "Improved subtyping for theoretical distributions.  Removed redundant  resample  methods for the  UncertainDataset  type.  UncertainDataset     is a subtype of  AbstractUncertainValueDataset  and has no special behaviour beyond    that implemented for the abstract type, so now we just rely on multiple dispatch here.", 
            "title": "Improvements"
        }, 
        {
            "location": "/changelog/#documentation", 
            "text": "Improved documentation statistical methods.  Other minor documentation improvements.  Improved documentation for  TruncateStd .", 
            "title": "Documentation"
        }, 
        {
            "location": "/changelog/#bug_fixes", 
            "text": "Fixed error in  show  method for  AbstractUncertainValue . Not subtypes of  AbstractUncertainValue  has the  distributions  field, so that is now removed from the  show  method.", 
            "title": "Bug fixes"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v040", 
            "text": "", 
            "title": "UncertainData.jl v0.4.0"
        }, 
        {
            "location": "/changelog/#new_functionality_1", 
            "text": "Introduce an abstract resampling type  AbstractUncertainDataResampling  for this    package pending the implementation of  AbstractResampling  in StatsBase.jl.  Added  ConstrainedResampling  resampling scheme.   Resample vectors of uncertain values without constraints. Syntax:   resample (:: Vector { : AbstractUncertainValue }  for single draws.  resample (:: Vector { : AbstractUncertainValue } ,   :: Int }  for multiple draws.   Resample vectors of uncertain values with constraint(s) multiple times. Syntax:    resample (:: Vector { : AbstractUncertainValue } ,   :: Union { SamplingConstraint ,   Vector { : SamplingConstraint }}  for single draws.   resample (:: Vector { : AbstractUncertainValue } ,   :: Union { SamplingConstraint ,   Vector { : SamplingConstraint }} ,   :: Int  for multiple draws.", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v030", 
            "text": "", 
            "title": "UncertainData.jl v0.3.0"
        }, 
        {
            "location": "/changelog/#new_functionality_2", 
            "text": "Added additional resampling methods for uncertain index and uncertain value datasets,    allowing passing vectors of constraints that are mapped to each value in the dataset. The    syntax is  resample (:: AbstractUncertainValueDataset ,   :: Vector { : SamplingConstraint }  for a    single draw, and  resample (:: AbstractUncertainValueDataset ,   :: Vector { : SamplingConstraint } ,   n :: Int    for  n  draws.", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v023", 
            "text": "", 
            "title": "UncertainData.jl v0.2.3"
        }, 
        {
            "location": "/changelog/#improvements_1", 
            "text": "Added input validation when initialising  TruncateQuantiles ,  TruncateRange  and     TruncateStd .  Separate parameters types for  TruncateQuantiles  and  TruncateRange , so one can do for    example  TruncateRange ( 1 ,   8 . 0 ) , instead of having to promote to  Float64 .  Added validation for distribution truncation when resampling.", 
            "title": "Improvements"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v022", 
            "text": "", 
            "title": "UncertainData.jl v0.2.2"
        }, 
        {
            "location": "/changelog/#new_functionality_and_syntax_changes", 
            "text": "", 
            "title": "New functionality and syntax changes"
        }, 
        {
            "location": "/changelog/#resampling_vectors_consisting_of_uncertain_values_done_in_61", 
            "text": "resample ( uvals :: Vector { AbstractUncertainValue } ,   n :: Int )  is now interpreted as \"treat     uvals  as a dataset and sample it  n  times\". Thus, it now behaves as     resample ( AbstractUncertainDataset ,   n :: Int ) , returning  n  vectors of length     length ( uvals ) , where the i-th element is a unique draw of  uvals [ i ] .  resample_elwise ( uvals :: Vector { AbstractUncertainValue } ,   n :: Int )  takes over the role as    \"sample  uvals  element-wise and  n  times for each element\". Returns a vector of    length  length ( uvals ) , where the i-th element is a  n -element vector of unique draws    of  uvals [ i ] .", 
            "title": "Resampling vectors consisting of uncertain values (done in #61)"
        }, 
        {
            "location": "/changelog/#resampling_with_subtypes_of_abstractuncertainvaluedataset", 
            "text": "Currently, this affects the generic  UncertainDataset s, as well as the specialized   UncertainIndexDataset s and  UncertainValueDataset s.   resample_elwise ( uvd :: AbstractUncertainValueDataset ,   n :: Int )  is now interpreted as    \"draw  n  realisations of each value in  uvd \". Returns a vector of length  length ( uvals )     where the i-th element is a  n -element vector of unique draws of  uvals [ i ] . This works    for  UncertainDataset s,  UncertainIndexDataset s, and  UncertainValueDataset s.  resample_elwise ( uvd :: AbstractUncertainValueDataset ,   constraint :: Union { SamplingConstraint ,   Vector { SamplingConstraint }} ,   n :: Int )     is now interpreted as \"draw  n  realisations of each value in  uvd , subjecting each value    in  uvd  to some sampling  constraint (s) during resampling\". Returns a vector of    length  length ( uvals )  where the i-th element is a  n -element vector of unique draws    of  uvals [ i ] , where the support of  uvals [ i ]  has been truncated by the provided     constraint (s).", 
            "title": "Resampling with subtypes of AbstractUncertainValueDataset"
        }, 
        {
            "location": "/changelog/#bug_fixes_1", 
            "text": "Removed extra blank line from print method for  AbstractUncertainPopulation .", 
            "title": "Bug fixes"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v021", 
            "text": "", 
            "title": "UncertainData.jl v0.2.1"
        }, 
        {
            "location": "/changelog/#new_functionality_3", 
            "text": "merge ( uvals :: Vector { :AbstractUncertainValue } ;   n   =   1000 )  now makes it possible to    combine many uncertain values of different into one uncertain value represented by a    kernel density estimate. This is achieved by resampling each of the values  n  times,    then pooling the draws and estimating a total distribution using KDE.  merge ( uvals :: Vector { :AbstractUncertainValue } ;   weights :: Weights   n   =   1000 ) ,     merge ( uvals :: Vector { :AbstractUncertainValue } ;   weights :: AnalyticalWeights   n   =   1000 )     and     merge ( uvals :: Vector { :AbstractUncertainValue } ;   weights :: ProbabilityWeights   n   =   1000 )    merges uncertain values by resampling them proportionally to  weights , then pooling    the draws and performing KDE. These are all functionally equivalent, but implementations   for different weights are provided for compatibility with StatsBase.  merge ( uvals :: Vector { :AbstractUncertainValue } ;   weights :: FrequencyWeights   n   =   1000 )     merges uncertain values by sampling them according to the number of samples provided    with  weights .", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#bug_fixes_2", 
            "text": "resample  didn't work for  UncertainIndexDataset s due to the data being stored in the     indices  field, not the  values  field as for other subtypes of     AbstractUncertainValueDataset . This is now fixed.", 
            "title": "Bug fixes"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v020", 
            "text": "", 
            "title": "UncertainData.jl v0.2.0"
        }, 
        {
            "location": "/changelog/#notes", 
            "text": "Julia 1.1 is required for version   v.0.2.0.", 
            "title": "Notes"
        }, 
        {
            "location": "/changelog/#new_functionality_4", 
            "text": "Spline interpolation on a regular grid.  Linear interpolation on an irregular grid.", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#improvements_2", 
            "text": "support_overlap  now returns an interval (from  IntervalArithmetic ), in line with    what  support  returns.", 
            "title": "Improvements"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v018", 
            "text": "", 
            "title": "UncertainData.jl v0.1.8"
        }, 
        {
            "location": "/changelog/#bug_fixes_3", 
            "text": "Added missing package dependencies which were not caught by CI.", 
            "title": "Bug fixes"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v017", 
            "text": "", 
            "title": "UncertainData.jl v0.1.7"
        }, 
        {
            "location": "/changelog/#new_functionality_5", 
            "text": "UncertainIndexValueDataset s can now be constructed from vectors of uncertain values.    To do so, provide a vector of uncertain values for the indices, and the same for the    values, e.g.  UncertainIndexValueDataset ([ idx1 ,   idx2 ],   [ val1 ,   val2 ]) .  Index-value dataset realizations can now be     interpolated on a regular grid .", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#bug_fixes_4", 
            "text": "minima  and  maxima  now returns the global minimum for a dataset instead of a vector    of elementwise minima and maxima.  Implemented the option to linearly interpolate index-value dataset realizations.    To do so, provide  resample  with a  RegularGrid  instance.  Merged redundant methods for assigning some distributions.  Fixed non-critical indexing bug for uncertain index-value datasets.  Removed redudant method definitions and multiple imports of the same files causing    definitions to be overwritten and printing warnings statements when loading the package.", 
            "title": "Bug fixes"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v016", 
            "text": "", 
            "title": "UncertainData.jl v0.1.6"
        }, 
        {
            "location": "/changelog/#new_functionality_6", 
            "text": "Implemented sequential sampling constraints  StrictlyIncreasing  and  StrictlyDecreasing    for  UncertainIndexValueDataset s.  Added  UncertainScalarPopulation  type, representing    vectors of values that should be sampled according to a vector of probabilities.", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#improvements_3", 
            "text": "Improved documentation for  CertainValue s.  Added documentation for  UncertainScalarPopulation .  Added  UncertainScalarPopulation  to uncertain value overview list in the documentation.  Fixed duplicate docs for  cot ,  cotd ,  coth  and added missing  acot ,  acotd ,  acoth    docs.  Shortened and updated main documentation page with more links.", 
            "title": "Improvements"
        }, 
        {
            "location": "/changelog/#bug_fixes_5", 
            "text": "Import  Base  functions properly when defining  CertainValue , so that no unexpected    behaviour is introduced.  Fixed links in documentation that pointed to the wrong locations.  Remove model resampling docs which was not supposed to be published until the    functionality is properly implemented.", 
            "title": "Bug fixes"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v015", 
            "text": "", 
            "title": "UncertainData.jl v0.1.5"
        }, 
        {
            "location": "/changelog/#new_functionality_7", 
            "text": "Added  CertainValue  type to represent scalars without   any uncertainty. Even though a scalar is not uncertain, we'll define it as subtype of     AbstractUncertainValue  to treat certain values alongside uncertain values in datasets.  Added plot recipe for  CertainValue s. They are just plotted as regular points.  Added method  resample ( Vector { AbstractUncertainValue } )  for resampling vectors of    uncertain values. Operates element-wise, just as for an uncertain dataset.  Added an abstract type  SequentialSamplingConstraint  to separate sequential constraints    from general constraints that might be applied  before  resampling according to    the sequential constraints.  Added abstract type ( OrderedSamplingAlgorithm ) and composite types    ( StartToEnd ,  EndToStart ,  MidpointOutwards ,  ChunksForwards ,  ChunksBackwards )    which indicates how to sample sequential realizations when resampling an uncertain    dataset. Only  StartToEnd  is used at the moment.  Added abstract type  SequentialSamplingConstraint  which is the supertype for all    sequential constraints.  Added function to check if strictly increasing sequences through an uncertain dataset    exist:  strictly_increasing_sequence_exists ( udata :: AbstractUncertainValueDataset .  Added function to check if strictly decreasing sequences through an uncertain dataset    exist:  strictly_increasing_sequence_exists ( udata :: AbstractUncertainValueDataset .  Added the  StrictlyIncreasing { T }   where   { T : OrderedSamplingAlgorithm }  sequential    constraint for resampling uncertain datasets.  Added the  StrictlyDecreasing { T }   where   { T : OrderedSamplingAlgorithm }  sequential    constraint for resampling uncertain datasets.   Added resampling methods   resample ( udata ,   sequential_constraint :: StrictlyIncreasing { T }   where   { T   :   StartToEnd }  resample ( udata ,   sequential_constraint :: StrictlyDecreasing { T }   where   { T   :   StartToEnd }  resample ( udata ,   constraint :: SamplingConstraint ,   sequential_constraint :: StrictlyIncreasing { T }   where   { T   :   StartToEnd }  resample ( udata ,   constraint :: SamplingConstraint ,   sequential_constraint :: StrictlyDecreasing { T }   where   { T   :   StartToEnd }  resample ( udata ,   constraint :: Vector { SamplingConstraint } ,   sequential_constraint :: StrictlyIncreasing { T }   where   { T   :   StartToEnd }  resample ( udata ,   constraint :: Vector { SamplingConstraint } ,   sequential_constraint :: StrictlyDecreasing { T }   where   { T   :   StartToEnd }", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#improvements_4", 
            "text": "Added  documentation on sequential constraints , clearly separating it from the general constraints.", 
            "title": "Improvements"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v014", 
            "text": "", 
            "title": "UncertainData.jl v0.1.4"
        }, 
        {
            "location": "/changelog/#breaking_changes_1", 
            "text": "Elementary operations for  ( scalar ,   uncertain_value ) ,  ( uncertain_value ,   scalar )  and     ( uncertain_value ,   uncertain_value )  pairs now returns an uncertain value instead of    a vector of resampled realizations. The default behaviour is to perform a kernel    density estimate over the vector of results of the element-wise operations (which    was previously returned without representing it as an uncertain value).", 
            "title": "Breaking changes"
        }, 
        {
            "location": "/changelog/#new_functionality_8", 
            "text": "Implemented constraints for datasets that have already been constrained.     constrain ( udata :: ConstrainedDataset ,   s :: SamplingConstraint )  will now return another     ConstrainedDataset . The same applies for  ConstrainedIndexDataset  and     ConstrainedValueDataset .  Added  maximum ( Vector { AbstractUncertainValue } )  and     minimum ( Vector { AbstractUncertainValue } )  methods.  Added plot recipe for  Vector { AbstractUncertainValue } s. Behaves just as plotting an   uncertain dataset, assuming an implicit indices  1 : length ( v ) . Error bars may be    tuned by providing a second argument of quantiles to  plot , e.g.  plot ( v ,   [ 0 . 2 ,   0 . 8 ]    gives error bars covering the 20 th  to 80 th  percentile range of the data.", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#improvements_5", 
            "text": "Added documentation for  StrictlyIncreasing  and  StrictlyDecreasing  sampling    constraints.  Added  show  function for  AbstractUncertainIndexDataset .  show  errored previously,    because it assumed the default behaviour of  AbstractUncertainValueDataset , which    does not have the  indices  field.", 
            "title": "Improvements"
        }, 
        {
            "location": "/changelog/#bug_fixes_6", 
            "text": "Fixed bug when resampling an uncertain dataset using the  NoConstraint  constraint,    which did not work to due to a reference to a non-existing variable.  Fixed test bug where when resampling an uncertain value with the  TruncateStd  sampling   constraint, the test compared the result to a fixed scalar, not the standar deviation    of the value. This sometimes made the travis build fail.", 
            "title": "Bug fixes"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v013", 
            "text": "", 
            "title": "UncertainData.jl v0.1.3"
        }, 
        {
            "location": "/changelog/#new_functionality_9", 
            "text": "Allow both the  indices  and  values  fields of  UncertainIndexValueDataset  to be any    subtype of  AbstractUncertainValueDataset . This way, you don't  have  to use an    index dataset type for the indices if not necessary.", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#improvements_6", 
            "text": "Improved documentation for  UncertainIndexDataset ,  UncertainValueDataset ,     UncertainDataset  and  UncertainIndexValueDataset  types and added an     overview page  in the documentation    to explain the difference between these types.  Added an  overview  section for the resampling    documentation.  Cleaned and improved  documentation for uncertain values .  Added separate  documentation for the uncertain index dataset type .  Added separate  documentation for the uncertain value dataset type .  Improved  documentation for the generic uncertain dataset type  Merged documentation for sampling constraints and resampling.  Added missing documentation for the  sinc ,  sincos ,  sinpi ,  cosc  and  cospi  trig    functions.", 
            "title": "Improvements"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v012", 
            "text": "", 
            "title": "UncertainData.jl v0.1.2"
        }, 
        {
            "location": "/changelog/#new_functionality_10", 
            "text": "Support  elementary mathematical operations     ( + ,  - ,  *  and  / ) between arbitrary    uncertain values of different types. Also works with the combination of scalars and    uncertain values. Because elementary operations should work on arbitrary uncertain    values, a resampling approach is used to perform the mathematical operations. This    means that all mathematical operations return a vector containing the results of    repeated element-wise operations (where each element is a resampled draw from the    furnishing distribution(s) of the uncertain value(s)). The default number of    realizations is set to  10000 . This allows calling  uval1   +   uval2  for two uncertain    values  uval1  and  uval2 . If you need to tune the number of resample draws to  n ,    you need to use the  + ( uval1 ,   uval2 ,   n )  syntax (similar for the operators). In the    future, elementary operations might be improved for certain combinations of uncertain   values where exact expressions for error propagation are now, for example using the    machinery in  Measurements . jl  for normally distributed values.  Support for  trigonometric functions  added ( sin ,  sind ,  sinh ,  cos ,    cosd ,  cosh ,  tan ,  tand ,  tanh ,  csc ,  cscd ,  csch ,  csc ,  cscd ,  csch ,     sec ,  secd ,  sech ,  cot ,  cotd ,  coth ,  sincos ,  sinc ,  sinpi ,  cosc ,     cospi ). Inverses are also defined ( asin ,  asind ,  asinh ,  acos ,    acosd ,  acosh ,  atan ,  atand ,  atanh ,  acsc ,  acscd ,  acsch ,  acsc ,  acscd ,     acsch ,  asec ,  asecd ,  asech ,  acot ,  acotd ,  acoth ).   Beware: if the support of the funishing distribution for an uncertain value lies partly    outside the domain of the function, you risk encountering errors.   These also use a resampling approach, using  10000  realizations by default.    Use either the  sin ( uval )  syntax for the default, and  sin ( uval ,   n :: Int )  to tune the    number of samples.  Support non-integer multiples of the standard deviation in the  TruncateStd  sampling    constraint.", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#fixes", 
            "text": "Fixed bug in resampling of index-value datasets, where the  n  arguments wasn't used.  Bugfix: due to  StatsBase . std  not being defined for  FittedDistribution  instances,    uncertain values represented by  UncertainScalarTheoreticalFit  instances were not    compatible with the  TruncateStd  sampling constraint. Now fixed!  Added missing  resample ( uv :: AbstractUncertainValue ,   constraint :: TruncateRange ,   n :: Int )     method.", 
            "title": "Fixes"
        }, 
        {
            "location": "/changelog/#improvements_7", 
            "text": "Improved resampling documentation for  UncertainIndexValueDataset s. Now shows    the documentation for the main methods, as well as examples of how to use different    sampling constraints for each individual index and data value.  Improved resampling documentation for  UncertainDataset s. Now shows    the documentation for the main methods.", 
            "title": "Improvements"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v011", 
            "text": "", 
            "title": "UncertainData.jl v0.1.1"
        }, 
        {
            "location": "/changelog/#new_functionality_11", 
            "text": "Indexing implemented for  UncertainIndexValueDataset .  Resampling implemented for  UncertainIndexValueDataset .  Uncertain values and uncertain datasets now support  minimum  and  maximum .  support ( uv :: AbstractUncertainValue )  now always returns an interval from     IntervalArithmetic.jl  support_overlap  now computes overlaps also for fitted theoretical distributions.  Added more plotting recipes.  All implemented uncertain data types now support resampling.", 
            "title": "New functionality"
        }, 
        {
            "location": "/changelog/#improvements_8", 
            "text": "Improved general documentation. Added a reference to     Measurements.jl  and an explanation    for the differences between the packages.  Improved resampling documentation with detailed explanation and plots.", 
            "title": "Improvements"
        }, 
        {
            "location": "/changelog/#uncertaindatajl_v010", 
            "text": "Basic functionality in place.", 
            "title": "UncertainData.jl v0.1.0"
        }, 
        {
            "location": "/publications/", 
            "text": "Scientific papers\n\n\n\n\nVasskog, Kristian, John\u2010Inge Svendsen, Jan Mangerud, Kristian Agas\u00f8ster Haaga,    Arve Svean, and Eva Maria Lunnan. \"Evidence of early deglaciation (18 000 cal a bp)    and a postglacial relative sea\u2010level curve from southern Karm\u00f8y, south\u2010west Norway.\"    Journal of Quaternary Science    (2019)\n.\n\n\n\n\n\n\nSoftware\n\n\n\n\nCausalityTools.jl\n version \n= 0.3.0   uses UncertainData.jl to detect causal relationships between time series with    uncertainties.", 
            "title": "Publications and software"
        }, 
        {
            "location": "/publications/#scientific_papers", 
            "text": "Vasskog, Kristian, John\u2010Inge Svendsen, Jan Mangerud, Kristian Agas\u00f8ster Haaga,    Arve Svean, and Eva Maria Lunnan. \"Evidence of early deglaciation (18 000 cal a bp)    and a postglacial relative sea\u2010level curve from southern Karm\u00f8y, south\u2010west Norway.\"    Journal of Quaternary Science    (2019) .", 
            "title": "Scientific papers"
        }, 
        {
            "location": "/publications/#software", 
            "text": "CausalityTools.jl  version  = 0.3.0   uses UncertainData.jl to detect causal relationships between time series with    uncertainties.", 
            "title": "Software"
        }
    ]
}